[
  {
    "url": "http://jayendrapatil.com/aws-elasticsearch/",
    "questionNumber": 1,
    "isProfessional": false,
    "text": "You need to perform ad-hoc analysis on log data, including searching quickly for specific error codes and reference numbers. Which should you evaluate first?",
    "choiceList": [
      "A. AWS Elasticsearch Service",
      "B. AWS RedShift",
      "C. AWS EMR",
      "D. AWS DynamoDB"
    ],
    "answerList": [
      "A"
    ],
    "commentList": [
      "Question 1@http://jayendrapatil.com/aws-elasticsearch/",
      "A: http://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/what-is-amazon-elasticsearch-service.html",
      "A: Elasticsearch Service (ES) is a managed service that makes it easy to deploy, operate, and scale Elasticsearch clusters in the AWS cloud. Elasticsearch is a popular open-source search and analytics engine for use cases such as log analytics, real-time application monitoring, and click stream analytics",
      "A: (. Refer )"
    ]
  },
  {
    "url": "http://jayendrapatil.com/aws-elasticsearch/",
    "questionNumber": 2,
    "isProfessional": false,
    "text": "You are hired as the new head of operations for a SaaS company. Your CTO has asked you to make debugging any part of your entire operation simpler and as fast as possible. She complains that she has no idea what is going on in the complex, service-oriented architecture, because the developers just log to disk, and itâ€™s very hard to find errors in logs on so many services. How can you best meet this requirement and satisfy your CTO?",
    "choiceList": [
      "A. Copy all log files into AWS S3 using a cron job on each instance. Use an S3 Notification Configuration on the \u003ccode\u003ePutBucket\u003c/code\u003e event and publish events to AWS Lambda. Use the Lambda to analyze logs as soon as they come in and flag issues.",
      "B. Begin using CloudWatch Logs on every service. Stream all Log Groups into S3 objects. Use AWS EMR cluster jobs to perform adhoc MapReduce analysis and write new queries when needed.",
      "C. Copy all log files into AWS S3 using a cron job on each instance. Use an S3 Notification Configuration on the \u003ccode\u003ePutBucket\u003c/code\u003e event and publish events to AWS Kinesis. Use Apache Spark on AWS EMR to perform at-scale stream processing queries on the log chunks and flag issues.",
      "D. Begin using CloudWatch Logs on every service. Stream all Log Groups into an AWS Elasticsearch Service Domain running Kibana 4 and perform log analysis on a search cluster."
    ],
    "answerList": [
      "D"
    ],
    "commentList": [
      "Question 2@http://jayendrapatil.com/aws-elasticsearch/",
      "D: AWS Elasticsearch with Kibana stack is designed specifically for real-time, ad-hoc log analysis and aggregation"
    ]
  }
]