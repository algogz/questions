### Question 1:

You are a Solutions Architect at Digital Cloud Guru. A client has requested a design for a highly-available, fault tolerant architecture for the web and app tiers of a three-tier application. The requirements are as follows: - Web instances will be in a public subnet and app instances will be in a private subnet - Connections to EC2 instances should be automatically distributed across AZs - A minimum of 12 web server EC2 instances must be running at all times - A minimum of 6 app server EC2 instances must be running at all times - The failure of a single availability zone (AZ) not affect the availability of the application or result in a reduction of capacity beneath the stated requirements Which of the following design options would be the most suitable and cost-effective solution?

- A. One Auto Scaling Group using 3 AZs and a minimum of 12 EC2 instances behind an Internet facing ALB for the web layer. One Auto Scaling Group using 3 AZs and a minimum of 6 EC2 instances behind an internal-only ALB for the app layer 
- B. One Auto Scaling Group using 3 AZs and a minimum of 18 EC2 instances behind an Internet facing ALB for the web layer. One Auto Scaling Group using 3 AZs and a minimum of 9 EC2 instances behind an internal-only ALB for the app layer 
- C. One Auto Scaling Group with a minimum of 12 EC2 instances for the web layer. One Auto Scaling Group using 3 AZs and a minimum of 6 EC2 instances for the app layer. A single Internet-facing ALB using 3 AZs and two target groups for the web and app layers
- D. One Auto Scaling Group with a minimum of 18 EC2 instances for the web layer. One Auto Scaling Group using 3 AZs and a minimum of 9 EC2 instances for the app layer. A single Internet-facing ALB using 3 AZs and two target groups for the web and app layers

<details><summary>Answer:</summary><p>
B

Explanation:

Simple scaling maintains a current number of instances, you can manually change the ASGs min/desired/max and attach/detach instances

Auto Scaling will try to distribute EC2 instances evenly across AZs

Must have a minimum of 12 instances running in the event of an AZ failure

ELBs can be Internet facing or internal-only

Internet facing ELB nodes have public IPs

Internal only ELB nodes have private IPs

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/compute/aws-auto-scaling/

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/compute/elastic-load-balancing/

</p></details><hr>

### Question 2:

The association between a poll-based source and a Lambda function is called the event source mapping. Event sources maintain the mapping configuration except for stream-based services such as ________ and ________ for which the configuration is made on the Lambda side and Lambda performs the polling. Fill in the blanks from the options below (choose 2)

- A. API Gateway
- B. S3
- C. DynamoDB 
- D. IoT Button 
- E. Kinesis 

<details><summary>Answer:</summary><p>
CE

Explanation:

Event sources are mapped to Lambda functions

Event sources maintain the mapping configuration except for stream-based services (e.g. DynamoDB, Kinesis) for which the configuration is made on the Lambda side and Lambda performs the polling

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/networking-and-content-delivery/amazon-route-53/

</p></details><hr>

### Question 3:

In AWS Identity and Access Management (IAM) which principals can assume a role? (choose 2)

- A. Users 
- B. VPC
- C. Groups 
- D. AWS Services 

<details><summary>Answer:</summary><p>
AD

Explanation:

You can allow users and services to assume a role

Groups are collections of users and have policies attached to them

A group is not an identity and cannot be identified as a principal in an IAM policy

A VPC is not a principal

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/security-identity-compliance/aws-iam/

</p></details><hr>

### Question 4:

What service can you use to monitor, store and access log files generated by EC2 instances and on-premises servers?

- A. OpsWorks
- B. CloudTrail
- C. Kinesis
- D. CloudWatch Logs 

<details><summary>Answer:</summary><p>
D

Explanation:

You can use Amazon CloudWatch Logs to monitor, store, and access your log files from Amazon Elastic Compute Cloud (Amazon EC2) instances, AWS CloudTrail, Route 53, and other sources

You can then retrieve the associated log data from CloudWatch Logs

https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/WhatIsCloudWatchLogs.html

</p></details><hr>

### Question 5:

Your company are reviewing their information security processes. One of the items that came out of a recent audit is that there is insufficient data recorded about requests made to a few S3 buckets. The security team require an audit trail for operations on the S3 buckets that includes the requester, bucket name, request time, request action, and response status. Which action would you take to enable this logging?

- A. Enable server access logging for the S3 buckets to save access logs to a specified destination bucket 
- B. Enable S3 event notifications for the specific actions and setup an SNS notification
- C. Create a CloudWatch metric that monitors the S3 bucket operations and triggers an alarm
- D. Create a CloudTrail trail that audits S3 bucket operations

<details><summary>Answer:</summary><p>
A

Explanation:

For capturing IAM/user identity information in logs configure AWS CloudTrail Data Events (does not audit the bucket operations required in the question)

Amazon S3 event notifications can be sent in response to actions in Amazon S3 like PUTs, POSTs, COPYs, or DELETEs

Amazon S3 event notifications enable you to run workflows, send alerts, or perform other actions in response to changes in your objects stored in S3

Access auditing can be configured by configuring an Amazon S3 bucket to create access log records for all requests made against it

Each access log record provides details about a single access request, such as the requester, bucket name, request time, request action, response status, and an error code, if relevant

CloudWatch metrics do not include the bucket operations specified in the question

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/storage/amazon-s3/

https://docs.aws.amazon.com/AmazonS3/latest/dev/ServerLogs.html

</p></details><hr>

### Question 6:

An application hosted in your VPC uses an EC2 instance with a MySQL DB running on it. The database uses a single 1TB General Purpose SSD (GP2) EBS volume. Recently it has been noticed that the database is not performing well and you need to improve the read performance. What are two possible ways this can be achieved? (choose 2)

- A. Add an RDS read replica in another AZ
- B. Create an active/passive cluster using MySQL
- C. Use a provisioned IOPS volume and specify the number of I/O operations required 
- D. Add multiple EBS volumes in a RAID 1 array
- E. Add multiple EBS volumes in a RAID 0 array 

<details><summary>Answer:</summary><p>
CE

Explanation:

RAID 0 = 0 striping – data is written across multiple disks and increases performance but no redundancy

RAID 1 = 1 mirroring – creates 2 copies of the data but does not increase performance, only redundancy

SSD, Provisioned IOPS – I01 provides higher performance than General Purpose SSD (GP2) and you can specify the IOPS required up to 50 IOPS per GB and a maximum of 32000 IOPS

RDS read replicas cannot be created from EC2 instances

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/compute/amazon-ebs/

</p></details><hr>

### Question 7:

You have been asked to implement a solution for capturing, transforming and loading streaming data into an Amazon RedShift cluster. The solution will capture data from Amazon Kinesis Data Streams. Which AWS services would you utilize in this scenario? (choose 2)

- A. EMR for transforming the data 
- B. Kinesis Data Firehose for capturing the data and loading it into RedShift 
- C. Lambda for transforming the data 
- D. Kinesis Video Streams for capturing the data and loading it into RedShift

<details><summary>Answer:</summary><p>
BC

Explanation:

Kinesis Data Firehose is the easiest way to load streaming data into data stores and analytics tools

Captures, transforms, and loads streaming data

Enables near real-time analytics with existing business intelligence tools and dashboards

Firehose can invoke an AWS Lambda function to transform incoming data before delivering it to a destination

For Amazon Redshift destinations, streaming data is delivered to your S3 bucket first

Kinesis Data Firehose then issues an Amazon Redshift COPY command to load data from your S3 bucket to your Amazon Redshift cluster

If data transformation is enabled, you can optionally back up source data to another Amazon S3 bucket

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/analytics/amazon-kinesis/

</p></details><hr>

### Question 8:

Your company would like to restrict the ability of most users to change their own passwords whilst continuing to allow a select group of users within specific user groups. What is the best way to achieve this? (choose 2)

- A. Create an IAM Policy that grants users the ability to change their own password and attach it to the groups that contain the users 
- B. Disable the ability for all users to change their own passwords using the AWS Security Token Service
- C. Under the IAM Password Policy deselect the option to allow users to change their own passwords 
- D. Create an IAM Role that grants users the ability to change their own password and attach it to the groups that contain the users

<details><summary>Answer:</summary><p>
AC

Explanation:

A password policy can be defined for enforcing password length, complexity etc. (applies to all users)

You can allow or disallow the ability to change passwords using an IAM policy

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/security-identity-compliance/aws-iam/

</p></details><hr>

### Question 9:

Which of the statements below are correct about Elastic Block Store volumes? (choose 3)

- A. You can attach an EBS volume to multiple instances
- B. You can attach multiple EBS volumes to an instance 
- C. EBS volume data is replicated across multiple servers in an AZ 
- D. EBS volumes must be in the same AZ as the instances they are attached to 
- E. Root EBS volumes are retained on termination by default

<details><summary>Answer:</summary><p>
BCD

Explanation:

Corrections: You cannot attach an EBS volume to multiple instances Root EBS volumes are not retained on termination by default

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/compute/amazon-ebs/

</p></details><hr>

### Question 10:

Which of the statements below accurately describes the Amazon Elastic Map Reduce (EMR) service? (choose 2)

- A. EMR is a fully-managed service that makes it easy to set up and scale file storage in the Amazon Cloud
- B. EMR utilizes a hosted Hadoop framework running on Amazon EC2 and Amazon S3 
- C. EMR launches all nodes for a given cluster in the same Amazon EC2 Availability Zone 
- D. EMR makes it easy to securely stream video from connected devices to AWS for analytics, machine learning (ML), and other processing

<details><summary>Answer:</summary><p>
BC

Explanation:

Amazon EMR is a web service that enables businesses, researchers, data analysts, and developers to easily and cost-effectively process vast amounts of data

EMR utilizes a hosted Hadoop framework running on Amazon EC2 and Amazon S3

EMR uses Apache Hadoop as its distributed data processing engine which is an open source, Java software framework that supports data-intensive distributed applications running on large clusters of commodity hardware

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/analytics/amazon-emr/

</p></details><hr>

### Question 11:

You are a Solutions Architect at a media company and you need to build an application stack that can receive customer comments from sporting events. The application is expected to receive significant load that could scale to millions of messages within a short space of time following high-profile matches. As you are unsure of the load required for the database layer what is the most cost-effective way to ensure that the messages are not dropped?

- A. Use DynamoDB for the database layer which will automatically scale as required
- B. Write the data to an S3 bucket, configure RDS to poll the bucket for new messages
- C. Create an SQS queue and modify the application to write to the SQS queue. Launch another application instance the polls the queue and writes messages to the database 
- D. Use DynamoDB and provision enough write capacity to handle the highest expected load

<details><summary>Answer:</summary><p>
C

Explanation:

Amazon Simple Queue Service (Amazon SQS) is a web service that gives you access to message queues that store messages waiting to be processed

SQS offers a reliable, highly-scalable, hosted queue for storing messages in transit between computers

SQS is used for distributed/decoupled applications

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/application-integration/amazon-sqs/

</p></details><hr>

### Question 12:

With Amazon API Gateway what are features that assist with creating and managing APIs? (Choose 2)

- A. You can define the maintenance window or AWS will schedule a 30 minute window
- B. Flexible message delivery over multiple transport protocols
- C. You can define plans that meter and restrict third-party developer access to APIs 
- D. You can operate multiple API versions and multiple stages for each version simultaneously 

<details><summary>Answer:</summary><p>
CD

Explanation:

Metering – define plans that meter and restrict third-party developer access to APIs

Lifecycle Management – Operate multiple API versions and multiple stages for each version simultaneously so that existing applications can continue to call previous versions after new API versions are published

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/networking-and-content-delivery/amazon-api-gateway/

</p></details><hr>

### Question 13:

You are a Solutions Architect at Digital Cloud Guru. One of your clients runs an application that write data to a DynamoDB table. The client has asked how they can implement a function that runs code in response to item level changes that take place in the DynamoDB table. What would you suggest to the client?

- A. Enable DynamoDB Streams and create an event source mapping between AWS Lambda and the relevant stream 
- B. Enable server access logging and create an event source mapping between AWS Lambda and the S3 bucket to which the logs are written
- C. Use Kinesis Data Streams and configure DynamoDB as a producer
- D. Create a local secondary index that records item level changes and write some custom code that responds to updates to the index

<details><summary>Answer:</summary><p>
A

Explanation:

DynamoDB Streams help you to keep a list of item level changes or provide a list of item level changes that have taken place in the last 24hrs

Amazon DynamoDB is integrated with AWS Lambda so that you can create triggers—pieces of code that automatically respond to events in DynamoDB Streams

If you enable DynamoDB Streams on a table, you can associate the stream ARN with a Lambda function that you write

Immediately after an item in the table is modified, a new record appears in the table's stream

AWS Lambda polls the stream and invokes your Lambda function synchronously when it detects new stream records

An event source mapping identifies a poll-based event source for a Lambda function. It can be either an Amazon Kinesis or DynamoDB stream

AWS Lambda invokes the specified function when records are posted to the event source

Event sources maintain the mapping configuration except for stream-based services (e.g. DynamoDB, Kinesis) for which the configuration is made on the Lambda side and Lambda performs the polling

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/database/amazon-dynamodb/

https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Streams.Lambda.html

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/compute/aws-lambda/

</p></details><hr>

### Question 14:

The AWS Security Token Service (STS) is a web service that enables you to request temporary, limited-privilege credentials for IAM users or for users that you authenticate (federated users). Which of the below are supported sources for users? (choose 2)

- A. A local user on a user's PC 
- B. OpenID Connect 
- C. Another AWS account 
- D. EC2 instance

<details><summary>Answer:</summary><p>
BC

Explanation:

Federation can come from three sources: Federation (typically AD) Federation with Mobile Apps (e.g. Facebook, Amazon, Google or other Open ID providers) Cross account access (another AWS account)

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/security-identity-compliance/aws-iam/

</p></details><hr>

### Question 15:

A colleague has asked you some questions about how AWS charge for DynamoDB. He is interested to know what type of workload DynamoDB is best suited for in relation to cost and how you are charged? (choose 2)

- A. You provision for expected throughput but are only charged for what you use 
- B. DynamoDB is more cost effective for read heavy workloads 
- C. Priced based on provisioned throughput (read/write) regardless of whether you use it or not 
- D. DynamoDB is more cost effective for write heavy workloads

<details><summary>Answer:</summary><p>
BC

Explanation:

DynamoDB charges: DynamoDB is more cost effective for read heavy workloads Priced based on provisioned throughput (read/write) regardless of whether you use it or not Write throughput per hour for every 10 units Read throughput per hour for every 50 units Indexed data storage Internet data transfer (outside of a region)

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/database/amazon-dynamodb/

</p></details><hr>

### Question 16:

You are a Solutions Architect at Digital Cloud Guru. A client from a large multinational corporation is working on a deployment of a significant amount of resources into AWS. The client would like to be able to deploy resources across multiple AWS accounts and regions using a single toolset and template. You have been asked to suggest a toolset that can provide this functionality?

- A. Use a CloudFormation StackSet and specify the target accounts and regions in which the stacks will be created 
- B. Use a third-party product such as Terraform that has support for multiple AWS accounts and regions
- C. This cannot be done, use separate CloudFormation templates per AWS account and region
- D. Use a CloudFormation template that creates a stack and specify the logical IDs of each account and region

<details><summary>Answer:</summary><p>
A

Explanation:

AWS CloudFormation StackSets extends the functionality of stacks by enabling you to create, update, or delete stacks across multiple accounts and regions with a single operation

Using an administrator account, you define and manage an AWS CloudFormation template, and use the template as the basis for provisioning stacks into selected target accounts across specified regions

An administrator account is the AWS account in which you create stack sets

A stack set is managed by signing in to the AWS administrator account in which it was created

A target account is the account into which you create, update, or delete one or more stacks in your stack set

Before you can use a stack set to create stacks in a target account, you must set up a trust relationship between the administrator and target accounts

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/management-tools/aws-cloudformation/

https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/stacksets-concepts.html

</p></details><hr>

### Question 17:

An application running on an external website is attempting to initiate a request to your company’s website on AWS using API calls. A problem has been reported in which the requests are failing with an error that includes the following text: “Cross-Origin Request Blocked: The Same Origin Policy disallows reading the remote resource” You have been asked to resolve the problem, what is the most likely solution?

- A. The ACL on the API needs to be updated
- B. The request is not secured with SSL/TLS
- C. Enable CORS on the APIs resources using the selected methods under the API Gateway 
- D. The IAM policy does not allow access to the API

<details><summary>Answer:</summary><p>
C

Explanation:

Can enable Cross Origin Resource Sharing (CORS) for multiple domain use with Javascript/AJAX: Can be used to enable requests from domains other the APIs domain Allows the sharing of resources between different domains The method (GET, PUT, POST etc) for which you will enable CORS must be available in the API Gateway API before you enable CORS If CORS is not enabled and an API resource received requests from another domain the request will be blocked Enable CORS on the APIs resources using the selected methods under the API Gateway

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/networking-and-content-delivery/amazon-api-gateway/

</p></details><hr>

### Question 18:

Which of the statements below is correct in relation to Amazon VPC routing? (choose 3)

- A. Can assign one route table to multiple subnets 
- B. The VPC router performs routing between AZs within a region 
- C. If no route table is specified a subnet will be assigned to the main route table at creation time 
- D. A subnet can be associated with multiple route tables
- E. You cannot modify which route table is the default route table

<details><summary>Answer:</summary><p>
ABC

Explanation:

The VPC router performs routing between AZs within a region

The VPC router connects different AZs together and connects the VPC to the Internet Gateway

Each subnet has a route table the router uses to forward traffic within the VPC

Route tables also have entries to external destinations

Each subnet can only be associated with one route table

Can assign one route table to multiple subnets

If no route table is specified a subnet will be assigned to the main route table at creation time

Cannot delete the main route table

You can manually set another route table to become the main route table

There is a default rule that allows all VPC subnets to communicate with one another – this cannot be deleted or modified

Routing between subnets is always possible because of this rule – any problems communicating is more likely to be security groups or NACLs

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/networking-and-content-delivery/amazon-vpc/

</p></details><hr>

### Question 19:

You are a Solutions Architect at Digital Cloud Guru. One of your clients has requested that you design a solution for distributing load across a number of EC2 instances across multiple AZs within a region. Customers will connect to several different applications running the client’s servers through their browser using multiple domain names and SSL certificates. The certificates are stored in AWS Certificate Manager (ACM). What is the optimal architecture to ensure high availability, cost effectiveness, and performance?

- A. Launch a single ALB and bind multiple SSL certificates to the same secure listener. Clients will use the Server Name Indication (SNI) extension 
- B. Launch a single ALB and bind multiple SSL certificates to multiple secure listeners
- C. Launch a single ALB, configure host-based routing for the domain names and bind an SSL certificate to each routing rule
- D. Launch multiple ALBs and bind separate SSL certificates to each ELB 

<details><summary>Answer:</summary><p>
A

Explanation:

Cannot have the same port in multiple listeners

Server Name Indication (SNI) supports multiple secure websites using a single secure listener

With Server Name Indication (SNI) a client indicates the hostname to connect to

Host-based routing – route client requests based on the Host field of the HTTP header allowing you to route to multiple domains from the same load balancer

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/compute/elastic-load-balancing/

</p></details><hr>

### Question 20:

You are building an application that will collect information about user behavior. The application will rapidly ingest large amounts of dynamic data and requires very low latency. The database must be scalable without incurring downtime. Which database would you recommend for this scenario?

- A. RDS with MySQL
- B. RDS with Microsoft SQL
- C. DynamoDB 
- D. RedShift

<details><summary>Answer:</summary><p>
C

Explanation:

Amazon Dynamo DB is a fully managed NoSQL database service that provides fast and predictable performance with seamless scalability

Push button scaling means that you can scale the DB at any time without incurring downtime

DynamoDB provides low read and write latency

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/database/amazon-dynamodb/

</p></details><hr>

### Question 21:

As a SysOps engineer working at Digital Cloud Guru, you are constantly trying to improve your processes for collecting log data. Currently you are collecting logs from across your AWS resources using CloudWatch and a combination of standard and custom metrics. You are currently investigating how you can optimize the storage of log files collected by CloudWatch. Which of the following are valid options for storing CloudWatch log files? (choose 2)

- A. CloudWatch Logs 
- B. Splunk 
- C. EFS
- D. EBS

<details><summary>Answer:</summary><p>
AB

Explanation:

Options for storing logs: CloudWatch Logs Centralized logging system (e.g. Splunk) Custom script and store on S3

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/management-tools/amazon-cloudwatch/

</p></details><hr>

### Question 22:

You have created a new custom security group. Which of the below statements is correct in relation to the default rules that will be created? (choose 2)

- A. No outbound traffic is allowed by default
- B. Inbound traffic is allowed from instances assigned to the group
- C. No inbound traffic is allowed by default 
- D. All outbound traffic is allowed by default 

<details><summary>Answer:</summary><p>
CD

Explanation:

Custom security groups do not have inbound allow rules (all inbound traffic is denied by default)

Default security groups do have inbound allow rules (allowing traffic from within the group)

All outbound traffic is allowed by default in custom and default security groups

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/networking-and-content-delivery/amazon-vpc/

</p></details><hr>

### Question 23:

You are undertaking a project to make some audio and video files that your company uses for onboarding new staff members available via a mobile application. You are looking for a cost-effective way to convert the files from their current formats into formats that are compatible with smartphones and tablets. The files are currently stored in an S3 bucket. What AWS service can help with converting the files?

- A. MediaConvert
- B. Rekognition
- C. Data Pipeline
- D. Elastic Transcoder 

<details><summary>Answer:</summary><p>
D

Explanation:

Amazon Elastic Transcoder is a highly scalable, easy to use and cost-effective way for developers and businesses to convert (or “transcode”) video and audio files from their source format into versions that will playback on devices like smartphones, tablets and PCs

MediaConvert converts file-based content for broadcast and multi-screen delivery

Data Pipeline helps you move, integrate, and process data across AWS compute and storage resources, as well as your on-premises resources

Rekognition is a deep learning-based visual analysis service

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/media-services/amazon-elastic-transcoder/

</p></details><hr>

### Question 24:

The company you work for is currently transitioning their infrastructure and applications into the AWS cloud. You are planning to deploy an Elastic Load Balancer (ELB) that distributes traffic for a web application running on EC2 instances. You still have some application servers running on-premise and you would like to distribute application traffic across both your AWS and on-premises resources. How can this be achieved?

- A. Provision a Direct Connect connection between your on-premises location and AWS and create a target group on an ALB to use IP based targets for both your EC2 instances and on-premises servers 
- B. Provision a Direct Connect connection between your on-premises location and AWS and create a target group on an ALB to use Instance ID based targets for both your EC2 instances and on-premises server
- C. Provision an IPSec VPN connection between your on-premises location and AWS and create a CLB that uses cross-zone load balancing to distributed traffic across EC2 instances and on-premises servers
- D. This cannot be done, ELBs are an AWS service and can only distributed traffic within the AWS cloud 

<details><summary>Answer:</summary><p>
A

Explanation:

ALB supports IP addresses as targets

IP addresses as targets allows load balancing any application hosted in AWS or on-premises using IP addresses of the application back-ends as targets

Requires a VPN or Direct Connect connection

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/compute/elastic-load-balancing/

https://aws.amazon.com/blogs/aws/new-application-load-balancing-via-ip-address-to-aws-on-premises-resources/

</p></details><hr>

### Question 25:

A colleague from your company’s IT Security team has notified you of an Internet-based threat that affects a certain port and protocol combination. You have conducted an audit of your VPC and found that this port and protocol combination is allowed on an Inbound Rule with a source of 0.0.0.0/0. You have verified that this rule only exists for maintenance purposes and need to make an urgent change to block the access. What is the fastest way to block access from the Internet to the specific ports and protocols?

- A. You don’t need to do anything; this rule will only allow access to VPC based resources
- B. Add a deny rule to the security group with a higher priority
- C. Delete the security group
- D. Update the security group by removing the rule 

<details><summary>Answer:</summary><p>
D

Explanation:

Security group membership can be changed whilst instances are running

Any changes to security groups will take effect immediately

You can only assign permit rules in a security group, cannot assign deny rules

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/networking-and-content-delivery/amazon-vpc/

</p></details><hr>

### Question 26:

When using a multi-node configuration in RedShift, what is the role of a leader node? (choose 2)

- A. Manages client connections and receives queries 
- B. Stores data and performs queries and computations
- C. Coordinates query execution 
- D. Parallel/distributed execution of all queries, loads, backups, restores, resizes

<details><summary>Answer:</summary><p>
AC

Explanation:

Leader node:

- Manages client connections and receives queries

- Simple SQL end-point

- Stores metadata

- Optimizes query plan

- Coordinates query execution

Compute nodes:

- Stores data and performs queries and computations

- Local columnar storage

- Parallel/distributed execution of all queries, loads, backups, restores, resizes

- Up to 128 compute nodes

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/database/amazon-redshift/

</p></details><hr>

### Question 27:

The application development team in your company have a new requirement for the deployment of a container solution. You plan to the use the AWS Elastic Container Service (ECS). The solution should include load balancing of incoming requests across the ECS containers and allow the containers to use dynamic host port mapping so that multiple tasks from the same service can run on the same container host. Which AWS load balancing configuration will support this?

- A. Use an Application Load Balancer (ALB) and map the ECS service to the ALB 
- B. Use a Classic Load Balancer (CLB) and create a static mapping of the ports
- C. Use a Network Load Balancer (NLB) and host-based routing
- D. You cannot run multiple copies of a task on the same instance, because the ports would conflict

<details><summary>Answer:</summary><p>
A

Explanation:

It is possible to associate a service on Amazon ECS to an Application Load Balancer (ALB) for the Elastic Load Balancing (ELB) service

ALB allows containers to use dynamic host port mapping so that multiple tasks from the same service are allowed on the same container host

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/compute/amazon-ecs/

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/compute/elastic-load-balancing/

</p></details><hr>

### Question 28:

Which AWS services are suitable for storing session state data? (choose 2)

- A. RedShift
- B. CloudFront
- C. DynamoDB 
- D. ElastiCache 
- E. RDS

<details><summary>Answer:</summary><p>
CD

Explanation:

From the options available only DynamoDB and ElastiCache are good for storing session state data

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/database/amazon-elasticache/

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/database/amazon-dynamodb/

</p></details><hr>

### Question 29:

Your company is starting to use AWS to host new web-based applications. A new two-tier application will be deployed that provides customers with access to data records. It is important that the application is highly responsive and retrieval times are optimized. You’re looking for a persistent data store that can provide the required performance. From the list below what AWS service would you recommend for this requirement?

- A. RDS in a multi-AZ configuration 
- B. ElastiCache with the Redis engine 
- C. ElastiCache with the Memcached engine
- D. Kinesis Data Streams

<details><summary>Answer:</summary><p>
B

Explanation:

ElastiCache is a web service that makes it easy to deploy and run Memcached or Redis protocol-compliant server nodes in the cloud

The in-memory caching provided by ElastiCache can be used to significantly improve latency and throughput for many read-heavy application workloads or compute-intensive workloads

Memcached

- Not persistent

- Cannot be used as a data store

- Supports large nodes with multiple cores or threads

- Scales out and in, by adding and removing nodes

Redis

- Data is persistent

- Can be used as a datastore

- Not multi-threaded

- Scales by adding shards, not nodes

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/database/amazon-elasticache/

</p></details><hr>

### Question 30:

You would like to share some documents with public users accessing an S3 bucket over the Internet. What are two valid methods of granting public read permissions so you can share the documents? (choose 2)

- A. Grant public read on all objects using the S3 bucket ACL
- B. Share the documents using CloudFront and a static website 
- C. Use the AWS Policy Generator to create a bucket policy for your Amazon S3 bucket granting read access to public anonymous users 
- D. Grant public read access to the objects when uploading 

<details><summary>Answer:</summary><p>
CD

Explanation:

Access policies define access to resources and can be associated with resources (buckets and objects) and users

You can use the AWS Policy Generator to create a bucket policy for your Amazon S3 bucket

You can define permissions on objects when uploading and at any time afterwards using the AWS Management Console

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/storage/amazon-s3/

</p></details><hr>

### Question 31:

You have an EC2 instance that has an EBS-backed root volume. You have attached a couple of Instance Store-backed volumes which have some important log files on them. What will happen to the data if the instance is stopped?

- A. The data will be accessible
- B. You cannot stop and EC2 instance with instance store volumes attached 
- C. The data will be lost 
- D. The data is automatically saved as an EBS snapshot

<details><summary>Answer:</summary><p>
C

Explanation:

Instance store volumes are sometimes called Ephemeral storage (non-persistent)

Instance store volumes cannot be stopped. If the underlying host fails the data will be lost

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/compute/amazon-ebs/

</p></details><hr>

### Question 32:

Which of the statements below best describes the Elastic Load Balancer service?

- A. Helps you ensure that you have the correct number of Amazon EC2 instances available to handle the load for your application
- B. A network service that provides an alternative to using the Internet to connect customers’ on-premise sites to AWS
- C. Automatically distributes incoming application traffic across multiple targets, such as Amazon EC2 instances, containers, and IP addresses 
- D. A highly available and scalable Domain Name System (DNS) service

<details><summary>Answer:</summary><p>
C

Explanation:

Elastic Load Balancing automatically distributes incoming application traffic across multiple targets, such as Amazon EC2 instances, containers, and IP addresses

Elastic Load Balancing provides fault tolerance for applications by automatically balancing traffic across targets – Amazon EC2 instances, containers and IP addresses – and Availability Zones while ensuring only healthy targets receive traffic

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/compute/elastic-load-balancing/

</p></details><hr>

### Question 33:

An application that was recently moved into the AWS cloud has been experiencing some authentication issues. The application is currently configured to authenticate to an on-premise Microsoft Active Directory Domain Controller via a VPN connection. Upon troubleshooting the issues, it seems that latency across the VPN connection is causing authentication to fail. Your company is very cost sensitive at the moment and the administrators of the Microsoft AD do not want to manage any additional directories. You need to resolve the issues quickly. What is the best solution to solve the authentication issues taking cost considerations into account?

- A. Use the AWS Active Directory Service for Microsoft Active Directory and create a new domain. Establish a trust relationship with your existing on-premise domain
- B. Use the AWS Active Directory Service for Microsoft Active Directory and join your existing on-premise domain 
- C. Install an additional Microsoft Active Directory Domain Controller for your existing domain on EC2 and configure the application to authenticate to the local DC 
- D. Create an AWS Direct Connect connection to reduce the latency between your company and AWS

<details><summary>Answer:</summary><p>
C

Explanation:

As an alternative to the AWS Directory service you can build your own Microsoft AD DCs in the AWS cloud (on EC2): When you build your own you can join an existing on-premise Active Directory domain (replication mode) Must establish a VPN (on top of Direct Connect if you have it) Replication mode is less secure than establishing trust relationships

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/security-identity-compliance/aws-iam/

</p></details><hr>

### Question 34:

The data scientists in your company are looking for a service that can process and analyze real-time, streaming data. They would like to use standard SQL queries to query the streaming data. Which combination of AWS services would deliver these requirements?

- A. ElastiCache and EMR
- B. Kinesis Data Streams and Kinesis Data Analytics 
- C. Kinesis Data Streams and Kinesis Firehose
- D. DynamoDB and EMR

<details><summary>Answer:</summary><p>
B

Explanation:

Kinesis Data Streams enables you to build custom applications that process or analyze streaming data for specialized needs

Amazon Kinesis Data Analytics is the easiest way to process and analyze real-time, streaming data

Kinesis Data Analytics can use standard SQL queries to process Kinesis data streams

Kinesis Data Analytics can ingest data from Kinesis Streams and Kinesis Firehose

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/analytics/amazon-kinesis/

</p></details><hr>

### Question 35:

Several websites you run on AWS use multiple Internet-facing Elastic Load Balancers (ELB) to distribute incoming connections to EC2 instances running web applications. The ELBs are configured to forward using either TCP (layer 4) or HTTP (layer 7) protocols. You would like to start recording the IP addresses of the clients that connect to your web applications. Which ELB features will you implement with which protocols? (choose 2)

- A. X-Forwarded-For request header and HTTP 
- B. Proxy Protocol and TCP 
- C. X-Forwarded-For request header and TCP
- D. Proxy Protocol and HTTP

<details><summary>Answer:</summary><p>
AB

Explanation:

Proxy protocol for TCP/SSL carries the source (client) IP/port information

X-forwarded-for for HTTP/HTTPS carries the source IP/port information

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/compute/elastic-load-balancing/

</p></details><hr>

### Question 36:

Your client is looking for fully managed directory service in the AWS cloud. The service should provide an inexpensive Active Directory-compatible service with common directory features. The client is a medium sized organization with 4000 users. As the client has a very limited budget it is important to select a cost-effective solution. What would you suggest?

- A. Amazon Cognito
- B. AWS Simple AD 
- C. AWS Single Sign-On
- D. AWS Active Directory Service for Microsoft Active Directory

<details><summary>Answer:</summary><p>
B

Explanation:

Active Directory Service for Microsoft Active Directory is the best choice if you have more than 5000 users and/or need a trust relationship set up

Simple AD:

- An inexpensive Active Directory-compatible service with common directory features

- Standalone, fully managed, directory on the AWS cloud

- Simple AD is generally the least expensive option

- Best choice for less than 50000 users and don’t need advanced AD features

Amazon Cognito is an authentication service for web and mobile apps

AWS Single Sign-On (SSO) is a cloud SSO service that makes it easy to centrally manage SSO access to multiple AWS accounts and business applications

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/security-identity-compliance/aws-directory-service/

</p></details><hr>

### Question 37:

Your company has offices in several locations around the world. Each office utilizes resources deployed in the geographically closest AWS region. You would like to implement connectivity between all of the VPCs so that you can provide full access to each other’s resources. As you are security conscious you would like to ensure the traffic is encrypted and does not traverse the public Internet. The topology should be many-to-many to enable all VPCs to access the resources in all other VPCs. How can you successfully implement this connectivity using only AWS services? (choose 2)

- A. Implement a fully meshed architecture 
- B. Use software VPN appliances running on EC2 instances
- C. Implement a hub and spoke architecture
- D. Use inter-region VPC peering 

<details><summary>Answer:</summary><p>
AD

Explanation:

Peering connections can be created with VPCs in different regions (available in most regions now)

Data sent between VPCs in different regions is encrypted (traffic charges apply)

Cannot do transitive peering (establish a mesh)

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/networking-and-content-delivery/amazon-vpc/

</p></details><hr>

### Question 38:

You would like to provide some on-demand and live streaming video to your customers. The plan is to provide the users with both the media player and the media files from the AWS cloud. One of the features you need is for the content of the media files to begin playing while the file is still being downloaded. What AWS services can deliver these requirements? (choose 2)

- A. Use CloudFront with a Web and RTMP distribution 
- B. Use CloudFront with an RTMP distribution
- C. Store the media files in an S3 bucket 
- D. Store the media files on an EC2 instance

<details><summary>Answer:</summary><p>
AC

Explanation:

For serving both the media player and media files you need two types of distributions:

- A web distribution for the media player

- An RTMP distribution for the media files

RTMP:

- Distribute streaming media files using Adobe Flash Media Server’s RTMP protocol

- Allows an end user to begin playing a media file before the file has finished downloading from a CloudFront edge location

- Files must be stored in an S3 bucket

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/networking-and-content-delivery/amazon-cloudfront/

</p></details><hr>

### Question 39:

Which Route 53 record type can be used to point a domain’s zone apex at an Elastic Load Balancer?

- A. A Route 53 CNAME record
- B. An AAAA record
- C. A Route 53 Alias record 
- D. An A record

<details><summary>Answer:</summary><p>
C

Explanation:

The Alias record is a Route 53 specific record type

Alias records are used to map resource record sets in your hosted zone to Amazon Elastic Load Balancing load balancers, Amazon CloudFront distributions, AWS Elastic Beanstalk environments, or Amazon S3 buckets that are configured as websites

An Alias record can be used for resolving apex or naked domain names (e.g. example.com)

A CNAME record can’t be used for resolving apex or naked domain names

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/networking-and-content-delivery/amazon-route-53/

</p></details><hr>

### Question 40:

When using Amazon RedShift, what of the following statements are correct in relation to availability and durability? (choose 3)

- A. Single-node clusters support data replication
- B. Manual backups are automatically deleted when you delete a cluster
- C. RedShift always keeps three copies of your data 
- D. RedShift provides continuous/incremental backups 
- E. RedShift provides fault tolerance for disk, node, and network failures 

<details><summary>Answer:</summary><p>
CDE

Explanation:

Corrections: Single-node clusters do not support data replication Manual backups are not automatically deleted when you delete a cluster

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/database/amazon-redshift/

</p></details><hr>

### Question 41:

You are an entrepreneur building a small company with some resources running on AWS. As you have limited funding you are extremely cost conscious. What AWS service can help you to ensure your costs do not exceed your funding capacity and send you alerts via email or SNS topic?

- A. AWS Billing Dashboard 
- B. Cost & Usage reports
- C. Cost Explorer
- D. AWS Budgets 

<details><summary>Answer:</summary><p>
D

Explanation:

AWS Budgets gives you the ability to set custom budgets that alert you when your costs or usage exceed (or are forecasted to exceed) your budgeted amount

Budget alerts can be sent via email and/or Amazon Simple Notification Service (SNS) topic

https://aws.amazon.com/aws-cost-management/aws-budgets/

</p></details><hr>

### Question 42:

You work for a company that produces TV commercials. You are planning to run an advertising campaign during a major political event that will be watched by millions of people over several days. It is expected that your website will receive large bursts of traffic following commercial breaks. You have performed an analysis and determined that you will need around 150 EC2 web instances to process the traffic You need to ensure you deliver a high quality and consistent user experience and to also consider cost-effectiveness. How would you design a highly available and elastic?

- A. Create an Auto Scaling Group across multiple AZs with a maximum capacity of 150 EC2 instances. Launch an Application Load Balancer and specify the same AZs as the ASG and pre-warm the ALB by contacting AWS prior to the event 
- B. Create an Auto Scaling Group across multiple AZs with a maximum capacity of 150 EC2 instances. Launch an Application Load Balancer and specify the same AZs as the ASG
- C. Create an Auto Scaling Group across multiple AZs with a desired capacity of 150 EC2 instances. Launch an Application Load Balancer and specify the same AZs as the ASG and pre-warm the ALB by contacting AWS prior to the event 
- D. Create an Auto Scaling Group across multiple AZs with a desired capacity of 150 EC2 instances. Launch an Application Load Balancer and specify the same AZs as the ASG and pre-warm the ALB by contacting AWS prior to the event and pre-warm the ALB by contacting AWS prior to the event

<details><summary>Answer:</summary><p>
A

Explanation:

Simple scaling maintains a current number of instances, you can manually change the ASGs min/desired/max and attach/detach instances

Auto Scaling will try to distribute EC2 instances evenly across AZs

If you’re anticipating a fast increase in load you can contact AWS and instruct them to pre-warm (provision) additional ELB nodes

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/compute/aws-auto-scaling/

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/compute/elastic-load-balancing/

</p></details><hr>

### Question 43:

You are planning to launch a RedShift cluster for processing and analyzing a large amount of data. The RedShift cluster will be deployed into a VPC with multiple subnets. Which construct is used when provisioning the cluster to allow you to specify a set of subnets in the VPC that the cluster will be deployed into?

- A. DB Subnet Group
- B. Subnet Group
- C. Availability Zone (AZ)
- D. Cluster Subnet Group 

<details><summary>Answer:</summary><p>
D

Explanation:

You create a cluster subnet group if you are provisioning your cluster in your virtual private cloud (VPC)

A cluster subnet group allows you to specify a set of subnets in your VPC

When provisioning a cluster you provide the subnet group and Amazon Redshift creates the cluster on one of the subnets in the group

A DB Subnet Group is used by RDS

A Subnet Group is used by ElastiCache

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/database/amazon-redshift/

https://docs.aws.amazon.com/redshift/latest/mgmt/working-with-cluster-subnet-groups.html

</p></details><hr>

### Question 44:

Which of the following are characteristics of an EC2 Reserved Instance (RI)? (Choose 3)

- A. There is a fee charged for any RI modifications
- B. You can launch RIs using Auto Scaling Groups 
- C. RIs can be sold on the Reserved Instance Marketplace 
- D. You can use RIs in Placement Groups 
- E. You can change the region with Convertible RIs

<details><summary>Answer:</summary><p>
BCD

Explanation:

Capacity is reserved for a term of 1 or 3 years

Standard = commitment of 1 or 3 years, charged whether it's on or off

Scheduled = reserved for specific periods of time, accrue charges hourly, billed in monthly increments over the term (1 year)

Scheduled RIs match your capacity reservation to a predictable recurring schedule

RIs are used for steady state workloads and predictable usage

Ideal for applications that need reserved capacity

Upfront payments can reduce the hourly rate

Can switch AZ within the same region

Can change the instance size within the same instance type

Instance type modifications are supported for Linux only

Cannot change the instance size of Windows RIs

Billed whether running or not

Can sell reservations on the AWS marketplace

Can be used in Auto Scaling Groups

Can be used in Placement Groups

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/compute/amazon-ec2/

</p></details><hr>

### Question 45:

A new Big Data application you are developing will use hundreds of EC2 instances to write data to a shared file system. The file system must be stored redundantly across multiple AZs within a region and allow the EC2 instances to concurrently access the file system. The required throughput is multiple GB per second. From the options presented which storage solution can deliver these requirements?

- A. Amazon Storage Gateway
- B. Amazon S3
- C. Amazon EBS using multiple volumes in a RAID 0 configuration
- D. Amazon EFS 

<details><summary>Answer:</summary><p>
D

Explanation:

EFS:

- EFS is elastic and grows and shrinks as you add and remove data

- Can concurrently connect 1 to 1000s of EC2 instances, from multiple AZs

- A file system can be accessed concurrently from all AZs in the region where it is located

- Throughput can be 10+ GB per second

EBS volumes cannot be accessed by multiple instances

S3 is an object store, not a file system and does not store data across multiple AZs (S3 is stored across multiple facilities in the region)

Storage Gateway is used for on-premises storage management

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/storage/amazon-efs/

</p></details><hr>

### Question 46:

Which of the statements below are correct about CloudWatch instance monitoring when using an Auto Scaling Group (ASG)? (choose 2)

- A. Detailed monitoring is chargeable and must always be manually enabled 
- B. Basic monitoring is enabled by default if the ASG is created from the CLI
- C. Detailed monitoring is enabled by default if the ASG is created from the CLI 
- D. Basic monitoring is enabled by default if the ASG is created from the console 

<details><summary>Answer:</summary><p>
CD

Explanation:

Basic monitoring sends EC2 metrics to CloudWatch about ASG instances every 5 minutes

Detailed can be enabled and sends metrics every 1 minute (chargeable)

When the launch configuration is created from the CLI detailed monitoring of EC2 instances is enabled by default

When you enable Auto Scaling group metrics, Auto Scaling sends sampled data to CloudWatch every minute

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/compute/aws-auto-scaling/

</p></details><hr>

### Question 47:

Your company has recently formed a partnership with another company. Both companies have resources running in the AWS cloud and you would like to be able to access each other’s resources using private IP addresses. The resources for each company are in different AWS regions and you need to ensure that fully redundant connectivity is established. What steps would you take to establish connectivity and resource sharing between the VPCs across regions? (choose 3)

- A. Manually add routes to each VPCs routing tables as required to enable IP connectivity 
- B. Establish redundant Direct Connect connections between the VPCs 
- C. Update Security Group rules to allow resource sharing 
- D. Establish a VPC peering connection between the VPCs 
- E. Establish dynamic routing with BGP and BFD

<details><summary>Answer:</summary><p>
ACD

Explanation:

Peering connections can be created with VPCs in different regions (available in most regions now)

Data sent between VPCs in different regions is encrypted (traffic charges apply)

Must update route tables to configure routing

Must update the inbound and outbound rules for VPC security group to reference security groups in the peered VPC

When creating a VPC peering connection with another account you need to enter the account ID and VPC ID from the other account

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/networking-and-content-delivery/amazon-vpc/

</p></details><hr>

### Question 48:

You are designing an identity, authorization and access management solution for the AWS cloud. The features you need include the ability to manage user accounts and group memberships, create and apply group policies, securely connect to Amazon EC2 instances, and provide Kerberos-based single sign-on (SSO). You do not need to establish trust relationships with other domains, use DNS dynamic update, implement schema extensions or use other advanced directory features. What would be the most cost-effective solution?

- A. Use AWS Directory Service for Microsoft AD
- B. Use Amazon Cloud Directory
- C. Use AWS Simple AD 
- D. Use AD Connector

<details><summary>Answer:</summary><p>
C

Explanation:

An inexpensive Active Directory-compatible service with common directory features

Standalone, fully managed, directory on the AWS cloud

Simple AD is generally the least expensive option

Best choice for less than 50000 users and don’t need advanced AD features

Powered by SAMBA 4 Active Directory compatible server

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/security-identity-compliance/aws-directory-service/

</p></details><hr>

### Question 49:

A customer has asked you to recommend the best solution for a highly available database. The database be an OLTP type of database and the customer does not want to manage the operating system the database runs on. Failover between AZs must be automatic. Which of the below options would you suggest to the customer?

- A. Install a relational database on EC2 instances in multiple AZs and create a cluster
- B. Use RDS in a Multi-AZ configuration 
- C. Use DynamoDB
- D. Use RedShift in a Multi-AZ configuration

<details><summary>Answer:</summary><p>
B

Explanation:

Amazon Relational Database Service (Amazon RDS) is a managed service that makes it easy to set up, operate, and scale a relational database in the cloud

Multi-AZ RDS creates a replica in another AZ and synchronously replicates to it (DR only)

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/compute/aws-auto-scaling/

</p></details><hr>

### Question 50:

For operational access to your AWS environment you are planning to setup a bastion host implementation. Which of the below are AWS best practices for setting up bastion hosts? (choose 3)

- A. An Auto Scaling group ensures that the number of bastion host instances always matches the desired capacity you specify during launch 
- B. Linux bastion hosts are deployed in two Availability Zones to support immediate access across the VPC 
- C. Elastic IP addresses are associated with the bastion instances to make it easier to remember and allow these IP addresses from on-premises firewalls 
- D. Access to the bastion hosts is configured to 0.0.0.0/0 for ingress in security groups
- E. Bastion hosts are deployed in the private subnets of the VPC
- F. Ports are unrestricted to allow full operational access to the bastion hosts

<details><summary>Answer:</summary><p>
ABC

Explanation:

You can configure EC2 instances as bastion hosts (aka jump boxes) in order to access your VPC instances for management

Can use the SSH or RDP protocols

Need to configure a security group with the relevant permissions

Can use auto-assigned public IPs or Elastic IPs

Can use security groups to restrict the IP addresses/CIDRs that can access the bastion host

Use auto-scaling groups for HA (set to 1 to just replace)

Best practice is to deploy Linux bastion hosts in two AZs, use auto-scaling and Elastic IP

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/compute/amazon-ec2/

</p></details><hr>

### Question 51:

Which of the statements below are correct in relation to CloudFront Regional Edge Caches? (choose 2)

- A. Regional Edge Caches are read-only
- B. Regional Edge Caches have larger cache-width than any individual edge location, so your objects remain in cache longer at these locations 
- C. Regional Edge Caches are enabled by default for CloudFront Distributions 
- D. There are additional charges for using Regional Edge Caches 

<details><summary>Answer:</summary><p>
BC

Explanation:

There are no additional charges for using Regional Edge Caches

You can write to regional edge caches too

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/networking-and-content-delivery/amazon-cloudfront/

https://aws.amazon.com/about-aws/whats-new/2016/11/announcing-regional-edge-caches-for-amazon-cloudfront/

</p></details><hr>

### Question 52:

One of your EC2 instances runs an application process that saves user data to an attached EBS volume. The EBS volume was attached to the EC2 instance after it was launched and is unencrypted. You would like to encrypt the data that is stored on the volume as it is considered sensitive however you cannot shutdown the instance due to other application processes that are running. What is the best method of applying encryption to the sensitive data without any downtime?

- A. Leverage the AWS Encryption CLI to encrypt the data on the volume
- B. Create and mount a new encrypted EBS volume. Move the data to the new volume and then delete the old volume 
- C. Create an encrypted snapshot of the current EBS volume. Restore the snapshot to the EBS volume
- D. Unmount the volume and enable server-side encryption. Re-mount the EBS volume

<details><summary>Answer:</summary><p>
B

Explanation:

You cannot restore a snapshot of a root volume without downtime

There is no direct way to change the encryption state of a volume

Either create an encrypted volume and copy data to it or take a snapshot, encrypt it, and create a new encrypted volume from the snapshot

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/compute/amazon-ebs/

</p></details><hr>

### Question 53:

Which of the following can you use to securely connect to an EC2 instance running Linux?

- A. Key pairs 
- B. SSL/TLS certificate
- C. Public key
- D. EC2 password

<details><summary>Answer:</summary><p>
A

Explanation:

A key pair consists of a public key that AWS stores, and a private key file that you store

For Windows AMIs, the private key file is required to obtain the password used to log into your instance

For Linux AMIs, the private key file allows you to securely SSH into your instance

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/compute/amazon-ec2/

</p></details><hr>

### Question 54:

Which of the following statements are correct about Amazon Simple Queue Service (SQS)? (choose 3)

- A. The maximum messages size is 512KB 
- B. Scaling is performed by adding more instances
- C. You can use IAM policies to control who can read/write messages 
- D. Messages can be kept in the queue from 1 minute to 4 days
- E. SQS is pull based (polling) not push based 
- F. CloudWatch metrics are automatically collected every 5 minutes 

<details><summary>Answer:</summary><p>
CEF

Explanation:

Corrections: Messages can be kept in the queue from 1 minute to 14 days (default is 4 days) The maximum messages size is 256KB Scaling is performed by creating more queues

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/application-integration/amazon-sqs/

</p></details><hr>

### Question 55:

Your company uses Amazon Glacier to store files that must be retained for compliance reasons and are rarely accessed. An auditor has requested access to some information that is stored in a Glacier archive. You have initiated an archive retrieval job. Which factors are important to know about the process from this point? (choose 2)

- A. The retrieved data will always be encrypted
- B. There is a charge if you delete data within 90 days
- C. Following retrieval, you have 24 hours to download your data 
- D. Amazon Glacier must complete a job before you can get its output 

<details><summary>Answer:</summary><p>
CD

Explanation:

There is a charge if you delete data within 90 days – however we are not talking about deleting data here, just retrieving it

Retrieved data is available for 24 hours by default (can be changed)

Amazon Glacier must complete a job before you can get its output

Glacier automatically encrypts data at rest using AES 256 symmetric keys and supports secure transfer of data over SSL

Retrieved data will not be encrypted if it was uploaded unencrypted

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/storage/amazon-s3/

</p></details><hr>

### Question 56:

You are creating a design for a web-based application that will be based on a web front-end based on EC2 instances and a database back-end. This application is a low priority and you do not want to incur costs in general day to day management. What AWS database service can you use that will require the least operational overhead?

- A. EMR
- B. RDS
- C. DynamoDB 
- D. RedShift

<details><summary>Answer:</summary><p>
C

Explanation:

Out of the options in the list, DynamoDB requires the least operational overhead as there are no backups, maintenance period, software updates etc. to deal with

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/database/amazon-dynamodb/

</p></details><hr>

### Question 57:

The company you work for has a presence across multiple AWS regions. As part of disaster recovery planning you are formulating a solution to provide a regional DR capability for an application running on a fleet of Amazon EC2 instances that are provisioned by an Auto Scaling Group (ASG). The applications are stateless and read and write data to an S3 bucket. You would like to utilize the current AMI used by the ASG as it has some customizations made to it. What are three steps you might take to enable a regional DR capability for this application? (choose 3)

- A. Modify the permissions of the AMI so it can be used across multiple regions
- B. Copy the AMI to the to the DR region 
- C. Modify the launch configuration for the ASG in the DR region and specify the AMI
- D. Enable multi-AZ for the S3 bucket to enable synchronous replication to the DR region
- E. Create a new launch configuration for the ASG in the DR region that uses the AMI 
- F. Enable cross region replication on the S3 bucket and specify a destination bucket in the DR region 

<details><summary>Answer:</summary><p>
BEF

Explanation:

CRR is an Amazon S3 feature that automatically replicates data across AWS Regions

With CRR, every object uploaded to an S3 bucket is automatically replicated to a destination bucket in a different AWS Region that you choose

AMIs that are backed by EBS snapshots can be copied between regions

You cannot modify an ASG launch configuration, you must create a new launch configuration and specify the copied AMI

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/storage/amazon-s3/

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/compute/amazon-ebs/

</p></details><hr>

### Question 58:

There is a temporary need to share some video files that are stored in a private S3 bucket. The consumers do not have AWS accounts and you need to ensure that only the authorized consumers can access the files. What is the best way to enable this access?

- A. Configure an allow rule in the Security Group for the IP addresses of the consumers
- B. Enable public read access for the S3 bucket
- C. Use CloudFront to distribute the files using authorization hash tags
- D. Generate a pre-signed URL and distribute it to the consumers 

<details><summary>Answer:</summary><p>
D

Explanation:

Enabling public read access does not restrict the content to authorized consumers

The second option is bogus as hash tags are not a CloudFront authentication mechanism

S3 pre-signed URLs can be used to provide temporary access to a specific object to those who do not have AWS credentials. This is the best option

The last option is also bogus as Security Groups do not apply to S3 buckets

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/storage/amazon-s3/

</p></details><hr>

### Question 59:

Which statements about Glacier are true? (choose 2)

- A. Retrieval is immediate
- B. Uploading archives is synchronous; downloading archives is asynchronous 
- C. Glacier objects are visible through S3 only 
- D. The contents of an archive can be modified after uploading

<details><summary>Answer:</summary><p>
BC

Explanation:

Glacier objects are visible through S3 only (not Glacier directly)

The contents of an archive that has been uploaded cannot be modified

Uploading archives is synchronous

Downloading archives is asynchronous

Retrieval can take a few hours

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/storage/amazon-s3/

</p></details><hr>

### Question 60:

You need to connect your company’s on-premise network into AWS and would like to establish a site-to-site VPN connection into your existing VPC. Which of the following configuration items needs to be setup in your company side of the connection?

- A. A Network Address Translation device
- B. A Customer Gateway 
- C. A Virtual Private Gateway
- D. A Firewall

<details><summary>Answer:</summary><p>
B

Explanation:

Virtual Private Gateway: The Amazon VPC side of a VPN connection

Customer Gateway: Your side of a VPN connection

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/networking-and-content-delivery/amazon-vpc/

</p></details><hr>

### Question 61:

There is a new requirement to implement in-memory caching for a Financial Services application due to increasing read-heavy load. The data must be stored persistently. Automatic failover across AZs is also required. Which two items from the list below are required to deliver these requirements? (choose 2)

- A. ElastiCache with the Redis engine 
- B. ElastiCache with the Memcached engine
- C. Multi-AZ with Cluster mode and Automatic Failover enabled 
- D. Multiple nodes placed in different AZs

<details><summary>Answer:</summary><p>
AC

Explanation:

Redis engine stores data persistently

Memached engine does not store data persistently

Redis engine supports Multi-AZ using read replicas in another AZ in the same region

You can have a fully automated, fault tolerant ElastiCache-Redis implementation by enabling both cluster mode and multi-AZ failover

Memcached engine does not support Multi-AZ failover or replication

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/database/amazon-elasticache/

</p></details><hr>

### Question 62:

You are troubleshooting a connectivity issue where you cannot connect to an EC2 instance in a subnet in your VPC from the Internet. Which of the three configuration items in the list below would you check first? (choose 3)

- A. The subnet has “Auto-assign public IPv4 address” set to “Yes” 
- B. The subnet route table has an attached Internet Gateway 
- C. There is a NAT Gateway installed in the subnet
- D. The EC2 instance has a private IP address associated with it
- E. The security group attached to the EC2 instance has an inbound rule allowing the traffic 

<details><summary>Answer:</summary><p>
ABE

Explanation:

Public subnets are subnets that have: “Auto-assign public IPv4 address” set to “Yes” The subnet route table has an attached Internet Gateway

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/compute/aws-auto-scaling/

</p></details><hr>

### Question 63:

To improve security in your AWS account you have decided to enable multi-factor authentication (MFA). You can authenticate using an MFA device in which two ways? (choose 2)

- A. Through the AWS Management Console 
- B. Locally to EC2 instances 
- C. Using a key pair
- D. Using the AWS API 

<details><summary>Answer:</summary><p>
AD

Explanation:

You can authenticate using an MFA device in the following two ways: Through the AWS Management Console – the user is prompted for a user name, password and authentication code Using the AWS API – restrictions are added to IAM policies and developers can request temporary security credentials and pass MFA parameters in their AWS STS API requests Using the AWS CLI by obtaining temporary security credentials from STS (aws sts get-session-token)

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/security-identity-compliance/aws-iam/

</p></details><hr>

### Question 64:

You are a Solutions Architect at Digital Cloud Guru. A large multi-national client has requested a design for a multi-region, multi-master database. The client has requested that the database be designed for fast, massively scaled applications for a global user base. The database should be a fully managed service including the replication. Which AWS service can deliver these requirements?

- A. DynamoDB with Global Tables and Cross Region Replication 
- B. S3 with Cross Region Replication
- C. RDS with Multi-AZ
- D. EC2 instances with EBS replication

<details><summary>Answer:</summary><p>
A

Explanation:

Cross-region replication allows you to replicate across regions: Amazon DynamoDB global tables provides a fully managed solution for deploying a multi-region, multi-master database When you create a global table, you specify the AWS regions where you want the table to be available DynamoDB performs all of the necessary tasks to create identical tables in these regions, and propagate ongoing data changes to all of them

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/database/amazon-dynamodb/

</p></details><hr>

### Question 65:

What is AWS Lambda’s resource limit for the amount of ephemeral disk capacity ("/tmp" space) that can be allocated per invocation?

- A. 512 KB
- B. 256 MB
- C. 512 MB 
- D. 2 TB
- E. 2 GB

<details><summary>Answer:</summary><p>
C

Explanation:

Lambda limits: Memory – minimum 128MB, maximum 3008MB in 64MB increments Ephemeral disk capacity (/tmp space) per invocation – 512 MB Number of file descriptors – 1024 Number of processes and threads (combined) – 1024 Maximum execution duration per request – 300 seconds Concurrent executions per account – 1000 (soft limit)

https://digitalcloud.guru/certification-training/aws-solutions-architect-associate/compute/aws-lambda/

</p></details><hr>

