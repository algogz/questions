<!DOCTYPE html>

<html lang="zh-cn" class="mac webkit chrome cursor">
<head><title>Google Cloud Professional Cloud Architect 01单词卡 | Quizlet</title><link as="font" crossorigin="anonymous" href="/a/i/fonts/latin-basic/hurmegeosans-no2-400.J8Wu.woff2" rel="preload" type="font/woff2"><link as="font" crossorigin="anonymous" href="/a/i/fonts/latin-basic/hurmegeosans-no2-600.DQUe.woff2" rel="preload" type="font/woff2"><link as="fetch" crossorigin="anonymous" href="/a/i/icons.ZDU5.svg" rel="preload"><link rel="stylesheet" type="text/css" href="/a/c/global/index.WFUdF.n.css"><link rel="stylesheet" type="text/css" href="/a/c/set/index.zYdBz.n.css"><link rel="stylesheet" type="text/css" href="/a/c/ui/index.aFbMu.n.css"><link rel="dns-prefetch" href="//up.quizlet.com"><meta property="og:site_name" content="Quizlet"><link rel="shortcut icon" href="/a/i/favicon.MDra.ico"><meta name="description" content="GPCCA - Test 01 or 03通过单词卡、游戏和更多工具来学习 — 这一切都是免费的。"><link rel="canonical" href="https://quizlet.com/348640679/gcp-architect-certification-002-flash-cards/"><meta name="referrer" content="origin-when-cross-origin"><script>var _rollbarConfig = {"accessToken":"27dcc4189dcf44d98247b58699a3e517","captureUncaught":true,"captureUnhandledRejections":true,"enabled":true,"hostWhiteList":["quizlet.com\\\/(?!(static\\\/rollbar))"],"ignoredMessages":["InvalidStateError","UnknownError","(Uncaught )?SyntaxError.*","Origin is not allowed.*","Ad container with id dfp-.*",".*__gCrWeb.*",".*b\\.postMessage is not a function.*",".*mobicip.*",".*hilitor.*",".*Blocked a frame with origin.*",".*event is not defined.*",".*didEnterViewPort",".*ms exceeded"],"maxItems":50,"payload":{"context":"Sets\/show","server":{"root":".\/"},"environment":"production","client":{"javascript":{"source_map_enabled":true,"code_version":"904c0e32f5aa01e143d7922b6a43fb356fd47f87","guess_uncaught_frames":true}},"person":{"id":"102871803","username":"algogz"}},"rollbarJsUrl":"\/static\/rollbarv2.3.9.min.js"};_rollbarConfig.transform = function xformPayload(payload) {  if (typeof payload.data === "undefined") payload.data = {};  if (window.FS) payload.fullstoryUrl = FS.getCurrentSessionURL(true);  return payload;};_rollbarConfig.checkIgnore = function shouldIgnore(isUncaught, args, payload) {  if (navigator.plugins["Gnome Shell Integration"]) {    return true;  }  var body = payload.body || {};  var m =    (body.message && body.message.body) ||    (body.exception && body.exception && body.exception.message);  if (!m) return false;  if (    m.match(/unhandled rejection was null or undefined/) ||    m.match(/Access-Control-Allow-Origin/)  ) {    return true;  }  return false;};</script><script>var _originForRollbar = window.location.origin || window.location.protocol + '//' + window.location.hostname + (window.location.port ? ':' + window.location.port: '');_rollbarConfig.enabled = _rollbarConfig.enabled && _originForRollbar === "https:\/\/quizlet.com";</script><script>!function(r){function o(n){if(e[n])return e[n].exports;var t=e[n]={exports:{},id:n,loaded:!1};return r[n].call(t.exports,t,t.exports,o),t.loaded=!0,t.exports}var e={};return o.m=r,o.c=e,o.p="",o(0)}([function(r,o,e){"use strict";var n=e(1),t=e(4);_rollbarConfig=_rollbarConfig||{},_rollbarConfig.rollbarJsUrl=_rollbarConfig.rollbarJsUrl||"https://cdnjs.cloudflare.com/ajax/libs/rollbar.js/2.3.6/rollbar.min.js",_rollbarConfig.async=void 0===_rollbarConfig.async||_rollbarConfig.async;var a=n.setupShim(window,_rollbarConfig),l=t(_rollbarConfig);window.rollbar=n.Rollbar,a.loadFull(window,document,!_rollbarConfig.async,_rollbarConfig,l)},function(r,o,e){"use strict";function n(r){return function(){try{return r.apply(this,arguments)}catch(r){try{console.error("[Rollbar]: Internal error",r)}catch(r){}}}}function t(r,o){this.options=r,this._rollbarOldOnError=null;var e=s++;this.shimId=function(){return e},window&&window._rollbarShims&&(window._rollbarShims[e]={handler:o,messages:[]})}function a(r,o){var e=o.globalAlias||"Rollbar";if("object"==typeof r[e])return r[e];r._rollbarShims={},r._rollbarWrappedError=null;var t=new p(o);return n(function(){o.captureUncaught&&(t._rollbarOldOnError=r.onerror,i.captureUncaughtExceptions(r,t,!0),i.wrapGlobals(r,t,!0)),o.captureUnhandledRejections&&i.captureUnhandledRejections(r,t,!0);var n=o.autoInstrument;return o.enabled!==!1&&(void 0===n||n===!0||"object"==typeof n&&n.network)&&r.addEventListener&&(r.addEventListener("load",t.captureLoad.bind(t)),r.addEventListener("DOMContentLoaded",t.captureDomContentLoaded.bind(t))),r[e]=t,t})()}function l(r){return n(function(){var o=this,e=Array.prototype.slice.call(arguments,0),n={shim:o,method:r,args:e,ts:new Date};window._rollbarShims[this.shimId()].messages.push(n)})}var i=e(2),s=0,d=e(3),c=function(r,o){return new t(r,o)},p=d.bind(null,c);t.prototype.loadFull=function(r,o,e,t,a){var l=function(){var o;if(void 0===r._rollbarDidLoad){o=new Error("rollbar.js did not load");for(var e,n,t,l,i=0;e=r._rollbarShims[i++];)for(e=e.messages||[];n=e.shift();)for(t=n.args||[],i=0;i<t.length;++i)if(l=t[i],"function"==typeof l){l(o);break}}"function"==typeof a&&a(o)},i=!1,s=o.createElement("script"),d=o.getElementsByTagName("script")[0],c=d.parentNode;s.crossOrigin="",s.src=t.rollbarJsUrl,e||(s.async=!0),s.onload=s.onreadystatechange=n(function(){if(!(i||this.readyState&&"loaded"!==this.readyState&&"complete"!==this.readyState)){s.onload=s.onreadystatechange=null;try{c.removeChild(s)}catch(r){}i=!0,l()}}),c.insertBefore(s,d)},t.prototype.wrap=function(r,o,e){try{var n;if(n="function"==typeof o?o:function(){return o||{}},"function"!=typeof r)return r;if(r._isWrap)return r;if(!r._rollbar_wrapped&&(r._rollbar_wrapped=function(){e&&"function"==typeof e&&e.apply(this,arguments);try{return r.apply(this,arguments)}catch(e){var o=e;throw"string"==typeof o&&(o=new String(o)),o._rollbarContext=n()||{},o._rollbarContext._wrappedSource=r.toString(),window._rollbarWrappedError=o,o}},r._rollbar_wrapped._isWrap=!0,r.hasOwnProperty))for(var t in r)r.hasOwnProperty(t)&&(r._rollbar_wrapped[t]=r[t]);return r._rollbar_wrapped}catch(o){return r}};for(var u="log,debug,info,warn,warning,error,critical,global,configure,handleUncaughtException,handleUnhandledRejection,captureEvent,captureDomContentLoaded,captureLoad".split(","),f=0;f<u.length;++f)t.prototype[u[f]]=l(u[f]);r.exports={setupShim:a,Rollbar:p}},function(r,o){"use strict";function e(r,o,e){if(r){var t;"function"==typeof o._rollbarOldOnError?t=o._rollbarOldOnError:r.onerror&&!r.onerror.belongsToShim&&(t=r.onerror,o._rollbarOldOnError=t);var a=function(){var e=Array.prototype.slice.call(arguments,0);n(r,o,t,e)};a.belongsToShim=e,r.onerror=a}}function n(r,o,e,n){r._rollbarWrappedError&&(n[4]||(n[4]=r._rollbarWrappedError),n[5]||(n[5]=r._rollbarWrappedError._rollbarContext),r._rollbarWrappedError=null),o.handleUncaughtException.apply(o,n),e&&e.apply(r,n)}function t(r,o,e){if(r){"function"==typeof r._rollbarURH&&r._rollbarURH.belongsToShim&&r.removeEventListener("unhandledrejection",r._rollbarURH);var n=function(r){var e,n,t;try{e=r.reason}catch(r){e=void 0}try{n=r.promise}catch(r){n="[unhandledrejection] error getting `promise` from event"}try{t=r.detail,!e&&t&&(e=t.reason,n=t.promise)}catch(r){t="[unhandledrejection] error getting `detail` from event"}e||(e="[unhandledrejection] error getting `reason` from event"),o&&o.handleUnhandledRejection&&o.handleUnhandledRejection(e,n)};n.belongsToShim=e,r._rollbarURH=n,r.addEventListener("unhandledrejection",n)}}function a(r,o,e){if(r){var n,t,a="EventTarget,Window,Node,ApplicationCache,AudioTrackList,ChannelMergerNode,CryptoOperation,EventSource,FileReader,HTMLUnknownElement,IDBDatabase,IDBRequest,IDBTransaction,KeyOperation,MediaController,MessagePort,ModalWindow,Notification,SVGElementInstance,Screen,TextTrack,TextTrackCue,TextTrackList,WebSocket,WebSocketWorker,Worker,XMLHttpRequest,XMLHttpRequestEventTarget,XMLHttpRequestUpload".split(",");for(n=0;n<a.length;++n)t=a[n],r[t]&&r[t].prototype&&l(o,r[t].prototype,e)}}function l(r,o,e){if(o.hasOwnProperty&&o.hasOwnProperty("addEventListener")){for(var n=o.addEventListener;n._rollbarOldAdd&&n.belongsToShim;)n=n._rollbarOldAdd;var t=function(o,e,t){n.call(this,o,r.wrap(e),t)};t._rollbarOldAdd=n,t.belongsToShim=e,o.addEventListener=t;for(var a=o.removeEventListener;a._rollbarOldRemove&&a.belongsToShim;)a=a._rollbarOldRemove;var l=function(r,o,e){a.call(this,r,o&&o._rollbar_wrapped||o,e)};l._rollbarOldRemove=a,l.belongsToShim=e,o.removeEventListener=l}}r.exports={captureUncaughtExceptions:e,captureUnhandledRejections:t,wrapGlobals:a}},function(r,o){"use strict";function e(r,o){this.impl=r(o,this),this.options=o,n(e.prototype)}function n(r){for(var o=function(r){return function(){var o=Array.prototype.slice.call(arguments,0);if(this.impl[r])return this.impl[r].apply(this.impl,o)}},e="log,debug,info,warn,warning,error,critical,global,configure,handleUncaughtException,handleUnhandledRejection,_createItem,wrap,loadFull,shimId,captureEvent,captureDomContentLoaded,captureLoad".split(","),n=0;n<e.length;n++)r[e[n]]=o(e[n])}e.prototype._swapAndProcessMessages=function(r,o){this.impl=r(this.options);for(var e,n,t;e=o.shift();)n=e.method,t=e.args,this[n]&&"function"==typeof this[n]&&("captureDomContentLoaded"===n||"captureLoad"===n?this[n].apply(this,[t[0],e.ts]):this[n].apply(this,t));return this},r.exports=e},function(r,o){"use strict";r.exports=function(r){return function(o){if(!o&&!window._rollbarInitialized){r=r||{};for(var e,n,t=r.globalAlias||"Rollbar",a=window.rollbar,l=function(r){return new a(r)},i=0;e=window._rollbarShims[i++];)n||(n=e.handler),e.handler._swapAndProcessMessages(l,e.messages);window[t]=n,window._rollbarInitialized=!0}}}}]);</script><script>var Quizlet = {"LOGGED_IN":true,"SERVER_TIME":1550158005,"DEBUG":false,"willHaveJquery":false,"willHaveMootools":false,"shouldReportLoggingErrors":false,"cstokenName":"qtkn","blackAndWhitelistObfuscatedRegexesByLang":{"en":{"black":"b\\ttubs\\ehts\\nib\\|b\\ssas\\ehts\\nib\\|huggin|eloh?]s\\-[ytoob|eloh?]s\\-[ttub|rekcuss\\)kcoc|kcid:?(|b\\?skcid?)s\\a?:(s\\?staeb\\|b\\kcids\\ymb\\|)kcoc|kcid:?(s\\)ruoy|sih|ym|a:?(s\\kcusb\\|b\\ffo?s\\gnikrejb\\|b\\ffo?]-s\\[krejb\\|b\\ffo?s\\gnikcajb\\|b\\ffo?]-s\\[kcajb\\|kcid?s\\yeknod|b\\erohwb\\|toggaf|b\\zzijb\\|b\\boj?]-s\\[wolbb\\|b\\eye?]-s\\[tnalsb\\|b\\yekcoj?]-s\\[lemacb\\|b\\ssa?]-s\\[dralb\\|b\\ssa?]-s\\[tafb\\|nmad?]-s\\[dog|daeh*s\\lewot|kcoc*s\\?skcus|kcid*s\\?skcus|regginb\\|)dr!?(agginb\\|rekcap*s\\egduf|kcuf|ssa?]-s\\[bmud|gab?]-s\\[ehcuod|b\\?stnucb\\|kcuskcoc|b\\?selohssab\\","white":"b\\tnucidb\\|ttubs\\ehts\\nis\\)mih|reh|uoy|em:?(s\\etib|ttubs\\ehts\\nis\\niap|ssas\\ehts\\nis\\niap"},"es":{"black":"nole]j|g[oc|]a|o[reluc|)agrev|adreim:?(?]-s\\[al?]-s\\[a?]-s\\[etev|b\\agrevb\\|sallopalpos|b\\?sa?kkiramb\\|]o|a[damam|solucemal|atup]o|a[jih|atup?]-s\\[ed?]-s\\[]o|a[jih|ajap?]-s\\[anu?]-s\\[recah|)rod|r:?(allof|erdam]-s\\[ut]-s\\[ed]-s\\[ahcnoc|sallopapuhc|]oa[dapuhc","white":"b\\esrallofirepmeb\\|b\\arelucseb\\|b\\odapuhcs\\?ratseb\\"},"de":{"black":"lethcuwhcs|rehcstulznawhcs|neppop|nrepmip|reggin|itfum|neseom|es\u00f6m|emmik|ekanak|eztarbkcak|eztof|kcifb\\|nesmub|hcsrab\\|rettirlana","white":"b\\?eztesegs\\?sehcs?'kcifb\\"}},"audioSpeeds":{"ja":{"normal":83,"slow":60,"medium":70},"ko":{"normal":83,"slow":60,"medium":70},"fr":{"normal":100,"slow":60,"medium":75},"default":{"normal":100,"slow":70,"medium":85}},"cloudFlareRay":"4a908e0ecd98985f-LAX","didJustUpgrade":null,"uid":"-255920372665102257","user":{"id":102871803,"username":"algogz","timestamp":1540630704,"lastModified":1550150187,"type":0,"isLocked":false,"_imageUrl":"\/a\/i\/animals\/4.gKYJ.jpg","timeZone":"Asia\/Shanghai","birthYear":1977,"birthMonth":12,"birthDay":5,"isConfirmed":true,"selfIdentifiedTeacherStatus":2,"profileImageId":104,"email":"wangyaojun@gmail.com","_hasPassword":true,"_hasFacebook":false,"_hasGoogle":false,"_canChangeUsername":true,"_isEligibleForFreeTrial":true,"_isUnderAge":false,"_isUnderAgeForAds":false,"_isUnderAgeOrInCoppaTransition":false,"_needsChildDirectedTreatment":false,"webLocale":"en-us","mobileLocale":"zh-cn","userLocalePreference":null,"srsNotificationTime":28800,"srsEmailNotificationsEnabled":false,"srsPushNotificationsEnabled":true},"ab_enrolled_variations":"PrefetchStudyModeLibraries:experiment","abTestConfiguration":[{"name":"HomepageNewValueProp","canEnroll":true,"isEnrolled":false,"variationSubjectToEnrollmentRules":"control"},{"name":"ReSETPageLayoutRedesign_20190105","canEnroll":false,"isEnrolled":false,"variationSubjectToEnrollmentRules":null},{"name":"RenderAboveFoldContentSetPageUS","canEnroll":false,"isEnrolled":false,"variationSubjectToEnrollmentRules":null},{"name":"RenderAboveFoldContentSetPageInternational","canEnroll":true,"isEnrolled":false,"variationSubjectToEnrollmentRules":"experiment"},{"name":"CheckoutPageCSS","canEnroll":false,"isEnrolled":false,"variationSubjectToEnrollmentRules":null},{"name":"DisableSignUpButtonUntilValidFormInternational","canEnroll":false,"isEnrolled":false,"variationSubjectToEnrollmentRules":"on"},{"name":"DisableSignUpButtonUntilValidFormUs","canEnroll":false,"isEnrolled":false,"variationSubjectToEnrollmentRules":null},{"name":"PrefetchStudyModeLibraries","canEnroll":false,"isEnrolled":true,"variationSubjectToEnrollmentRules":"experiment"},{"name":"ReengagementPushNotification","canEnroll":true,"isEnrolled":false,"variationSubjectToEnrollmentRules":"control"},{"name":"VideoAdSetPageFooterLoggedIn_20181207","canEnroll":false,"isEnrolled":false,"variationSubjectToEnrollmentRules":null},{"name":"VideoAdSetPageFooterLoggedOut_20181207","canEnroll":false,"isEnrolled":false,"variationSubjectToEnrollmentRules":null},{"name":"FreeTrialTeacherLoggedIn_20181207","canEnroll":false,"isEnrolled":false,"variationSubjectToEnrollmentRules":"trial30Day"},{"name":"FreeTrialStudentLoggedIn_20181207","canEnroll":false,"isEnrolled":false,"variationSubjectToEnrollmentRules":"trialPlusAndGo7Day"},{"name":"FreeTrialStudentLoggedOut_20181207","canEnroll":false,"isEnrolled":false,"variationSubjectToEnrollmentRules":"trialPlusAndGo7Day"},{"name":"QLiveNextActionLoggedIn_20181211","canEnroll":true,"isEnrolled":false,"variationSubjectToEnrollmentRules":"control"},{"name":"QLiveNextActionLoggedOut_20181211","canEnroll":true,"isEnrolled":false,"variationSubjectToEnrollmentRules":"promptSignup"},{"name":"SetPagePreviewLayoutInternational_20181120","canEnroll":false,"isEnrolled":false,"variationSubjectToEnrollmentRules":"control"},{"name":"SetPagePreviewLayoutUS_20181120","canEnroll":false,"isEnrolled":false,"variationSubjectToEnrollmentRules":null},{"name":"TeacherOnboardingUSPhaseOne_20181127","canEnroll":false,"isEnrolled":false,"variationSubjectToEnrollmentRules":null},{"name":"TeacherOnboardingPhaseTwo_20190108","canEnroll":true,"isEnrolled":false,"variationSubjectToEnrollmentRules":"control"},{"name":"SetPageWithPremiumRecommendations_20190204","canEnroll":true,"isEnrolled":false,"variationSubjectToEnrollmentRules":"newCards"},{"name":"SpecificPremiumContentUpsell_20181011","canEnroll":true,"isEnrolled":false,"variationSubjectToEnrollmentRules":"control"},{"name":"SetPageCardsPreviewSignupWall_20181107","canEnroll":false,"isEnrolled":false,"variationSubjectToEnrollmentRules":"hard8"},{"name":"UKHomepageNewSets","canEnroll":true,"isEnrolled":false,"variationSubjectToEnrollmentRules":"experiment"},{"name":"HeapTrial_20181012","canEnroll":false,"isEnrolled":false,"variationSubjectToEnrollmentRules":"experiment"},{"name":"SetPageBranchIoAppBanner_20181106","canEnroll":true,"isEnrolled":false,"variationSubjectToEnrollmentRules":"control"},{"name":"SetPageHoldOut_20180918","canEnroll":false,"isEnrolled":false,"variationSubjectToEnrollmentRules":null},{"name":"NewLearnModeProgress_20180904","canEnroll":false,"isEnrolled":false,"variationSubjectToEnrollmentRules":"experiment"},{"name":"NewTeacherPage_07272018","canEnroll":false,"isEnrolled":false,"variationSubjectToEnrollmentRules":"experiment"},{"name":"adsHoldOut_20180315","canEnroll":false,"isEnrolled":false,"variationSubjectToEnrollmentRules":null},{"name":"gqlFolders","canEnroll":false,"isEnrolled":false,"variationSubjectToEnrollmentRules":null},{"name":"nextDayReminderNotification_20180503","canEnroll":false,"isEnrolled":false,"variationSubjectToEnrollmentRules":null},{"name":"createSetDiagramsOcr2","canEnroll":false,"isEnrolled":false,"variationSubjectToEnrollmentRules":null},{"name":"createSetDiagramImagesGallery3","canEnroll":false,"isEnrolled":false,"variationSubjectToEnrollmentRules":"off"},{"name":"fullStoryVariation","canEnroll":false,"isEnrolled":false,"variationSubjectToEnrollmentRules":null},{"name":"fullStoryVariationUk","canEnroll":false,"isEnrolled":false,"variationSubjectToEnrollmentRules":null},{"name":"webpackVariation","canEnroll":false,"isEnrolled":false,"variationSubjectToEnrollmentRules":"a"},{"name":"ShowDownloadCurtain_20190123","canEnroll":false,"isEnrolled":false,"variationSubjectToEnrollmentRules":null},{"name":"SpellSidebarAdRefreshLogic","canEnroll":true,"isEnrolled":false,"variationSubjectToEnrollmentRules":"experiment"},{"name":"DownloadAppEmail","canEnroll":true,"isEnrolled":false,"variationSubjectToEnrollmentRules":"control"},{"name":"AssistantSidebarAdRefreshLogic","canEnroll":false,"isEnrolled":false,"variationSubjectToEnrollmentRules":null},{"name":"LearnSidebarAdRefreshLogic","canEnroll":true,"isEnrolled":false,"variationSubjectToEnrollmentRules":"control"},{"name":"ClozeQuestionType","canEnroll":false,"isEnrolled":false,"variationSubjectToEnrollmentRules":null}],"i18nFlagExternalizedMessages":false,"isPageloadDataCollectionEnabled":true,"adConfig":{"allAdsDisabled":false,"keyValues":{"childDirected":"no","n":"zh-cn","l":"1","p":"1","v":"1","g":"4","f":"0","t":"0","u":"0"},"registeredAds":{"SetSidebarV4":{"isFlexible":true,"showAdHeading":true,"supportsVideo":false,"useHeaderBidding":true,"type":"SIDEBAR"},"SetRectangleHeader":{"isFlexible":false,"showAdHeading":false,"supportsVideo":false,"useHeaderBidding":true,"type":"RECTANGLE"},"SetMWebStripV3":{"isFlexible":false,"showAdHeading":true,"supportsVideo":false,"useHeaderBidding":true,"type":"MOBILE_HORIZONTAL_STRIP"},"SetMWebEmbeddedStripSqrv3":{"isFlexible":true,"showAdHeading":true,"supportsVideo":false,"useHeaderBidding":true,"type":"MOBILE_RECTANGLE"},"SetEmbeddedStripFlexi":{"isFlexible":true,"showAdHeading":false,"supportsVideo":false,"useHeaderBidding":true,"type":"BANNER"},"SetPageFooterVideo":{"isFlexible":true,"showAdHeading":true,"supportsVideo":true,"useHeaderBidding":true,"type":"RECTANGLE","tag":"https:\/\/pubads.g.doubleclick.net\/gampad\/ads?iu=\/6396803\/SetPageFooterVideo&description_url=__page-url__&env=vp&impl=s&correlator=&tfcd=0&npa=0&gdfp_req=1&output=vast&sz=400x300&unviewed_position_start=1"},"NewFooterLI-17Plus":{"isFlexible":false,"showAdHeading":true,"supportsVideo":false,"useHeaderBidding":true,"type":"FOOTER"}},"shouldLogAdRequests":true,"tagForChildDirectedTreatment":0},"underAgeCutoff":13,"upsellPrice":"US$19.99","upsellMonthlyPrice":"US$1.67","upsellProductType":14,"goUpsellPrice":"US$11.99","goUpsellMonthlyPrice":"US$1","goUpsellProductType":20,"iconPaths":null,"recurlyKey":"ewr1-74WTM8nDUDdRhj2nlyzwZj","extraSessionUUIDs":["73c8d418-b137-4ec5-be90-1bee52c98098","5679ef5a-01c0-4970-9823-27f211cf7f7f","2f7f184d-d918-4f7e-8c2b-86c038dc746f","884c116d-8472-4217-85c8-cd8f15498acf","bebd8f9c-786d-4db7-8b94-6be975683731"],"countryCode":"cn","lowerTeacherAgeBound":22,"upperTeacherAgeBound":80,"requestId":"873SspFA3rYv7wkWq8AF","colorTheme":"default","upgradeData":{"freeTrial":{"amount":7,"unit":"day"}}};Quizlet.actionString = "Sets\"show".replace(/"/g, '/');</script><script>window.ga=function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;window.QWait=function(){QWait.p.push(arguments)};QWait.p=[];window.QLoad=function(){QLoad.p.push(arguments)};QLoad.p=[];window.QJP=[];</script><script>(function(e,b){b.getCsToken=function(){var a;a=e.cookie.match("(?:^|;)\\s*"+b.cstokenName.replace(/[\-\[\]{}()*+?.,\\^$|#\s]/g,"$&")+"=([^;]*)");a=null!==a?decodeURIComponent(a[1]):null;return a};b.appendCstokenToForm=function(a){var c=b.getCsToken();c?(b.setHiddenFormElement(a,"cstoken",c),b.addCsTokenDebugging(a)):Rollbar.warning("csrf_cookie_missing")};b.setHiddenFormElement=function(a,c,b){var d=!1;if(a.querySelectorAll){var f=a.querySelectorAll("input[type='hidden'][name='"+c+"']");if(0<f.length)for(var d=
!0,g=0;g<f.length;g++)f[g].value=b}d||(d=e.createElement("input"),d.type="hidden",d.name=c,d.value=b,a.appendChild(d))};b.addCsTokenDebugging=function(a){b.setHiddenFormElement(a,"cstokenV2",b.getCsTokenV2());b.setHiddenFormElement(a,"cstokenFieldCount",""+b.getFormFieldCount(a,"cstoken"));b.setHiddenFormElement(a,"cstokenSetByJs","1")};b.getCsTokenV2=function(){for(var a=b.cstokenName+"=",c=document.cookie?document.cookie.split(/;\s*/):[],h=[],d=0;d<c.length;d++){var f=c[d];f&&0===f.indexOf(a)&&
h.push(f.substr(a.length))}return h.join(";")};b.getFormFieldCount=function(a,c){for(var b=0,d=0;d<a.elements.length;d++)"hidden"===a.elements[d].type&&a.elements[d].name===c&&b++;return b};var k=function(a){a=a.target||a.srcElement;var c=a.method.toLowerCase();"post"!==c&&"put"!==c&&"delete"!==c&&"patch"!==c||b.appendCstokenToForm(a)};"addEventListener"in e?e.addEventListener("submit",k,!1):e.attachEvent&&e.attachEvent("onsubmit",k);b.willHaveJquery?QWait("jquery",function(){$.ajaxPrefilter(function(a){var c=
a.type.toLowerCase();if("post"===c||"put"===c||"delete"===c||"patch"===c){var c=b.getCsToken(),e="cstoken="+encodeURIComponent(c);a.data&&"[object FormData]"===a.data.toString()?a.data.append("cstoken",c):a.data=a.data?a.data+("&"+e):e}})}):b.willHaveMootools&&QWait("mootools",function(){var a=function(){var a=b.getCsToken();Request.prototype.options.headers={"X-Requested-With":"XMLHttpRequest",Accept:"text/javascript, text/html, application/xml, text/xml, */*","Cs-Token":a};Request.prototype.options.data=
{cstoken:a}};a();setInterval(a,3E3)})})(document,Quizlet);
</script><script>QWait('dom', function teaser() {if (window.console && window.console.log) {console.log("\n .d88888b.           d8b          888          888\nd88P\" \"Y88b          Y8P          888          888\n888     888                       888          888\n888     888 888  888 888 88888888 888  .d88b.  888888\n888     888 888  888 888    d88P  888 d8P  Y8b 888\n888 Y8b 888 888  888 888   d88P   888 88888888 888\nY88b.Y8b88P Y88b 888 888  d88P    888 Y8b.     Y88b.\n \"Y888888\"   \"Y88888 888 88888888 888  \"Y8888   \"Y888\n       Y8b\n\nThe world of education is changing, and a generation of students is turning to digital learning tools.\nQuizlet is building those tools... come join us!\n\nCheck out our jobs page at: https:\/\/quizlet.com\/jobs");}});</script><script>(function() {var ajax = new XMLHttpRequest();ajax.open('GET', "\/a\/i\/icons.ZDU5.svg");ajax.send();ajax.onload = function() {if (ajax.status !== 200) return Rollbar.warning('Error fetching SVG sprite sheet (bad response)', { code: ajax.status });var div = document.createElement('div');div.style.display = 'none';div.innerHTML = ajax.responseText;var waitForBody = setInterval(function() {if (document.body) {clearInterval(waitForBody);document.body.insertBefore(div, document.body.childNodes[0]);}}, 10);};})();</script><script>if (!window.Intl) {var script = document.createElement("script");script.setAttribute("src", "/a/j/dist/i18n.d8ffcd093c8ee941e392.a.zh-cn.js");script.setAttribute("async", "");script.setAttribute("defer", "");script.setAttribute("integrity", "sha512-pi7tjROYchMN1OvFEbuf35S2RHT/D1CWAqqZJorTEqW1gwpCj5TDbgVCn2pLrGRb2CbLUNjIWox4TjWjhPw0ww==");document.querySelector("head").appendChild(script);}else { QLoad('Quizlet.Common.i18n'); }</script><script async src="https://www.googletagservices.com/tag/js/gpt.js" defer></script><script async src="https://c.amazon-adsystem.com/aax2/apstag.js" defer onload="QLoad('Quizlet.apstag');"></script><script async src="/a/j/dist/main.12077f16ab9e8ea4d8a8.a.zh-cn.js" defer integrity="sha512-2uXTLSHa3YWxp6sCA/4/StM/mTAy2p92ggK+L/SoLmjy+TArjTqD1yGOEkMomNQlh/vt6GfLRAO5Rf2SkbYiXA=="></script><script async src="/a/j/dist/ads.46bb5be6576ab00dbf7c.a.zh-cn.js" defer integrity="sha512-P3S8Dt9dUmCwF1ZTWEyvkxC4KsoOM4Afhh/1JOhqYemMOXSl3n1YOvBF81fF0rKqhKCLFO1phNBC0fdsPsOq8Q=="></script><script async src="/a/j/dist/set.29db52c2ce35160f64b2.a.zh-cn.js" defer integrity="sha512-LsNQesujkMO/EiNuC6r8U+LD6uSfRPlOXgdBve1tO4jTfPeqYaJEwLVwImnmK221w+Lal2cKLgFWJCWFdpePmw=="></script><script async src="/a/j/dist/header_and_common.eea1a36b6e73c508400a.a.zh-cn.js" defer integrity="sha512-zQmwbV24Rk/oSwVjgVyuOYvY6sJptp0zhPrePoWlLobTya9D7KLJwV7fpMZDTEMeSJCN/XvKNk7BOADrFCKDsw=="></script><script async src="/a/j/dist/quizlet_global.e06f93f5c5e3b0343748.a.zh-cn.js" defer integrity="sha512-ZXdsDijpGQnmfKC4LohXkS0hJe6nOdS7nLXGV2f3UMIob2hlNEk1V36HvqwhPiCWZDD4BzjXr48dEhUir/zPPw=="></script><script async src="/a/j/dist/common.4b41e9648691996.a.zh-cn.js" defer integrity="sha512-HZQWwtHGc0DmHNOI1C5QDJvWDICQhVMfH1ZYiTpn8+sVr3mAslP+MJ666o9XLUbpmEICCRJ9YC8td22xs76dfQ=="></script><script async src="/a/j/dist/react.0b4610f0d85df05.a.zh-cn.js" defer integrity="sha512-KFvvIuQI0i+eeDNpjybeeRzRR+CQECDDkJV2W47xFRKMHf3TRVUsbcjKjoL/6aBIGDHrmzJG+wFQKYDUjrR2qg=="></script><script async src="/a/j/dist/redux_and_immutable.b41b01a0cb3b317.a.zh-cn.js" defer integrity="sha512-Vnwr6deCkpdHs1lqBYKgMnrocK5bmhu+JFbz/usm/3+qBzXvUKbtebewD7S550qHoex7QiSCqq+NJc+1gY3ZhQ=="></script></head><body class="sets show flex-sidebar has-footer qad-is-showing" itemscope itemtype="http://schema.org/WebPage">

<div class="ads ad adsbox doubleclick ad-placement carbon-ads __isAdBlockerEnabled" style="position: absolute; width: 10px; height: 10px; left: -100px; top: -100px;">&nbsp;</div>

<div class="site">

			<script>window.Quizlet["coreData"] = {"acknowledgedOnboardingSteps":{},"shouldShowAd":true,"user":{"id":102871803,"username":"algogz","timestamp":1540630704,"lastModified":1550150187,"type":0,"isLocked":false,"_imageUrl":"\/a\/i\/animals\/4.gKYJ.jpg","timeZone":"Asia\/Shanghai","birthYear":1977,"birthMonth":12,"birthDay":5,"isConfirmed":true,"selfIdentifiedTeacherStatus":2,"profileImageId":104,"email":"wangyaojun@gmail.com","_hasPassword":true,"_hasFacebook":false,"_hasGoogle":false,"_canChangeUsername":true,"_isEligibleForFreeTrial":true,"_isUnderAge":false,"_isUnderAgeForAds":false,"_isUnderAgeOrInCoppaTransition":false,"_needsChildDirectedTreatment":false,"webLocale":"en-us","mobileLocale":"zh-cn","userLocalePreference":null,"srsNotificationTime":28800,"srsEmailNotificationsEnabled":false,"srsPushNotificationsEnabled":true}}; QLoad("Quizlet.coreData");</script><script>window.Quizlet["userPromptsData"] = {"canResendConfirmationEmail":null,"formattedTeacherUpsellMonthlyPrice":"US$3","hasExceededMaxConfirmationEmailResends":null,"requestUri":"\/348513265\/google-cloud-professional-cloud-architect-01-flash-cards\/","shouldShowBrazilAmbassadorPrompt":false,"shouldShowConfirmEmailPrompt":false,"shouldShowTeacherStatusPrompt":false,"supportEmail":null}; QLoad("Quizlet.userPromptsData");</script><script>window.Quizlet["siteNavData"] = {"blogEntry":{"id":1185,"timestamp":1549315092,"lastModified":1550147648,"publishedTimestamp":1549323514,"authorId":111129557,"lastModifiedUserId":111129557,"type":"blog","title":"Celebrating Black History Month","slug":"celebrating-black-history-month","allowsComments":2,"imagePath":"https:\/\/img.quizlet.com\/WbvtJ-700.jpg","authorFirstName":"Chad","textPreview":"Each February the United States \u2014 as well as in Canada \u2014 pay tribute and celebrate the history and social and cultural contributions of African-Ameri\u2026"},"bookmarkedFolders":[],"canCreateClass":true,"canJoinClasses":false,"classInvitations":[],"classMemberships":[],"folders":[{"id":61482863,"personId":102871803,"name":"GCP","description":"","timestamp":1550055668,"lastModified":1550055668,"isHidden":false,"_webUrl":"https:\/\/quizlet.com\/algogz\/folders\/gcp"}],"isUserInFreeTrial":false,"mainSchool":null,"numClassesAllowed":8,"numClassesUsed":0,"showBlog":false,"showRenewLink":false,"user":{"id":102871803,"username":"algogz","timestamp":1540630704,"lastModified":1550150187,"type":0,"isLocked":false,"_imageUrl":"\/a\/i\/animals\/4.gKYJ.jpg","timeZone":"Asia\/Shanghai","birthYear":1977,"birthMonth":12,"birthDay":5,"isConfirmed":true,"selfIdentifiedTeacherStatus":2,"profileImageId":104,"email":"wangyaojun@gmail.com","_hasPassword":true,"_hasFacebook":false,"_hasGoogle":false,"_canChangeUsername":true,"_isEligibleForFreeTrial":true,"_isUnderAge":false,"_isUnderAgeForAds":false,"_isUnderAgeOrInCoppaTransition":false,"_needsChildDirectedTreatment":false,"webLocale":"en-us","mobileLocale":"zh-cn","userLocalePreference":null,"srsNotificationTime":28800,"srsEmailNotificationsEnabled":false,"srsPushNotificationsEnabled":true},"userFoldersByFolderId":[],"userSchools":[]}; QLoad("Quizlet.siteNavData");</script><div id="MobileNavTarget" style="display: none;"></div><div class="SiteHeaderWrapper" id="SiteHeaderReactTarget"><header class="SiteHeader" itemscope="true" itemtype="http://schema.org/WPHeader" role="navigation"><div class="UIContainer UIContainer--isFullBleed"><div class="SiteHeader-wrapper"><div class="SiteHeader-logo SiteHeader-section"><a class="UILink UILink--inverted" href="/latest"><div class="SiteHeader-logoWrapper"><div aria-label="Quizlet" class="SiteLogo" role="img" title="Quizlet"><svg fill="currentColor" viewBox="0 0 244 53" xmlns="http://www.w3.org/2000/svg"><path d="M26.99 1.09c15.382 0 26.99 11.36 26.99 25.883 0 6.687-2.54 12.583-6.676 17.04l7.182 7.98H42.37l-2.49-2.847c-3.6 2.482-8.102 3.638-12.89 3.638C11.68 52.784 0 41.496 0 26.974 0 12.017 12.116 1.09 26.99 1.09zm0 41.7c2.03 0 3.844-.43 5.586-1.15L22.2 29.993h12.117l5.587 6.4c2.03-2.518 2.974-5.537 2.974-9.42 0-8.698-6.6-15.817-15.89-15.817-9.287 0-15.814 7.046-15.814 15.817 0 8.915 6.527 15.818 15.815 15.818zM61.035 15.76H71.99v20.706c0 4.89 3.048 6.686 6.676 6.686 3.627 0 6.675-1.797 6.675-6.686V15.758h10.956v21.64C96.296 48.04 88.026 53 78.666 53s-17.63-4.96-17.63-15.6V15.757zm42.75 36.235h10.81V15.758h-10.81v36.235zm-.992-45.69c0-3.56 2.92-6.303 6.36-6.303 3.518 0 6.36 2.743 6.36 6.303 0 3.485-2.842 6.23-6.36 6.23-3.44 0-6.36-2.745-6.36-6.23zm35.738 18.873h-16.74v-9.418h35.332l-20.15 26.817h19.133v9.418h-37.94l20.365-26.817zm23.67 26.817h10.81V1.883H162.2v50.11zm17.063-18.19c0-11.503 8.272-18.908 19.372-18.908 11.173 0 18.5 8.196 18.5 18.334 0 0 0 2.03-.217 3.684h-26.843c.218 4.314 3.48 6.883 9.648 6.883 6.966 0 10.883-2.085 12.987-3.523v9.347c-3.41 2.157-7.182 3.308-13.567 3.308-12.263 0-19.88-7.405-19.88-18.765v-.36zm26.99-4.026c0-3.235-3.337-5.967-7.618-5.967-4.498 0-8.27 2.66-8.488 5.967h16.105zm19.172-4.313h-4.86v-9.706h4.86V1.882h10.52v13.876H244v9.706h-8.054v26.53h-10.52v-26.53z" fill-rule="evenodd"></path></svg></div></div></a></div><div class="SiteHeader-defaultDesktop"><div class="SiteHeader-search SiteHeader-section"><a class="UILink UILink--inverted" href="/subject/"><div class="SiteHeader-searchInner"><svg class="UIIcon UIIcon--search SiteHeader-searchSubmitIcon SiteHeader-icon UIIcon--large"><noscript></noscript><use xlink:href="#search"></use><noscript></noscript></svg><script>QWait('Quizlet.IconContainer',function(){Quizlet.IconContainer.loadIcon("search")})</script><span class="SiteHeader-linkText">搜索</span></div></a></div><div class="SiteHeader-create SiteHeader-section"><a class="UILink UILink--inverted" href="https://quizlet.com/create-set"><svg class="UIIcon UIIcon--create-set SiteHeader-createIcon SiteHeader-icon UIIcon--large"><noscript></noscript><use xlink:href="#create-set"></use><noscript></noscript></svg><script>QWait('Quizlet.IconContainer',function(){Quizlet.IconContainer.loadIcon("create-set")})</script><span class="SiteHeader-linkText">创建</span></a></div><div class="SiteHeader-userSection SiteHeader-section"><div class="SiteHeader-chiclet"><a class="UILink" href="/upgrade?source=header_plus"><span class="SiteHeaderChiclet">升级：<br/>免费试用7天</span></a></div><div class="SiteHeader-userInfo"><a class="UILink UILink--inverted" href="/algogz"><span class="SiteHeader-avatar"><span class="UserAvatar" style="background-image:url(/a/i/animals/4.gKYJ.jpg);height:32px;width:32px;"></span></span><span class="SiteHeader-username">algogz</span><svg class="UIIcon UIIcon--dropdown SiteHeader-userDropdownIcon UIIcon--small"><noscript></noscript><use xlink:href="#dropdown"></use><noscript></noscript></svg><script>QWait('Quizlet.IconContainer',function(){Quizlet.IconContainer.loadIcon("dropdown")})</script></a></div></div></div><div class="SiteHeader-defaultMobileHeader SiteHeader-section"><span aria-label="创建" class="SiteHeader-mobileLinkArea"><a class="UILink UILink--inverted" href="/create-set"><svg class="UIIcon UIIcon--create-set SiteHeader-icon UIIcon--large"><noscript></noscript><use xlink:href="#create-set"></use><noscript></noscript></svg><script>QWait('Quizlet.IconContainer',function(){Quizlet.IconContainer.loadIcon("create-set")})</script></a></span><span aria-label="搜索" class="SiteHeader-mobileLinkArea"><a class="UILink UILink--inverted" href="/subject/"><svg class="UIIcon UIIcon--search SiteHeader-icon UIIcon--large"><noscript></noscript><use xlink:href="#search"></use><noscript></noscript></svg><script>QWait('Quizlet.IconContainer',function(){Quizlet.IconContainer.loadIcon("search")})</script></a></span><span class="SiteHeader-mobileLinkArea" id="activate-nav"><a class="UILink UILink--inverted" href="#"><svg class="UIIcon UIIcon--list SiteHeader-icon UIIcon--large"><noscript></noscript><use xlink:href="#list"></use><noscript></noscript></svg><script>QWait('Quizlet.IconContainer',function(){Quizlet.IconContainer.loadIcon("list")})</script></a></span></div></div></div></header></div><script>window.Quizlet["headerData"] = {"createSetPath":"https:\/\/quizlet.com\/create-set","feedbackMinorCategoryId":-1,"headerChicletData":["\u5347\u7ea7\uff1a\u003Cbr\/\u003E\u514d\u8d39\u8bd5\u75287\u5929","\/upgrade?source=header_plus",[]],"initialIsSearchExpanded":false,"initialQuery":"","isHelpCenter":false,"loginFormData":null,"referer":null,"searchAction":"\/subject","signupFormData":null,"user":{"id":102871803,"username":"algogz","timestamp":1540630704,"lastModified":1550150187,"type":0,"isLocked":false,"_imageUrl":"\/a\/i\/animals\/4.gKYJ.jpg","timeZone":"Asia\/Shanghai","birthYear":1977,"birthMonth":12,"birthDay":5,"isConfirmed":true,"selfIdentifiedTeacherStatus":2,"profileImageId":104,"email":"wangyaojun@gmail.com","_hasPassword":true,"_hasFacebook":false,"_hasGoogle":false,"_canChangeUsername":true,"_isEligibleForFreeTrial":true,"_isUnderAge":false,"_isUnderAgeForAds":false,"_isUnderAgeOrInCoppaTransition":false,"_needsChildDirectedTreatment":false,"webLocale":"en-us","mobileLocale":"zh-cn","userLocalePreference":null,"srsNotificationTime":28800,"srsEmailNotificationsEnabled":false,"srsPushNotificationsEnabled":true},"userDropdownData":{"accountLinks":[{"text":"\u4f60\u7684\u5b66\u4e60\u96c6","url":"\/algogz"},{"text":"\u8bbe\u7f6e","url":"\/settings"}],"helpLinks":[{"text":"\u5e2e\u52a9\u4e2d\u5fc3","url":"\/zh-cn\/help"}],"upgradeLinks":[{"attrs":{"source":"upgrade-dropdown"},"text":"\u5347\u7ea7\uff1a\u514d\u8d39\u8bd5\u75287\u5929","url":"\/upgrade?source=dropdown"}]}}; QLoad("Quizlet.headerData");</script><img class="PrintLogo" id="QJDA9WNXacT"><script>QWait("dom",function(){document.getElementById("QJDA9WNXacT").setAttribute("src", "\/a\/i\/logo\/Quizlet-print.68Eu.png")});</script>	
<div class="SetPageWrapper"><div class="SetPageWrapper-contentContainer"><div class="SetPageHeaderAdz"><div class="SetPageHeaderAdz-container"><div class="SetPageHeaderAdz-wrapper"><script>if (Quizlet.adConfig && Quizlet.adConfig.registeredAds && Quizlet.adConfig.registeredAds["SetRectangleHeader"]) {Quizlet.adConfig.registeredAds["SetRectangleHeader"].isServerRendered = true;}</script><div id="SiteAdSetRectangleHeaderTarget"></div><script>window.Quizlet["siteAdSetRectangleHeaderData"] = {"headingAlignment":"block","id":"SetRectangleHeader","upgradeSource":"remove_ads"}; QLoad("Quizlet.siteAdSetRectangleHeaderData");</script></div></div></div><div id="SetPageTarget"><div class="SetPage has-adz"><div class="SetPage-headerWrapper"><div class="SetPage-headerContainer"><div class="SetPageHeader has-adz"><div class="SetPageHeader-container"><div class="UIDiv SetPageHeader-info"><span class="SetPageHeader-termCount">50个词语</span><span class="SetPageHeader-infoDelimiter"></span><div class="SetPageHeader-creator"><div class="UserLink"><div class="UserLink-inner"><div class="UserLink-avatar"><a class="UILink" href="/WJScott" title="访问WJScott的个人资料"><span class="UserAvatar" style="background-image:url(https://gimg.quizlet.com/-f6oMjACGc7Q/AAAAAAAAAAI/AAAAAAAAAAA/AGDgw-jN8aZQWgIUaNu9YXAEVV8WTZ1MdA/mo/photo.jpg?sz=24);background-image:-webkit-image-set(url(https://gimg.quizlet.com/-f6oMjACGc7Q/AAAAAAAAAAI/AAAAAAAAAAA/AGDgw-jN8aZQWgIUaNu9YXAEVV8WTZ1MdA/mo/photo.jpg?sz=24) 1x, url(https://gimg.quizlet.com/-f6oMjACGc7Q/AAAAAAAAAAI/AAAAAAAAAAA/AGDgw-jN8aZQWgIUaNu9YXAEVV8WTZ1MdA/mo/photo.jpg?sz=48) 2x);height:24px;width:24px;"></span></a></div><div class="UserLink-content"><a class="UILink" href="/WJScott" title="访问WJScott的个人资料"><span class="UserLink-username">WJScott</span></a></div></div></div></div></div><h1 class="UIHeading UIHeading--one">Google Cloud Professional Cloud Architect 01</h1><div class="SetPageHeader-description">GPCCA - Test 01 or 03<div class="SetPageHeader-descriptionBlur"></div></div><div class="SetPageHeader-setMemberships">添加至<span class="SetPageHeader-setMembershipsContainer"><a class="UILink" href="/algogz/folders/gcp">GCP</a></span></div></div></div><div class="SetPage-header"></div></div></div><div class="SetPage-menu"><div class="SetPage-modesWrapper"><div class="SetPage-modesBottomBackground"></div><div class="SetPage-modes"><div class="UIRow"><div class="SetPageModes-group SetPageModes-group--study"><div class="SetPageModes-groupLabel"><h6 class="UIHeading UIHeading--six">学习</h6></div><span class="SetPageModes-buttonWrapper"><span class="SetPageModeButton"></span></span><span class="SetPageModes-buttonWrapper"><span class="SetPageModeButton"></span></span><span class="SetPageModes-buttonWrapper"><span class="SetPageModeButton"></span></span><span class="SetPageModes-buttonWrapper"><span class="SetPageModeButton"></span></span><span class="SetPageModes-buttonWrapper"><span class="SetPageModeButton"></span></span></div><div class="SetPageModes-group SetPageModes-group--play"><div class="SetPageModes-groupLabel"><h6 class="UIHeading UIHeading--six">游戏</h6></div><span class="SetPageModes-buttonWrapper"><span class="SetPageModeButton"></span></span><span class="SetPageModes-buttonWrapper SetPageModes-buttonWrapper--gravity SetPageModes-buttonWrapper--hiddenForMobile"><span class="SetPageModeButton"></span></span></div></div></div></div></div><div class="UIDiv SetPage-termsWrapper"><div class="UIRow"><div class="SetPage-terms"><div class="SetPage-termsList"><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">What information is required to connect to an on-premises network router over VPN using Cloud Router for dynamic routing? <br><br>Choose 3 correct answers: <br>[ ] A) Remote Router DNS Name<br>[ ] B) Remote Router (Peer) IP Address<br>[ ] C) Shared Secret<br>[ ] D) Border Gateway Protocol Address (BGP)</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct answers B, C, and D <br><br>Using Cloud Router for dynamic routing requires a BGP address along with the peer address and the shared secret for secure access.</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">You want to ensure Dress4Win's sales and tax records remain available for infrequent viewing by auditors for at least 10 years. Cost optimization is your top priority. Which cloud services should you choose?<br><br>[ ] A) Google Bigtable with US or EU as location to store the data, and gcloud to access the data. <br>[ ] B) BigQuery to store the data, and a web server cluster in a managed instance group to access the data. Google Cloud SQL mirrored across two distinct regions to store the data, and a Redis cluster in a managed instance group to access the data. <br>[ ] C) Google Cloud Storage Nearline to store the data, and gsutil to access the data. <br>[ ] D) Google Cloud Storage Coldline to store the data, and gsutil to access the data.</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct Answer D <br><br>Feedback:<br>A and B are not suitable for this type of task &quot;infrequent viewing by auditors for at least 10 years&quot; and they are not cost-effective, either <br><br>D (Correct answer) - &quot;for infrequent viewing by auditors&quot; and &quot;for at least 10 years&quot; fit the usage pattern for Coldline and qualify Answer D for meeting the requirements &quot;Cost optimization is your top priority&quot; due to its lowest storage cost. <br><br>Explanation: <br>This is about choosing the storage solution for backup or achieving, depending the required access frequency which in turn impact the cost, you have the option between Nearline and Coldline.<br>https://cloud.google.com/images/storage/storage-classes-desktop.svg</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">Mountkirk Games has deployed their new backend on Google Cloud Platform (GCP). You want to create a thorough testing process for new versions of the backend before they are released to the public. You want the testing environment to scale in an economical way.<br> <br>How should you design the process?<br>[ ] A)Create a scalable environment in GCP for simulating production load. <br>[ ] B) Build stress tests into each component of your application using resources internal to GCP to simulate load. <br>[ ] C) Use the existing infrastructure to test the GCP-based backend at scale. <br>[ ] D) Create a set of static environments in GCP to test different levels of load - for example, high, medium, and low.</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct Answer A <br><br>Feedback <br><br>A) (Correct Answer) With this disposable and repeatable testing resources, you can do load test whenever needed. Shutdown or stop the services or simplify delete and recreate it based on the test plans, to keep the cost low. <br><br>It meets the requirements &quot;create a thorough testing process for new versions of the backend before they are released to the public&quot; and&quot; testing environment to scale in an economical way&quot;. Doing thorough testing on production infrastructure is risky to other running application, not feasible, not scale in economical way. <br><br>B) This is not scale nor economical and too complicated to implement. <br><br>C) At first glance, reuse exiting environments so it'll be scalable, economical, and in real situation. If Read the case study again, we know Mountkirk Games is popular game platform targeting to global users with very high traffic and heavy load. Doing load test on the production is no longer an option, nor is it necessary a scale in an economical way if you mix the production and testing load. Comparing to the solution creating disposable and reputable testing environment simulating production load and execute test plans on demanding, Answer A is the winner. <br><br>D) This is not scalable or economical</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">You have been asked to select the storage system for the click-data of your company's large portfolio of websites. This data is streamed in from a custom website analytics package at a typical rate of 6,000 clicks per minute, with bursts of up to 8,500 clicks per second. It must be stored for future analysis by your data science and user experience teams.<br> <br>Which storage infrastructure should you choose?<br>[ ] A) Google cloud Datastore <br>[ ] B) Google Cloud SQL <br>[ ] C) Google Cloud Bigtable <br>[ ] D) Google Cloud Storage</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct Answer C <br><br>Feedback <br><br>A) Doesn't not meet this requirement &quot;It must be stored for future analysis by your data science and user experience teams.&quot; Google Cloud Datastore is a NoSQL document database built for automatic scaling, high performance, and ease of application development and integrating well with App Engine. <br><br>Datastore: A scalable, fully-managed NoSQL document database for your web and mobile applications. <br><br>Good for: <br> - Semi-structured application data <br> - Hierarchical data <br> - Durable key-value data <br><br>Workload: <br> - User profiles <br> - Product catalogs <br> - Game state <br><br>B) Cloud SQL is mainly for OLTP (Transactional, CRUD) not for taking and storing streaming data. It does not have the scalability and elasticity to absorb this amount of data in real time. <br><br>C) (Correct Answer) The reason is that data is in IoT nature and it will be used for analytics. <br><br>Bigtable: A scalable, fully-managed NoSQL wide-column database that is suitable for both real-time access and analytics workloads. Bigtable is ideal for very large NoSQL datasets and is useful for high-speed transactions and analysis. It integrates well with ML. Dataproc, and analytics <br><br>Good for <br> - Low-latency read/write access <br> - High-throughput analytics <br> - Native time series support <br><br>Work load <br> - IoT, finance, adtech <br> - Personalization, recommendations <br> - Monitoring <br> - Geospatial datasets <br> - Graphs <br><br>Although both Datastore and Bigtable are NoSQL databases, only Bigtable is able to support over a petabyte of data and is useful for high speed analytics as well, whereas Datastore is not. <br><br>D) GCS is ideally for Object storage purpose although it has pretty good scalability. It's not suitable for IoT kind of spiky streaming data. Its buckets initially support roughly 1000 writes per second and then scale as needed. As the request rate for a given bucket grows, Cloud Storage automatically increases the IO capacity for that bucket by distributing the request load across multiple servers. Especially considering the click stream rate of 6,000 clicks per minute, with bursts of up to 8,500 clicks per second, the way GCS handle and absorb this kind high and low data stream by scale up and down make it not suitable for this task.</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">Over time, you've created 5 snapshots of a single instance. To save space, you delete snapshots number 3 and 4. What has happened to the fifth snapshot?<br><br>[ ] A) The data from both snapshots 3 and 4 necessary for continuance are transferred to snapshot 5. <br>[ ] B) It is no longer useable and cannot restore data. <br>[ ] C) All later snapshots, including 5, are automatically deleted as well. <br>[ ] D) The data from snapshot 4 necessary for continuance was transferred to snapshot 5, however snapshot 3's contents were transferred to snapshot 2.</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct Answer A <br><br>Explanation <br><br>Deleting a snapshot: <br>https://cloud.google.com/compute/docs/disks/restore-and-delete-snapshots <br><br>When you delete a snapshot, Compute Engine immediately marks the snapshot as DELETED in the system. If the snapshot has no dependent snapshots, it is deleted outright. However, if the snapshot does have dependent snapshots: <br><br>1) Any data that is required for restoring other snapshots is moved into the next snapshot, increasing its size. <br>2) Any data that is not required for restoring other snapshots is deleted. This lowers the total size of all your snapshots. <br>3) The next snapshot no longer references the snapshot marked for deletion, and instead references the snapshot before it. <br><br>Because subsequent snapshots might require information stored in a previous snapshot, keep in mind that deleting a snapshot does not necessarily delete all the data on the snapshot. As mentioned in the first bullet above, if any data on a snapshot that is marked for deletion is needed for restoring subsequent snapshots, that data is moved into the next corresponding snapshot. To definitively delete data from your snapshots, you should delete all snapshots. <br><br>The linked diagram below illustrates the process described above: https://cloud.google.com/compute/images/deleting-snapshot.png</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">A small number of API requests to your microservices-based application take a very long time. You know that each request to the API can traverse many services. You want to know which service takes the longest in those cases. What should you do? <br>[ ] A) Set timeouts on your application so that you can fail requests faster. <br>[ ] B) Instrument your application with StackDriver Trace to break down the request latencies at each microservice. <br>[ ] C) Send custom metrics for each of your requests to Stackdriver Monitoring. <br>[ ] D) Use Stackdriver Monitoring to look for insights that show when your API latencies are high.</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct Answer B <br><br>Explanation <br><br>A) This won't be able to tell you directly where the bottleneck is. <br><br>B) (Correct Answer) This is exactly StackDriver Trace comes to play. <br><br>C) Without knowing where the bottleneck is beforehand, it's not easy, if not impossible, to setup custom metrics to capture the latency causes. Besides, the question itself is about to find where the latency/bottleneck exists. <br><br>D) This could tell you when the API call latency reaching to certain threshold/criteria but can hardly tell where the root causes is without additional setup and analysis. <br><br>Reference Resources:<br><br>Stackdriver Trace can help you answer the following questions: <br>https://cloud.google.com/trace/docs/overview<br>• How long does it take my application to handle a given request? <br>• Why is it taking my application so long to handle a request? <br>• Why do some of my requests take longer than others? <br>• What is the overall latency of requests to my application? <br>• Has latency for my application increased or decreased over time? <br>• What can I do to reduce application latency? <br><br>&quot;As micro-services become more popular, the cross-application tracing provided by Stackdriver Trace becomes essential in pinpointing the root cause of latency issues.&quot;</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">The operations manager asks you for a list of recommended practices that she should consider when migrating a J2EE application to the cloud. Which three practices should you recommend? <br><br>Choose 3 answers:<br>[ ] A) Port the application code to run on Google App Engine<br>[ ] B) Integrate Cloud Dataflow into the application to capture real-time metrics. <br>[ ] C) Instrument the application with a monitoring tool like Stackdriver Debugger. <br>[ ] D) Select an automation framework to reliably provision the cloud infrastructure. <br>[ ] E) Deploy a continuous integration tool with automated testing in a staging environment. <br>[ ] F) Migrate from MySQL to a managed NoSQL database like Google Cloud Datastore or Bigtable.</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct Answer A, E, and F <br><br>Feedback:<br><br>A) (Correct answer) For Java applications, App Engine provides a J2EE standard servlet container with a complete Java 7 JVM and standard library. Because App Engine supports common Java API standards, your code stays clean and portable. <br><br>B) Cloud Dataflow is a fully-managed service for transforming and enriching data in stream (real time) and batch (historical) modes. It is not necessary apply to J2EE migration to Cloud. <br><br>C) If using GAE, no configuration is required for this feature - Google App Engine standard environment is configured to use Google Stackdriver Error Reporting and Debugger automatically. The following runtimes are supported (Java, Python, Go, PHP) for debugging at this time. <br><br>D) GAE will take care of this for you: GAE is Fully managed serverless application platform. Build and deploy applications on a fully managed platform. Scale your applications seamlessly from zero to planet scale without having to worry about managing the underlying infrastructure. With zero server management and zero configuration deployments, developers can focus only on building great applications without the management overhead. <br><br>E) (Correct answer) When you migrate, you would not move you J2EE application directly to production, you would do some testing before roll to production. Ideally automation CI tool should use in staging to test the any changes introduce including code and configuration before roll into production. <br><br>F) (Correct answer) In GAE you can access Datastore which is built on top of Google's NoSQL database, Bigtable, and is subject to Bigtable's performance characteristics. <br><br>Java Persistence API (JPA) is a standard interface for accessing databases in Java, providing an automatic mapping between Java classes and database tables. There is an open-source plugin available for using JPA with Datastore.</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">TerramEarth's 20 million vehicles are scattered around the world. Based on the vehicle's location its telemetry data is stored in a Google Cloud Storage (GCS) regional bucket (US. Europe, or Asia). The CTO has asked you to run a report on the raw telemetry data to determine why vehicles are breaking down after 100 K miles. You want to run this job on all the data. What is the most cost-effective way to run this job?<br><br>[ ] A) Launch a cluster in each region to preprocess and compress the raw data, then move the data into a regional bucket and use a Cloud Dataproc cluster to finish the job. <br>[ ] B) Move all the data into 1 region, then launch a Google Cloud Dataproc cluster to run the job. <br>[ ] C) Launch a cluster in each region to preprocess and compress the raw data, then move the data into a multi-region bucket and use a Dataproc cluster to finish the job. <br>[ ] D) Move all the data into 1 zone, then launch a Cloud Dataproc cluster to run the job.</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct Answer A <br><br>Feedback <br><br>A (Correct answer) Since the raw data are saved based on the vehicle's location all over the world, most likely they'll scatter in many different regions and eventually they need to move to a centralized location for final processing. <br><br>Preprocessing raw data and compressing them from each location to reduce the size so to save the between-region data egress cost. <br><br>Dataproc is Zone-specific resources and since you want to run this job on all data and you or your group probably are the only consumers for the data, moving the data into a regional bucket same or closest to the DataProc cluster zone's region for final analysis is most cost effective. <br><br>Use a regional location to help optimize latency, availability, and network bandwidth for data consumers grouped in the same region. <br><br>Use a multi-regional location when you want to serve content to data consumers that are outside of the Google network and distributed across large geographic areas. <br>• Store frequently accessed data, or data that needs to be geo-redundant as Multi-Regional Storage. <br><br>B) Since the raw data are save based on the vehicles' location all over the world, moving them to a centralized region without preprocessing and compressing would incur additional between-region data egress cost <br><br>C) Dataproc is Zone-specific resources and since you want to run this job on all data and data consumption occurs in a centralized location, then moving the data into a multi-region bucket for Dataproc cluster jobs is not most cost effective. <br><br>Use a multi-regional location when you want to serve content to data consumers that are outside of the Google network and distributed across large geographic areas. <br>• Store frequently accessed data, or data that needs to be geo-redundant as Multi-Regional Storage.</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">Your company just finished a rapid lift and shift to Google Compute Engine for your compute needs. You have another 9 months to design and deploy a more cloud-native solution. Specifically, you want a system that is no-ops and auto-scaling. Which options of following compute products should you choose? <br><br>Choose 2 answers:<br>[ ] A) Google Container Engine with containers <br>[ ] B) Compute Engine with custom instance types<br>[ ] C) Google App Engine Standard Environment<br>[ ] D) Compute Engine with containers<br>[ ] E) Compute Engine with managed instance groups</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct Answer A and C <br><br>Feedback: <br>Ordering the answers from most to least &quot;no-ops&quot; since &quot;you want a system that is no-ops and auto-scaling.&quot;: <br><br>C) (Part of correct answer): This is most to &quot;no-ops and auto-scaling&quot; since App Engine is fully managed. <br><br>A) (Part of correct answer): The 2nd most toward &quot;no-ops&quot; <br><br>D) The Third most to &quot;no-ops&quot; <br><br>E) The least to &quot;no-ops&quot;, but the instance could be predefined or custom type, so put it slightly closer to &quot;no-ops&quot; than answer B <br><br>B The least &quot;no-ops&quot; <br><br>Note: You may also consider D, E, and B as similar level of &quot;no-ops&quot; <br><br>Also, C (AppEngine) and A (Container Engine) both have the autoscale capability <br><br>So, the correct answers are A and C <br><br>Reference Resource:<br>You can imagine a spectrum where, at one end, you have most of the responsibilities for resource management and, at the other end, <br><br>Google has most of those responsibilities: <br>https://cloud.google.com/docs/images/overview/ops-continuum.svg</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">Your company's test suite is a custom C++ application that runs tests throughout each day on Linux virtual machines. The full test suite takes several hours to complete, running on a limited number of on premises servers reserved for testing. Your company wants to move the testing infrastructure to the cloud, to reduce the amount of time it takes to fully test a change to the system, while changing the tests as little as possible. <br><br>Which cloud infrastructure should you recommend? <br>[ ] A) Google Cloud Dataproc to run Apache Hadoop jobs to process each test <br>[ ] B) Google App Engine with Google Stackdriver for logging <br>[ ] C) Google Compute Engine managed instance groups with auto-scaling <br>[ ] D) Google Compute Engine unmanaged instance groups and Network Load Balancer</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct Answer C Feedback <br><br>A) Apache Hadoop run Java not C++; If the questions meant to use Hadoop to manage and process the test, it's overkill and also need significant changes to the testing infrastructure to integrate with Dataproc. <br><br>B) App Engine did not natively support C++, also it's probably hard to port their &quot;runs tests throughout each day on Linux virtual machines&quot; to App Engine &quot;while changing the tests as little as possible&quot;; StackDriver logging won't help porting the test to GCP, either. <br><br>Between C and D, the main difference is managed or unmanaged instance group <br><br>Unmanaged instance groups are groups of dissimilar instances that you can arbitrarily add and remove from the group. Unmanaged instance groups do not offer autoscaling, rolling update support, or the use of instance templates so Google recommends creating managed instance groups whenever possible. Use unmanaged instance groups only if you need to apply load balancing to your pre-existing configurations or to groups of dissimilar instances. <br><br>https://cloud.google.com/compute/docs/instance-groups/ <br><br>From the question there is no such requirement for unmanaged instance group and not mention that dissimilar Linux machine types are required. <br><br>In addition, judging from what they suffered &quot;The full test suite takes several hours to complete, running on a limited number of on premises servers&quot;, it seems they simply need more computation power - bigger and/or more instances for the testing. So the managed instance group with autoscaling is the preferred.</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">Operational parameters such as oil pressure are adjustable on each of TerramEarth's vehicles to increase their efficiency, depending on their environmental conditions. Your primary goal is to increase the operating efficiency of all 20 million cellular and unconnected vehicles in the field. <br><br>How can you accomplish this goal?<br>[ ] A) Have your engineers inspect the data for patterns, and then create an algorithm with rules that make operational adjustments automatically. <br>[ ] B) Implement a Google Cloud Dataflow streaming job with a sliding window and use Google Cloud Messaging (GCM) to make operational adjustments automatically. <br>[ ] C) Capture all operating data, train machine learning models that identify ideal operations, and host in Google Cloud Machine Learning (ML) Platform to make operational adjustments automatically. <br>[ ] D) Capture all operating data, train machine learning models that identify ideal operations, and run locally to make operational adjustments automatically.</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct Answer D <br><br>Feedback:<br>A) This won't work - the engineer simply won't be able just to inspect the data for patterns for 20 million vehicles whether the algorithm created run local or in-cloud <br><br>B) Without data analytics and machine learning, the two technologies just won't create meaningful algorithm for operational adjustments automatically. Besides, majority (99%) of the 20M vehicles are unconnected and the two technologies have to run on GCP for scalability so there is no way to communicated between local and GCP for adjustments automatically. <br><br>C) Again, majority (99%) of the 20M vehicles are unconnected and if the trained model was host in Google Cloud Machine Learning (ML) Platform then there is no way to use the model generated parameters to command the field vehicles to make operational adjustments automatically. <br><br>D) (Correct Answer) After creating good ML model by &quot;Capture all operating data, train machine learning models that identify ideal operations&quot;, you can run the model in the vehicle to make operational adjustments automatically based on each specific vehicle's parameters. Probably run the model in the onboard computer or computer connected to the maintenance port. <br><br>TerramEarth connection related Information in the Case Study. There are 20 million TerramEarth vehicles in operation that collect 120 fields of data per second. Data is stored locally on the vehicle and can be accessed for analysis when a vehicle is serviced. The data is downloaded via a maintenance port. This same port can be used to adjust operational parameters, allowing the vehicles to be upgraded in the field with new computing modules. <br><br>Approximately 200,000 vehicles are connected to a cellular network, allowing TerramEarth to collect data directly.</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">You need to regularly create disk level backups of the root disk of a critical instance. These backups need to be able to be converted into new instances that can be used in different projects. <br><br>How should you do this?<br>[ ] A) Create snapshots, turn the snapshot into a custom image, and share the image across projects. <br>[ ] B) Use the VM migration tools in Compute Engine to copy a VM to a different project. <br>[ ] C) Create snapshots and share them to other projects. <br>[ ] D) Stream your VM's data into Cloud Storage and share the exported data in the storage bucket with another project</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct Answer A <br><br>Explanation:<br>A) (Correct answer) - The proper method is to create a custom image either from an existing, stopped instance, or snapshots of a boot disk, which can then be shared across projects and used to create additional instances. <br><br>https://cloud.google.com/compute/docs/instances/create-start-instance <br><br>B) Is for migration not for &quot;regularly create disk level backups of the root disk of a critical instance&quot;. There are tools allowing copying (importing) on-premises virtual disk to Compute engine but you cannot copy GCP VM. <br><br>C) Snapshots cannot be shared across projects. <br><br>D) Doesn't meet the requirement &quot;regularly create disk level backups of the root disk of a critical instance&quot; nor is it easy to convert into new instance.</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">Your company has decided to build a backup replica of their on-premises user authentication PostgreSQL database on Google Cloud Platform. The database is 4 TB, and large updates are frequent. Replication requires private address space communication. <br><br>Which networking approach should you use? <br>[ ] A) A Google Compute Engine instance with a VPN server installed connected to the data center network <br>[ ] B) A NAT and TLS translation gateway installed on-premises <br>[ ] C) Google Cloud Dedicated Interconnect <br>[ ] D) Google Cloud VPN connected to the data center network</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct Answer C <br><br>Explanation:<br><br>A) Single interconnect can be a single 10G link or a link bundle, connected to a single Google router.<br><br>B) Does not exist.<br><br>Answer A and B either are not applicable or feature doesn't not exist. <br><br>C) (Correct answer) Both VPN and Dedicated Interconnect provide private address space communication. &quot;The database is 4 TB, and large updates are frequent&quot; makes the Dedicated Interconnect a suitable solution due to its bandwidth capability and SLA <br><br>D) Each VPN tunnel has a max speed of 1.5 Gbps, though you can create multiple VPN tunnels to increase bandwidth, the internet connection from on-premises to GCP may be also a limiting factor <br><br>Let assume VPN can reach to 1.5 Gbps speed, to transfer 4 TB data, you need: <br><br>4000 * 1024/1.5 = 4096000 seconds, Approximately equal 47.4 days. <br><br>This is maximum for full set of data replicating, though it won't really happen, but the math is here for the reference <br><br>Reference <br><br>Google Cloud Interconnect https://cloud.google.com/interconnect/ <br><br>Dedicated Interconnect Overview<br>https://cloud.google.com/interconnect/docs/concepts/dedicated-overview<br><br>Diagram: https://s3.amazonaws.com/whizlabs-pub/GCP+Professional+Cloud+Architect+Images/GCP+PCA_PT1/PT1_Q13.png</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">JencoMart wants to migrate their current computing environment to GCP. They want to modify their existing setup to scale for peak traffic instead of needing to provision in advance to meet peak load. When scaling, they want their machines to have as identical of performance as possible to their existing servers. What two actions can they take? <br><br>Choose two:<br>[ ] A) Convert their compute environment into an App Engine application.<br>[ ] B) Set machine type to a custom machine type to match their current individual machines. <br>[ ] C) Select the next step higher standard machine type to allow for capacity.<br>[ ] D) Create a managed instance group with autoscaling enabled to scale with demand.</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct answer B and D <br><br>Explanation <br><br>While they technically could convert their application into App Engine, it is not necessary to do so. A managed instance group that auto scales would meet their capacity requirements. For each instance group machine, they can use a custom machine type to match their current machine environment. <br><br>JencoMart Existing Technical Environment <br><br>JencoMart hosts all of its applications in 4 data centers: 3 in North American and 1 in Europe; most applications are dual-homed. ... ... ... <br><br>Compute<br>• 30 machines in US West Coast, each machine has: <br>• Twin, dual core CPUs<br>• 32GB of RAM<br>• Twin 250 GB HDD (RAID 1) <br>• 20 machines in US East Coast, each machine has: <br>• Single, dual-core CPU<br>• 24 GB of RAM<br>• Twin 250 GB HDD (RAID 1)</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">Your company has successfully migrated to the cloud and wants to analyze their data stream to optimize operations. They do not have any existing code for this analysis, so they are exploring all their options. These options include a mix of batch and stream processing, as they are running some hourly jobs and live-processing some data as it comes in. <br><br>Which technology should they use for this? <br>[ ] A) Google Cloud Dataflow<br>[ ] B) Google Compute Engine with Google BigQuery<br>[ ] C) Google Container Engine with Bigtable<br>[ ] D) Google Cloud Dataproc</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct Answer A <br><br>Feedback <br><br>Cloud Dataflow (https://cloud.google.com/dataflow/) is a fully-managed service for transforming and enriching data in stream (real time) and batch (historical) modes with equal reliability and expressiveness - no more complex workarounds or compromises needed. And with its serverless approach to resource provisioning and management, you have access to virtually limitless capacity to solve your biggest data processing challenges, while paying only for what you use. <br><br>Cloud Dataflow unlocks transformational use cases across industries, including: <br>• check Clickstream, Point-of-Sale, and segmentation analysis in retail<br>• check Fraud detection in financial services<br>• check Personalized user experience in gaming<br>• check IoT analytics in manufacturing, healthcare, and logistics<br><br>Dataflow acts as your data processing pipeline for ETL functions on both streaming and batch data. <br>Diagram: https://s3.amazonaws.com/whizlabs-pub/GCP+Professional+Cloud+Architect+Images/GCP+PCA_PT1/PT1_Q15.png</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">JencoMart is evaluating what managed services (if any) they can migrate their databases to, and which databases will need to be modified to do so. Of their Oracle and PostgreSQL databases, which one needs to be modified, and what service(s) can they move to? <br><br>Choose two:<br>[ ] A) Oracle will need to be modified into a relational database and can be hosted on Cloud Spanner. <br>[ ] B) PostgreSQL will need to be modified to NoSQL and can be hosted on Datastore.<br>[ ] C) Oracle can be imported without modification and can be hosted on Cloud Bigtable. <br>[ ] D) PostgreSQL can be imported without modification and can be hosted on Cloud SQL.</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct answer A and D <br><br>Explanation <br><br>Oracle is a relational database and cannot be imported into a managed GCP storage option. It will need to be converted to a relational database and can be hosted on Cloud Spanner. Although Cloud SQL would be the more direct 'lift and shift' option, it only holds up to 10TB (their existing database is 20TB) and Spanner can support that amount using additional nodes. PostgreSQL can be migrated in its current form, as Cloud SQL natively supports PostgreSQL as well. <br><br>JencoMart Existing Technical Environment - Database<br>Oracle Database stores user profiles<br>• 20 TB<br>PostgreSQL database stores user credentials</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">You have created several preemptible Linux virtual machine instances using Google Compute Engine. You want to properly shut down your application before the virtual machines are preempted. <br><br>What should you do? <br>[ ] A) Create a shutdown script registered as a xinetd service in Linux and configure a StackDriver endpoint check to call the service.<br>[ ] B) Create a shutdown script, registered as a xinetd service in Linux, and use the gcloud compute instances add-metadata command to specify the service URL as the value for a new metadata entry with the key shutdown-script-url<br>[ ] C) Create a shutdown script named k99.shutdown in the /etc/rc.6.d/ directory. <br>[ ] D) Create a shutdown script and use it as the value for a new metadata entry with the key shutdown-script in the Cloud Platform Console when you create the new virtual machine instance.</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct Answer D <br><br>Feedback <br><br>Running Shutdown Scripts: Create and run shutdown scripts that execute commands right before an instance is terminated or restarted, on a best-effort basis. This is useful if you rely on automated scripts to start up and shut down instances, allowing instances time to clean up or perform tasks, such as exporting logs, or syncing with other systems. https://cloud.google.com/compute/docs/shutdownscript <br><br>To setup Shutdown Scripts, go to GCP console and follow the steps: <br>Compute Engine -&gt; VM instance -&gt; Create Instance -&gt; (Expand) Management, disks, networking, SSH keys <br><br>Enter the key &quot;shutdown-script&quot; and proper value (Diagram Link): https://s3.amazonaws.com/whizlabs-pub/GCP+Professional+Cloud+Architect+Images/GCP+PCA_PT1/PT1_Q17.png</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">You need to allow traffic from specific virtual machines in 'subnet-a' network access to machines in 'subnet-b' without giving the entirety of subnet-a access. <br><br>How can you accomplish this?<br>[ ] A) Create a firewall rule to allow traffic from resources with specific network tags, then assign the machines in subnet-a the same tags.<br>[ ] B) Relocate the subnet-a machines to a different subnet and give the new subnet the needed access.<br>[ ] C) Create a rule to deny all traffic to the entire subnet, then create a second rule with higher priority giving access to tagged VM's in subnet-a.<br>[ ] D) You can only grant firewall access to an entire subnet and not individual VM's inside.</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct Answer A <br><br>Explanation <br><br>A) (Correct answer) Network tags allow more granular access based on individually tagged instances - Instances by target tags: The firewall rule is applicable only to VMs if they have a matching network tag. <br><br>B) This would give the entire subnet access which is against the requirements: allow traffic from specific virtual machines in 'subnet-a' network access to machines in 'subnet-b' without giving the entirety of subnet-a access. <br><br>C) Creating overlapping rules with higher priority might technically work, but since traffic defaults to denied if no rule is in place, this is unnecessary. Assigning rules and instances by tags is the best answer. <br><br>D) This is not true per answer A</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">A news feed web service has the following code running on Google App Engine. During peak load, users report that they can see news articles they already viewed. <br><br>1. import news<br>2. from flash import flask, redirect request<br>3. from flask.ext.api import status<br>4. from google.appengineapl import users<br>5. app = falsk (__name__)<br>6. sessions = {}<br>7. @app. Route (&quot;/&quot;)<br>8. def homepage ():<br>9. user = users.get current_user ()<br>10. if not user:<br>11. return &quot;invalid login&quot;, status.http_401_uhautorized<br>12. if user not in session:<br>13. sessions [user] {&quot;viewed&quot;} : []}<br>14. news_articles = news.get_new_news (user, session [user] {&quot;viewed&quot;}<br>15. sessions[user] {&quot;viewed&quot;} += [n[&quot;id&quot;] for n in news_artides]<br>16. return news, render (news articles)<br>17. if __name__ == &quot;__main__&quot;:<br>18. app.run()<br><br>What is the most likely cause of this problem?<br> <br>[ ] A) The session variable is local to just a single instance. <br>[ ] B) The session variable is being overwritten in Cloud Datastore.<br>[ ] C) The URL of the API needs to be modified to prevent caching. <br>[ ] D) The HTTP Expires header needs to be set to -1 to stop caching.</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct Answer A <br><br>Detailed Explanation <br><br>Answer A is the correct - The session variable is local to just a single instance. <br><br>The question described &quot;users report that they can see news articles they already viewed&quot;, which means the correct behavior is, user should only be able to read article they did not reviewed before. <br><br>Here is how: <br><br>Line 6 declared new session variable: sesions = {}, initially is empty<br>Then the code somehow gets the all user, and somehow get the article<br>Line 13, 14, 15: basically, save the article(s) the current specific user viewed in session variable. The sessios variable is key value pair data type, key is &quot;viewed&quot;, value is a list VIEWED [article 1, article 2...]. Of course, if THE user just started or never viewed nay article, the list would be empty <br>Remember that session variable host list articles only if they viewed by that user <br><br>Then you deploy and run the app in AppEngine. &quot;During peak load&quot; most likely means you have many instances run the same codebase independently from each other. If a user hit instance #9, read an article A, then made another request, most likely he'd hit another instance, say #1000. The session variable in the code running in instance #1000 would not have had that information and the article A might be displayed again treated as not viewed before.</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">One of the microservices in your application has an intermittent performance problem. You have not observed the problem when it occurs but when it does, it triggers a particular burst of log lines. You want to debug a machine while the problem is occurring. <br><br>What should you do? <br>[ ] A) Log into one of the machines running the microservice and wait for the log storm.<br>[ ] B) In the Stackdriver Error Reporting dashboard, look for a pattern in the times the problem occurs.<br>[ ] C) Configure your microservice to send traces to Stackdriver Trace so you can find what is taking so long.<br>[ ] D) Set up a log metric in Stackdriver Logging, and then set up an alert to notify you when the number of log lines increases past a threshold.</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct Answer D <br><br>Feedback:<br><br>A) Logging into an individual machine may not see the specific performance problem as multiple machines may be in the configuration and reducing the chances of interacting with an intermittent performance problem. <br><br>B) Error reporting won't necessarily catch the log lines unless they are stack traces in the proper format. Additionally, just because there is a pattern doesn't mean you will know exactly when and where to log in to debug. <br><br>C) Trace may tell you where time is being spent but won't let you know in on the exact host that the problem is occurring on because you generally only send samples of traces. There is also no alerting on traces to notify exactly when the problem is happening. <br><br>D) (Correct Answer) - Since you know that there is a burst of log lines you can set up a metric that identifies those lines. Stackdriver will also allow you to set up a text, email or messaging alert that can notify promptly when the error is detected so you can hop onto the system to debug. <br><br>Additional Resource:<br>https://cloud.google.com/logging/docs/logs-based-metrics/</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">To ensure that your application will handle the load even if an entire zone fails, what should you do? <br>[ ] A) Don't select the &quot;Multizone&quot; option when creating your managed instance group.<br>[ ] B) Spread your managed instance group over two zones and overprovision by 100%. (for Two Zone)<br>[ ] C) Create a regional unmanaged instance group and spread your instances across multiple zones.<br>[ ] D) Overprovision your regional managed instance group by at least 50%. (for Three Zones)</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct answer B and D <br><br>Feedback:<br><br>B) is correct if one zone fails you still have 100% desired capacity in another zone <br><br>D) is correct since you have at least total 150% desired capacity spread over 3 zones, each zone has 50% capacity. You'll have 100% desired capacity in two zones if any single zone failed at given time. <br><br>Reference Resources: <br>https://cloud.google.com/compute/docs/instance-groups/distributing-instances-with-regional-instance-groups <br><br>If you are creating a regional managed instance group in a region with at least three zones, Google recommends overprovisioning your instance group by at least 50%.</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">You are creating a single preemptible VM instance named &quot;preempt&quot; to be used as scratch space for a single workload. If your VM is preempted, you need to ensure that disk contents can be re-used. <br><br>Which gcloud command would you use to create this instance? <br>[ ] A) gcloud compute instances create &quot;preempt&quot; --preemptible --no-boot-disk-auto-delete<br>[ ] B) gcloud compute instances create &quot;preempt&quot; --preemptible --boot-disk-auto-delete=no<br>[ ] C) gcloud compute instances create &quot;preempt&quot; --preemptible<br>[ ] D) gcloud compute instances create &quot;preempt&quot; --no-auto-delete</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct Answer A <br><br>Explanation <br><br>A (Correct answer) - Specifying '--no-boot-disk-auto-delete' preserves the disk. This flag is not enabled by default so if not specify, it causes the disk to be auto-deleted. <br><br>B - The default is boot disk automatically delete and no flag needed, also the syntax is incorrect for this type of flags <br><br>C - if you don't specify '--no-boot-disk-auto-delete'. The default would be boot disk automatically delete Here is the corresponding console setting displaying the default option (Diagram Link):<br>https://s3.amazonaws.com/whizlabs-pub/GCP+Professional+Cloud+Architect+Images/GCP+PCA_PT1/PT1_Q22.png<br><br>D - when instance created without this flag: --preemptible, it'll be standard instance <br><br>Here is the corresponding console setting in &quot;Availability Policy&quot; when you create instance with --preemptible flag (Diagram Link):<br>https://s3.amazonaws.com/whizlabs-pub/GCP+Professional+Cloud+Architect+Images/GCP+PCA_PT1/PT1_Q22.1.png</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">You want to make a copy of a production Linux virtual machine in the US-Central region. You want to manage and replace the copy easily if there are changes on the production virtual machine. You will deploy the copy as a new instance in a different project in the US-East region. <br><br>What steps must you take? <br>[ ] A) Use the Linux dd and netcat commands to copy and stream the root disk contents to a new virtual machine instance in the US-East region.<br>[ ] B) Create a snapshot of the root disk and select the snapshot as the root disk when you create a new virtual machine instance in the US-East region.<br>[ ] C) Create an image file from the root disk with Linux dd command, create a new disk from the image file, and use it to create a new virtual machine instance in the US-East region.<br>[ ] D) Create a snapshot of the root disk, create an image file in Google Cloud Storage from the snapshot, and create a new virtual machine instance in the US-East region using the image file for the root disk.</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct Answer D <br><br>Feedback:<br>A) This approach affects performance of the existing machine and incurs significant network costs. <br><br>B) This approach does not allow you to create the VM in the new project since snapshots are limited to the project in which they are taken. <br><br>C) dd will not work correctly on a mounted disk. <br><br>D) (Correct Answer) - This approach meets all of the requirements, it is easy to do and works cross project and cross region. <br><br>Reference Resources:<br>https://cloud.google.com/compute/docs/images/sharing-images-across-projects</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">A lead software engineer tells you that his new application design uses websockets and HTTP sessions that are not distributed across the web servers. You want to help him ensure his application will run properly on Google Cloud Platform. <br><br>What should you do? <br>[ ] A) Help the engineer to convert his websocket code to use HTTP streaming. <br>[ ] B) Review the encryption requirements for websocket connections with the security team. <br>[ ] C) Meet with the cloud operations team and the engineer to discuss load balancer options.<br>[ ] D) Help the engineer redesign the application to use a distributed user session service that does not rely on websockets and HTTP sessions.</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct Answer C <br><br>Feedback:<br>A) There is no compelling reason to move away from websockets as part of a move to GCP. <br><br>B) This may be a good exercise anyway, but it doesn't really have any bearing on the GCP migration. <br><br>C) (Correct Answer) The HTTP(S) load balancer in GCP handles websocket traffic natively. Backends that use WebSocket to communicate with clients can use the HTTP(S) load balancer as a front end, for scale and availability. <br><br>D) There is no compelling reason to move away from websockets as part of a move to GCP.</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">JencoMart has decided to migrate user profile storage to Google Cloud Datastore and the application servers to Google Compute Engine (GCE). During the migration, the existing infrastructure will need access to Datastore to upload the data. <br><br>What service account key-management strategy should you recommend?<br>[ ] A) Provision service account keys for the on-premises infrastructure and use Google Cloud Platform (GCP) managed keys for the VMs <br>[ ] B) Authenticate the on-premises infrastructure with a user account and provision service account keys for the VMs.<br>[ ] C) Deploy a custom authentication service on GCE/Google Container Engine (GKE) for the on-premises infrastructure and use GCP managed keys for the VMs.<br>[ ] D) Provision service account keys for the on-premises infrastructure and for the GCE virtual machines (VMs).</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct Answer A <br><br>Feedback:<br><br>A) (correct answer) This addresses both of data migration and application server migration properly. <br><br>&quot;Provision service account keys for the on-premises infrastructure&quot;: For code running on systems outside Google, you cannot use GCP-managed keys. You need to create Service account for it and provision User-managed keys. These keys are created, downloadable, and managed by users - This is solution for on-premises access to GCP datastore during migration <br><br>&quot;use Google Cloud Platform (GCP) managed keys for the VMs&quot; - this is solution for Application server migration since there is no external access to GCP is required during the migration. <br><br>Answer B is incorrect: First, the applications running on-premises to access GCP Datastore assume the identity of the service account to call Google APIs, so that the users aren't directly involved. <br><br>Secondly, for the application server migration to GCP VMs, you can use GCP managed keys for the VMs. It's simple and effective. There is no need to provision and manage keys (User-managed keys) by yourself for the VMs. <br><br>GCP-managed keys are used by Cloud Platform services such as App Engine and Compute Engine. These keys cannot be downloaded. Google will keep the keys and automatically rotate them on an approximately weekly basis. <br><br>C) is incorrect in the solution for on-premises access to GCP Datastore - This is possible options that might require more setup than worthwhile for the requirements. <br><br>D) is incorrect for reason of application server migration: you can use GCP managed keys for the VMs. It's simple and effective. There is no need to provision and manage keys (User-managed keys) by yourself for the application VMs</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">Your company processes high volumes of IoT data that are time-stamped. The total data volume can be several petabytes. The data needs to be written and changed at a high speed. You want to use the most performant storage option for your data. <br><br>Which product should you use? <br>[ ] A) Cloud Datastore <br>[ ] B) Cloud Storage<br>[ ] C) Cloud Bigtable <br>[ ] D) BigQuery</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct answer C <br><br>Feedback:<br>A) is not correct because Cloud Datastore is not the most performant product for frequent writes or timestamp-based queries. <br><br>B) is not correct because Cloud Storage is designed for object storage not for this type of data ingestion and collection. <br><br>C) is correct because Cloud Bigtable is the most performant storage option to work with IoT and time series data. <br><br>D) is not correct because although it can store the data, BigQuery is very slow at changing data. <br><br>Reference:<br>Cloud Bigtable Schema Design for Time Series Data: <br><br>https://cloud.google.com/bigtable/docs/schema-design-time-series</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">You set up an autoscaling instance group to serve web traffic for an upcoming launch. After configuring the instance group as a backend service to an HTTP(S) load balancer, you notice that virtual machine (VM) instances are being terminated and re-launched every minute. The instances do not have a public IP address. You have verified the appropriate web response is coming from each instance using the curl command. You want to ensure the backend is configured correctly. <br><br>What should you do? <br>[ ] A) Ensure that a firewall rule exists to allow source traffic on HTTP/HTTPS to reach the load balancer. <br>[ ] B) Create a tag on each instance with the name of the load balancer. Configure a firewall rule with the name of the load balancer as the source and the instance tag as the destination. <br>[ ] C) Ensure that a firewall rule exists to allow load balancer health checks to reach the instances in the instance group. <br>[ ] D) Assign a public IP to each instance and configure a firewall rule to allow the load balancer to reach the instance public IP.</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct Answer C <br><br>Feedback:<br>A) Firewall controls access at instance level, not load balancer. Must allow load balancer traffic to connect backend instance allowing health check <br><br>B) At this moment it is not possible to set firewall rules over the GCE Load Balancers. You need to create firewall rules that at subnet or instances level allowing specific health check IP ranges (See Answer A above), not the LB tags, to connect to all your load balanced instances. <br><br>C) (correct answer) HTTP health check probes are sent from the IP ranges depending on LB types used. These are IP address ranges that the load balancer uses to connect to backend instances. You must create firewall rules that allows traffic from those ranges to reach your instances <br><br>For Network load balancing <br><br>When a health check is used with Network load balancing, the health check probes come from addresses in the ranges 209.85.152.0/22, 209.85.204.0/22, and 35.191.0.0/16. <br><br>For HTTP(S). SSL proxy. TCP proxy, and Internal load balancing<br>When a health check is used with HTTP(S), SSL proxy, TCP proxy, or Internal load balancing, the health check probes come from addresses in the ranges 130.211.0.0/22 and 35.191.0.0/16. <br><br>D) This is not mandatory since your LB could be Internal load balancing so instances' external IPs may be removed</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">You are working on a project with two compliance requirements. The first requirement states that your developers should be able to see the Google Cloud Platform billing charges for only their own projects. The second requirement states that your finance team members can set budgets and view the current charges for all projects in the organization. The finance team should not be able to view the project contents. You want to set permissions. <br><br>What should you do? <br>[ ] A) Add the finance team members to the default IAM Owner role. Add the developers to a custom role that allows them to see their own spend only. <br>[ ] B) Add the finance team members to the Billing Administrator role for each of the billing accounts that they need to manage. Add the developers to the Viewer role for the Project. <br>[ ] C) Add the developers and finance managers to the Viewer role for the Project. <br>[ ] D) Add the finance team to the Viewer role for the Project. Add the developers to the Security Reviewer role for each of the billing accounts.</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct answer B <br><br>Feedback:<br>B) (Correct Answer) Is correct because it uses the principle of least privilege for IAM roles; use the Billing Administrator IAM role for that job function. <br><br>A, C, and D are not correct because is it a Google best practice to use pre-defined IAM roles when they exist and match your business scenario; see the link below. <br><br>Reference<br>IAM for Billing:</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">Dress4Win has configured a new uptime check with Google Stackdriver for several of their legacy services. The Stackdriver dashboard is not reporting the services as healthy. <br><br>What should they do?<br>[ ] A) In the Cloud Platform Console download the list of the uptime servers' IP addresses and create an inbound firewall rule <br>[ ] B) Install the Stackdriver agent on all of the legacy web servers. <br>[ ] C) Configure their legacy web servers to allow requests that contain user-Agent HTTP header when the value matches GoogleStackdriverMonitoring- UptimeChecks (https://cloud.google.com/monitoring) <br>[ ] D) Configure their load balancer to pass through the User-Agent HTTP header when the value matches GoogleStackdriverMonitoring-UptimeChecks (https://cloud.google.com/monitoring)</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct Answer A <br><br>Explanation <br><br>A) (Correct Answer) &quot;If you are checking a service that is behind a firewall, you can configure your service's firewall to accept traffic from the current set of IP addresses used for uptime checking (Getting uptime-check IP addresses <br><br>https://cloud.google.com/monitoring/uptime-checks/#monitoring_uptime_check_list_ips-console). https://cloud.google.com/monitoring/uptime-checks/#identifying_uptime_check_traffic): <br><br>GoogleStackdriverMonitoring-UptimeChecks <br>(https://cloud.google.com/monitoring): <br><br>Regardless on instance or LoadBalancer level, as long as the firewall allowed, this user-agent can pass through; also, there is no feature supporting User-Agent header value associated firewall rule configuration. <br><br>Additional Resource <br><br>For your quick reference, here are the part of Dress4win existing Application servers in a single data center location: <br>• Tomcat - Java micro-services<br>• Nginx - static content<br>• Apache Beam - Batch processing</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">In moving their test and development environments to Google Cloud, what is the best practice for Dress4Win to follow to ensure proper isolation between both environments using the principle of least privilege? <br>[ ] A) Separate the test and dev environments into different projects, giving each team access to only their own projects. <br>[ ] B) Separate the test and dev environments into different projects, with each team sharing a single account to access each. <br>[ ] C) Host both environments in the same project but different VPC's. <br>[ ] D) Separate the test and dev environments into different projects, with different levels of access for each team.</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct Answer A <br><br>Explanation <br><br>A) (Correct answer) For least privilege and separation of duties, the best practice is to separate both environments into different projects, development or test team gets their own accounts, and each team is assigned to only their projects. <br><br>The best practices: <br>• You should not use same account for both Development and Test environments regardless how do you create projects inside that account for different environments. You should use different account for each environment which associated with different group of users. You should use project to isolate user access to resource not to manage users. <br><br>• Using a shared VPC allows each team to individually manage their own application resources, while enabling each application to communicate between each other securely over RFC1918 address space. So VPC's isolate resources but not user/service accounts. <br><br>Answers B, C, and D are incorrect <br><br>B) is the scenario that use same account for both development and test environments attempting to isolate user access with different projects <br><br>C) is the scenario that use same account for both development and test environments with same project attempting to isolate user access with network separation. Note, VPC's isolate resources but not user or service accounts. <br><br>D) is the scenario that use same account for both development and test environments attempting to isolate user access with different projects <br><br>You can add team members to projects you own and grant the members different levels of access to the project's resources and APIs. This is not the best practice for managing users and their privileges with different environments. It might work for small shop but not for the origination size like Dress4Win. <br><br>Reference Resources <br>Here is the Dress4Win Solution Concept (partial): <br><br>&quot;For the first phase of their migration to the cloud, Dress4win is considering moving their development and test environments...&quot;</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">Mountkirk Games wants to set up a real-time analytics platform for their new game. The new platform must meet their technical requirements. <br><br>Which combination of Google technologies will meet all of their requirements?<br>[ ] A) Cloud Dataflow, Cloud Storage, Cloud Pub/Sub, and BigQuery <br>[ ] B) Cloud SQL, Cloud Storage, Cloud Pub/Sub, and Cloud Dataflow <br>[ ] C) Container Engine, Cloud Pub/Sub, and Cloud SQL <br>[ ] D) Cloud Pub/Sub, Compute Engine, Cloud Storage, and Cloud Dataproc <br>[ ] E) Cloud Dataproc, Cloud Pub/Sub, Cloud SQL, and Cloud Dataflow</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct Answer A <br><br>Feedback <br><br>(see Mountkirk Games case study for details or below for briefing summary) <br><br>For requirements: Process incoming data on the fly directly from the game servers - Cloud Dataflow (Both <br>Stream and Batch), reference architect component , we can eliminate C and D since they don't have DataFlow <br>C - Container Engine, Cloud Pub/Sub, and Cloud SQL <br>D - Cloud Pub/Sub, Compute Engine, Cloud Storage, and Cloud Dataproc <br>For requirements: Allow SQL queries to access at least 10 TB of historical data - BigQuery, reference architect <br><br>component, we can eliminate B and E since they don't have BigQuery <br><br>B - Cloud SQL, Cloud Storage, Cloud Pub/Sub, and Cloud Dataflow <br><br>E - Cloud Dataproc, Cloud Pub/Sub, Cloud SQL, and Cloud Dataflow <br><br>The only correct answer left is A, which meets all of their requirements <br><br>A - Cloud Dataflow, Cloud Storage, Cloud Pub/Sub, and BigQuery <br><br>Below is a reference architect Google recommending for similar scenario in data collection and analysis <br><br>https://cloud.google.com/solutions/mobile/mobile-gaming-analysis-telemetry <br><br>Building a Mobile Gaming Analytics Platform - a Reference Architecture (Diagram Link):<br>https://s3.amazonaws.com/whizlabs-pub/GCP+Professional+Cloud+Architect+Images/GCP+PCA_PT1/PT1_Q31.png<br><br>Mountkirk Games real-time analytics platform <br><br>Solution Concept <br><br>Mountkirk Games is building a new game, which they expect to be very popular. They plan to deploy the game's backend on Google Compute Engine so they can capture streaming metrics, run intensive analytics, and take advantage of its autoscaling server environment and integrate with a managed NoSQL database. <br><br>Technical Requirements <br><br>Requirements for Game Analytics Platform<br>• Dynamically scale up or down based on game activity - Compute engine, container engine, Cloud Storage<br>• Process incoming data on the fly directly from the game servers - Cloud Dataflow (Both Stream and Batch) <br>• Process data that arrives late because of slow mobile networks - Cloud Pub/Sub<br>• Allow SQL queries to access at least 10 TB of historical data - BigQuery<br>• Process files that are regularly uploaded by users' mobile devices - Cloud Pub/Sub<br>• Use only fully managed services - BigQuery, DataFlow, Cloud SQL</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">Your company is forecasting a sharp increase in the number and size of Apache Spark and Hadoop jobs being run on your local datacenter. You want to utilize the cloud to help you scale this upcoming demand with the least amount of operations work and code change.<br> <br>Which product should you use?<br>[ ] A) Google Cloud Dataflow <br>[ ] B) Google Compute Engine <br>[ ] C) Google Container Engine <br>[ ] D) Google Cloud Dataproc</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct Answer D <br><br>Feedback <br><br>Cloud Dataproc is the only choice in the answers you can (almost) directly map to your on-premises Apache Spark/Hadoop platform and meet the requirements &quot;scale this upcoming demand with the least amount of operations work and code change&quot;. <br><br>Cloud Dataproc is a fast, easy-to-use, fully-managed cloud service for running Apache Spark and Apache Hadoop clusters in a simpler, more cost-efficient way. Operations that used to take hours or days take seconds or minutes instead, and you pay only for the resources you use (with per-second billing). Cloud Dataproc also easily integrates with other Google Cloud Platform (GCP) services, giving you a powerful and complete platform for data processing, analytics and machine learning. <br>https://cloud.google.com/dataproc/</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">Your customer is receiving reports that their recently updated Google App Engine application is taking approximately 30 seconds to load for some of their users. This behavior was not reported before the update. <br><br>What strategy should you take? <br>[ ] A) Work with your ISP to diagnose the problem. <br>[ ] B) Open a support ticket to ask for network capture and flow data to diagnose the problem, then roll back your application. <br>[ ] C) Roll back to an earlier known good release initially, then use Stackdriver Trace and logging to diagnose the problem in a development/test/staging environment. <br>[ ] D) Roll back to an earlier known good release, then push the release again at a quieter period to investigate. Then use Stackdriver Trace and logging to diagnose the problem.</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct Answer C <br><br>Explanation <br><br>A - You ISP normally won't help in this level. Also, the problem most likely is caused by recent update. The good approach is to rollback first and then investigate later. Similarly, this also apply to answer B. <br><br>To investigate this kind of issue, use Stackdriver Trace and logging to diagnose the bottleneck <br><br>C and D have something in common for both &quot;use Stackdriver Trace and logging&quot;, either in test/dev or in production environment and &quot;Roll back to an earlier known good release&quot;. At this moment, only the &quot;earlier known good release&quot; version starts receiving traffic. <br><br>The difference lines between C's &quot;to diagnose the problem in a development/test/staging environment.&quot; and D's &quot;then push the release again at a quieter period to investigate&quot;. <br><br>If you want to debug in production environments, &quot;then push the release again at a quieter period to investigate&quot; is not necessary - you can simply switch &quot;default&quot; version or split the traffic between the &quot;earlier known good release&quot; version and the new problem version. <br><br>Essentially D's &quot;then push the release again at a quieter period to investigate&quot; disqualifies itself as good answer - the default would be the new pushed version (the one with problem) starts receiving traffic &quot;at a quieter period&quot;, and the slow loading users may not present. But with answer C in development/test/staging environment, you can arbitrarily load those suffering users if you know them or simulate production load to reveal the problem users and then do further investigation. <br><br>So, C is the correct answer: First, rollback to &quot;the earlier known good release&quot; and then use the test/dev/staging envs to investigate. <br><br>Additional Resource<br><br>https://cloud.google.com/appengine/docs/flexible/python/testing-and-deploying-your-app</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">TerramEarth plans to connect all 20 million vehicles in the field to the cloud. This increases the volume to 20 million 600 byte records a second for 40 TB an hour. <br><br>How should you design the data ingestion?<br>[ ] A) Vehicles write data directly to GCS. <br>[ ] B) Vehicles stream data directly to Google BigQuery. <br>[ ] C) Vehicles continue to write data using the existing system (FTP). <br>[ ] D) Vehicles write data directly to Google Cloud Pub/Sub.</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct Answer D <br><br>Feedback <br><br>Here is the volume to 20 million 600 byte records a second for 40 TB an hour streaming data need to ingest to and absorb by the system <br><br>A - Vehicles write data directly to GCS - GCS is mainly for storage and it cannot stand for this amount of data streaming ingestion.<br><br>GCS is ideally for Object storage purpose although it has pretty good scalability. It's not suitable for IOT kind of streaming data. Its Buckets initially support roughly 1000 writes per second and then scale as needed. As the request rate for a given bucket grows, Cloud Storage automatically increases the IO capacity for that bucket by distributing the request load across multiple servers. Especially considering the volume to 20 million 600 byte records a second for 40 TB an hour streaming data, it makes unsuitable for this task. <br><br>B - Vehicles stream data directly to Google BigQuery GCS - BigQuery is mainly for BI analysis though it also provides storage capacity and price similar to GCS and it cannot stand for this amount of data streaming ingestion <br><br>C - Vehicles continue to write data using the existing system (FTP) - this is exiting solution we already know it's not scalable. Please refer to the case study for details <br><br>D (Correct answer) - Vehicles write data directly to Google Cloud Pub/Sub - Pub/Sub is acting as 'shock absorber', allowing asynchronous messaging between large numbers of devices.</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">You have data stored in a Cloud Storage dataset and also in a BigQuery dataset. You need to secure the data and provide 3 different types of access levels for your Google Cloud Platform users: administrator, read/write, and read-only. You want to follow Google-recommended practices. <br><br>What should you do? <br>[ ] A) Create 3 custom IAM roles with appropriate policies for the access levels needed for Cloud Storage and BigQuery. Add your users to the appropriate roles. <br>[ ] B) At the Organization level, add your administrator user accounts to the Owner role, add your read/write user accounts to the Editor role, and add your read-only user accounts to the Viewer role. <br>[ ] C) At the Project level, add your administrator user accounts to the Owner role, add your read/write user accounts to the Editor role, and add your read-only user accounts to the Viewer role. <br>[ ] D) Use the appropriate pre-defined IAM roles for each of the access levels needed for Cloud Storage and BigQuery. Add your users to those roles for each of the services.</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct answer D <br><br>Feedback <br><br>D (Correct Answer) - D is correct because the principle of least privilege favors using pre-created roles with associated policies when they match your requirements. <br><br>A, B, and C are not correct because it is a Google best practice to use pre-defined IAM roles when they exist and match your business scenario <br><br>Reference<br>Storage Access Control<br>https://cloud.google.com/storage/docs/access-control/ <br>BigQuery access control <br>https://cloud.google.com/bigquery/docs/access-control <br>IAM Overview <br>https://cloud.google.com/iam/docs/overview <br>Identity and Access Management https://cloud.google.com/iam/docs/overview</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">Your office is connected to GCP via a VPN connection. How can you increase the speed of your VPN connection, assuming that your office Internet is not the bottleneck? <br>[ ] A) Apply for a dedicated interconnect option <br>[ ] B) Enable high speed routing in your VPN settings <br>[ ] C) Create an additional VPN tunnel <br>[ ] D) Submit request to increase bandwidth quota</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct answer C <br><br>Explanation <br><br>A - Apply for a dedicated interconnect option. A dedicated interconnect will also increase speeds, however the question asked how to speed up your VPN connection, not create a new type of connection. <br><br>C (Correct answer) - Create an additional VPN tunnel. Each VPN tunnel has a max speed of 1.5 Gbps. However, you can create multiple VPN tunnels to increase bandwidth. <br><br>Answer B and D either are not applicable or feature doesn't not exist.</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">Using principal of least privilege and allowing for maximum automation, what steps can you take to store audit logs for long-term access and to allow access for external auditors to view? <br><br>Choose two:<br>[ ] A) Generate a signed URL to the Stackdriver export destination for auditors to access. <br>[ ] B) Create an account for auditors to have view access to Stackdriver Logging. <br>[ ] C) Export audit logs to Cloud Storage via an export sink. <br>[ ] D) Export audit logs to BigQuery via an export sink.</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct Answer A and C <br><br>Explanation <br><br>C (Correct answer) - Export audit logs to Cloud Storage via an export sink. Cloud Storage is perfect solution for long-term logs storage. <br><br>There are 3 type of sink destinations you can export StackDriver Logs to: Cloud Storage, Cloud Pub/Sub, BigQuery. While you could export to BigQuery for low-cost storage, BigQuery is mainly and best for analysis not for long-term storage. Besides, whenever you need to do analysis with BigQuery, you can always easily export the logs from GCS to BigQuery or do query directly against data in GCS bucket. <br><br>A (Correct answer) - You could either create a GCP account for auditor ACL object access or signed URL's depending on if they need to have a GCP account or not. Since the requirement is &quot;allow access for external auditors to view&quot;, hence signed URL is the right choice <br>B - Does not meet the &quot;for long-term access&quot; requirement <br><br>D - It works but for the &quot;for long-term access&quot; storage consideration, Cloud Storage is better choice over BigQuery <br><br>Additional Resources<br>https://cloud.google.com/logging/docs/export/<br>https://cloud.google.com/logging/docs/export/configure_export_v2</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">Suppose you have a web server that is working properly, but you can't connect to its instance VM over SSH. Which of these troubleshooting methods can you use without disrupting production traffic? <br><br>Select 3 answers:<br>[ ] A) Create a snapshot of the disk and use it to create a new disk; then attach the new disk to a new instance <br>[ ] B) Use netcat to try to connect to port 22 <br>[ ] C) Access the serial console output <br>[ ] D) Create a startup script to collect information.</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct answer A, B, and C <br><br>Feedback <br><br>Answers A, B, and C are valid methods to diagnose the problem without stop/start the instance. Answer D need to restart the instance for the script to take effect. <br><br>Troubleshooting SSH<br>https://cloud.google.com/compute/docs/troubleshooting/troubleshooting-ssh <br><br>Under certain conditions, it is possible that a Google Compute Engine instance no longer accepts SSH connections. There are many reasons this could happen, from a full disk to an accidental misconfiguration of sshd. This section describes a number of tips and approaches to troubleshoot and resolve common SSH issues. <br><br>1) Check your firewall rules ... ... ...<br><br>2) Debug the issue in the serial console<br>You can enable read-write access to an instance's serial console so you can log into the console and troubleshoot problems with the instance. This is particularly useful when you cannot log in with SSH or if the instance has no connection to the network. The serial console remains accessible in both these conditions. <br><br>3) Test the network<br>You can use the netcat tool to connect to your instance on port 22 and see if the network connection is working. If you connect and see an ssh banner (e.g. SSH-2.0-OpenSSH_6.0p1 Debian-4), your network connection is working, and you can rule out firewall problems. First, use the gcloud tool to obtain the external natIP for your instance: <br><br>gcloud compute instances describe example-instance --format='get(networkInterfaces[0].accessConfigs[0].natIP)' 198.51.100.8 <br><br>Use the nc command to connect to your instance: # Check for SSH banner user@local:~$ nc [EXTERNAL.IP] 22 SSH-2.0-OpenSSH_6.0p1 Debian-4<br><br>4) Try a new user ... ... ...<br>5) Use your disk on a new instance ... ... ...<br><br>6) Inspect an instance without shutting it down<br>You might have an instance you can't connect to that continues to correctly serve production traffic. In this case, you might want to inspect the disk without interrupting the instance's ability to serve users. First, take a snapshot of the instance's boot disk, then create a new disk from that snapshot, create a temporary instance, and finally attach and mount the new persistent disk to your temporary instance to troubleshoot the disk. <br><br>7) Use a startup script If none of the above helped, you can create a startup script to collect information right after the instance starts. Follow the instructions for running a startup script.</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">You have a Kubernetes cluster with 1 node-pool. The cluster receives a lot of traffic and needs to grow. You decide to add a node. <br><br>What should you do? <br>[ ] A) Use &quot;gcloud container clusters resize&quot; with the desired number of nodes. <br>[ ] B) Use &quot;kubectl container clusters resize&quot; with the desired number of nodes. <br>[ ] C) Edit the managed instance group of the cluster and increase the number of VMs by 1. <br>[ ] D) Edit the managed instance group of the cluster and enable autoscaling.</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct answer A <br><br>Feedback:<br>A is correct because this resizes the cluster to the desired number of nodes. <br><br>B is not correct because you need to use gcloud, not kubectl. <br><br>C is not correct because you should not manually manage the MIG behind a cluster. <br><br>D is not correct because you should not manually manage the MIG behind a cluster.</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">Your App Engine application needs to store stateful data in a proper storage service. Your data is non-relational database data. You do not expect the database size to grow beyond 10 GB and you need to have the ability to scale down to zero to avoid unnecessary costs. <br><br>Which storage service should you use? <br>[ ] A) Cloud Datastore <br>[ ] B) Cloud Dataproc <br>[ ] C) Cloud SQL <br>[ ] D) Cloud Bigtable</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct answer A <br><br>Cloud Datastore is for storing non-relational/NoSQL data and scales down to zero and up to several TB, which fits all of the requirements. <br><br>Datastore: A scalable, fully-managed NoSQL document database for your web and mobile applications. <br><br>Good for: <br>Semi-structured application data<br>Hierarchical data<br>Durable key-value data<br><br>Workload: <br>User profiles<br>Product catalogs<br>Game state</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">To reduce costs, the Director of Engineering has required all developers to move their development infrastructure resources from on-premises virtual machines (VMs) to Google Cloud Platform. These resources go through multiple start/stop events during the day and require state to persist. You have been asked to design the process of running a development environment in Google Cloud while providing cost visibility to the finance department. Which two steps should you take? <br><br>Choose 2 answers:<br>[ ] A) Store all state in Google Cloud Storage, snapshot the persistent disks, and terminate the VM<br>[ ] B) Use the --no-auto-delete flag on all persistent disks and stop the VM. <br>[ ] C) Apply VM CPU utilization label and include it in the BigQuery billing export.<br>[ ] D) Use Google BigQuery billing export and labels to associate cost to groups.<br>[ ] E) Use the -auto-delete flag on all persistent disks and terminate the VM.<br>[ ] F) Store all state into local SSD, snapshot the persistent disks, and terminate the VM.</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct answers are B and D<br><br>B (Correct Answer) - Use the --no-auto-delete flag on all persistent disks and stop the VM - with this flag set, when you terminate the instance, the persistence disk will not be deleted so the disk contents are preserved between start and stop. When the instance in stop status, you are only got charged for very low-cost disk storage<br>auto-delete for the given disk is enabled by default, use --no-auto-delete to disable.<br>https://cloud.google.com/sdk/gcloud/reference/compute/instances/set-disk-auto-delete<br>C - Apply VM CPU utilization label and include it in the BigQuery billing export - this is simply not doable D (Correct Answer) - Use Google BigQuery billing export and labels to associate cost to groups. Billing export to BigQuery enables you to export your daily usage and cost estimates automatically throughout the day to a BigQuery dataset you specify. You can then access your billing data from BigQuery. About labels: You'll see columns for labels in your BigQuery dataset, but for the current release some label values will be empty. Label export data will be populated at different times for different services, depending on when each service provides it. E - Use the -auto-delete flag on all persistent disks and terminate the VM - This is totally against the requirements. Since the instance is terminated and disk is gone when this flag is on, there is no way to restart the same instance and needless to say the disk content are not persisted. Answer A and F are incorrect, or at least not as good as Answer B - they are not a suitable solution for frequently start/stop and require state to persist. The correct answers are: Use the --no-auto-delete flag on all persistent disks and stop the VM., Use Google BigQuery billing export and labels to associate cost to groups.</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">MountKirk Games needs to build out their streaming data analytics pipeline to feed from their game backend application. <br><br>What GCP services in which order will achieve this?<br>[ ] A) Cloud Storage - Cloud Dataflow - BigQuery <br>[ ] B) Cloud Dataproc - Cloud Storage - BigQuery <br>[ ] C) Cloud Pub/Sub - Cloud Dataflow - Cloud Bigtable <br>[ ] D) Cloud Pub/Sub - Cloud Dataflow - BigQuery</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct answer D <br><br>Explanation <br><br>Pub/Sub is kind of 'shock absorber', allowing asynchronous messaging between large numbers of devices. Cloud Dataflow acts as your data processing pipeline for ETL functions on both streaming and batch data. BigQuery is a data warehouse, able to run analysis on petabytes of data using SQL queries. <br><br>Below is a reference architect Google recommending for similar scenario in Real-time streaming data collection and analysis https://cloud.google.com/solutions/mobile/mobile-gaming-analysis-telemetry <br><br>Real-time processing of events from game clients and game servers(Diagram Link):<br>https://s3.amazonaws.com/whizlabs-pub/GCP+Professional+Cloud+Architect+Images/GCP+PCA_PT1/PT1_Q42.png<br><br><br>Data Transformation with Cloud Dataflow - Dataflow acts as your data processing pipeline for ETL functions on both streaming and batch data. (Diagram Link):<br>https://s3.amazonaws.com/whizlabs-pub/GCP+Professional+Cloud+Architect+Images/GCP+PCA_PT1/PT1_Q42.1.png</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">Your company is planning the infrastructure for a new large-scale application that will need to store over 100 TB or a petabyte of data of data in NoSQL format for high-speed transactions and analytics. <br><br>Which storage option should you use? <br>[ ] A) Cloud Bigtable <br>[ ] B) Cloud Spanner <br>[ ] C) Cloud SQL <br>[ ] D) Cloud Datastore</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct answer A <br><br>Bigtable is ideal for very large NoSQL datasets and is useful for high-speed transactions and analysis. Bigtable: A scalable, fully-managed NoSQL wide-column database that is suitable for both real-time access and analytics workloads. Bigtable is ideal for very large NoSQL datasets and is useful for high-speed transactions and analysis. It integrates well with ML. Dataproc, and analytics <br><br>Good for<br>Low-latency read/write access<br>High-throughput analytics<br>Native time series support<br><br>Work load<br>IoT, finance, adtech<br>Personalization, recommendations<br>Monitoring<br>Geospatial datasets<br>Graphs<br><br>Although both Datastore and Bigtable are NoSQL databases, Bigtable is able to support over a petabyte of data and is useful for high speed analytics as well, whereas Datastore is not.</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">You created an update for your application on App Engine. You want to deploy the update without impacting your users. You want to be able to roll back as quickly as possible if it fails. <br><br>What should you do? <br>[ ] A) Delete the current version of your application. Deploy the update using the same version identifier as the deleted version. <br>[ ] B) Notify your users of an upcoming maintenance window. Deploy the update in that maintenance window. <br>[ ] C) Deploy the update as the same version that is currently running. <br>[ ] D) Deploy the update as a new version. Migrate traffic from the current version to the new version.</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct answer D <br><br>Feedback <br><br>A and B are not correct because this will make the application temporarily unavailable to users. <br><br>C is not correct because to roll back, you'll need to redeploy the previous deployment because the app was overwritten with the same version number. Therefore this takes longer than a rollback using method D. <br><br>D is correct because this makes sure there is no downtime and you can roll back the fastest. <br><br>Reference<br>Migrating and Splitting Traffic https://cloud.google.com/appengine/docs/admin-api/migrating-splitting-traffic</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">You are designing a large distributed application with 30 microservices. Each of your distributed microservices needs to connect to a database back-end. You want to store the credentials securely. <br><br>Where should you store the credentials? <br>[ ] A) In a secret management system <br>[ ] B) In the source code <br>[ ] C) In an environment variable <br>[ ] D) In a config file that has restricted access through ACLs</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct Answer A <br><br>Feedback <br><br>A (Correct answer) - In a secret management system <br><br>Applications often require access to small pieces of sensitive data at build or run time. These pieces of data are often referred to as secrets. Secrets are similar in concept to configuration files, but are generally more sensitive, as they may grant access to additional data, such as user data. https://cloud.google.com/kms/docs/secret-management <br><br>B - In the source code: This is exactly again the best practice &quot;Do not embed secrets related to authentication in source code, such as API keys, OAuth tokens, and service account credentials.&quot; (see below the best practice #1) <br><br>C - In an environment variable - you use environment variable to point to the location where the secrets (credentials) are stored other than store the secrete directly (see below the best practice #1) <br><br>D - In a configuration file that has restricted access through ACLs - Secrets are similar to but generally more sensitive than configuration and also, ACLs may not enough for the secrete management. Here is example for Storing secrets <br><br>https://cloud.google.com/kms/docs/store-secrets <br><br>Additional Resource<br>https://cloud.google.com/docs/authentication/production#providing_credentials_to_your_application <br><br>Best practices for managing credentials <br><br>Credentials provide access to sensitive data. The following practices help protect access to these resources: <br>1) Do not embed secrets related to authentication in source code, such as API keys, OAuth tokens, and service account credentials. You can use an environment variable pointing to credentials outside of the application's source code, such as Cloud Key Management Service. <br>2) Do use different credentials in different contexts, such as in testing and production environments. <br>3) Do transfer credentials only over HTTPS to prevent a third party from intercepting your credentials. Never transfer in clear text or as part of the URL. <br>4) Never embed long-lived credentials into your client-side app. For example, do not embed service account credentials into a mobile app. Client-side apps can be examined, and credentials can easily be found and used by a third party. <br>5) Do revoke a token if you no longer need it.</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">Based on TerramEarth's current data flow environment (refer to the image in the case study), what are the direct GCP services needed to replicate the same structure for batch uploads?<br>[ ] A) Cloud Spanner - Cloud SQL - BigQuery <br>[ ] B) Cloud Dataflow - Cloud Bigtable - Cloud Dataproc <br>[ ] C) Cloud Dataproc - Cloud Storage - BigQuery <br>[ ] D) Cloud Storage - Cloud Dataflow - BigQuery</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct answer D <br><br>Explanation <br><br>Based on their current batch upload model, the direct equivalent would be to use Cloud Storage for storing files, Dataflow for their ETL processing, and BigQuery for their data warehouse needs. <br><br>Below illustrates the solution concept. <br><br>TerramEarth's Existing Technical Environment One Possible GCP solution for batch upload flow (Diagram Links):<br>https://s3.amazonaws.com/whizlabs-pub/GCP+Professional+Cloud+Architect+Images/GCP+PCA_PT1/PT1_Q46.png<br>https://s3.amazonaws.com/whizlabs-pub/GCP+Professional+Cloud+Architect+Images/GCP+PCA_PT1/PT1_Q46.1.png</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">An application development team believes their current logging tool will not meet their needs for their new cloud-based product. They want a better tool to capture errors and help them analyze their historical log data. You want to help them find a solution that meets their needs. <br><br>What should you do?<br>[ ] A) Send them a list of online resources about logging best practices. <br>[ ] B) Help them define their requirements and assess viable logging tools. <br>[ ] C) Help them upgrade their current tool to take advantage of any new features. <br>[ ] D) Direct them to download and install the Google StackDriver logging agent.</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct Answer B <br><br>Feedback <br><br>A and D can be ruled out for them are not general IT good practices. They need your help, not just simply to sell your products by pointing to a specific tool in your favor (D), or just give them a general best practice list (A) without insight opinions and further explains. <br><br>B (Correct Answer) - Help them define their requirements and assess viable logging tools. They know the requirements and the existing tools' problems. While it's true StackDriver Logging and Error Reporting possibly meet all their requirements, there might be other tools also meet their need. They need you to provide expertise to make assessment for new tools, specifically, logging tools that can &quot;capture errors and help them analyze their historical log data&quot;. <br><br>C - Help them upgrade their current tool to take advantage of any new features. They have already used and known those tools' shortcomings. They need your help to find better one. Simply help them upgrade for new features is not enough and may not resolve the problems.</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">You have a definition for an instance template that contains a web application. You are asked to deploy the application so that it can scale based on the HTTP traffic it receives. <br><br>What should you do? <br>[ ] A) Create a VM from the instance template. Create a custom image from the VM's disk. Export the image to Cloud Storage. Create an HTTP load balancer and add the Cloud Storage bucket as its backend service. <br>[ ] B) Create a VM from the instance template. Create an App Engine application in Automatic Scaling mode that forwards all traffic to the VM. <br>[ ] C) Create a managed instance group based on the instance template. Configure autoscaling based on HTTP traffic and configure the instance group as the backend service of an HTTP load balancer. <br>[ ] D) Create the necessary amount of instances required for peak user traffic based on the instance template. Create an unmanaged instance group and add the instances to that instance group. Configure the instance group as the Backend Service of an HTTP load balancer.</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct answer C <br><br>Feedback <br><br>A Is not correct because the Load Balancer will just load balance access to the uploaded image itself, and not create or autoscale VMs based on that image. <br><br>B Is not correct because while the App Engine can scale as a proxy, all requests will still end up on the same Compute Engine instance, which needs to scale itself. <br><br>C is correct because a managed instance group can use an instance template to scale based on HTTP traffic. <br><br>D is not correct because unmanaged instance groups do not offer autoscaling. <br><br>Reference <br>Managed instance groups and autoscaling <br>https://cloud.google.com/compute/docs/instance-groups/#managed_instance_groups_and_autoscaling <br><br>Exporting an Image https://cloud.google.com/compute/docs/images/export-image <br><br>Adding a Cloud Storage Bucket to Content-based Load Balancing <br><br>https://cloud.google.com/compute/docs/load-balancing/<br>http/adding-a-backend-bucket-to-content-based-load-balancing</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">As part of your backup plan, you set up regular snapshots of Compute Engine instances that are running. You want to be able to restore these snapshots using the fewest possible steps for replacement instances. <br><br>What should you do? <br>[ ] A) Export the snapshots to Cloud Storage. Create disks from the exported snapshot files. Create images from the new disks. <br>[ ] B) Export the snapshots to Cloud Storage. Create images from the exported snapshot files. <br>[ ] C) Use the snapshots to create replacement disks. Use the disks to create instances as needed. <br>[ ] D) Use the snapshots to create replacement instances as needed.</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct answer D <br><br>Feedback:<br>D (Correct Answer) - D is correct because the scenario asks how to recreate instances. <br><br>A, B, and C are not correct because the Google best practice of creating images from running Compute Engine instances is to first take a snapshot, export it to Cloud Storage, and then import that file as the basis for a custom image for use in DR scenarios <br><br>Reference <br><br>Choosing a storage option https://cloud.google.com/storage-options/</span></div></div></div></div></div></div></div></div><div class="SetPage-term"><div class="SetPageTerm is-showing"><div class="SetPageTerm-inner"><div class="SetPageTerm-contentWrapper"><div class="SetPageTerm-content"><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-wordText"><span class="TermText notranslate lang-en">For future phases, Dress4Win is looking at options to deploy data analytics to the Google Cloud. <br><br>Which option meets their business and technical requirements? <br>[ ] A) Run current jobs from the current technical environment on Google Cloud Dataproc. <br>[ ] B) Review all current data jobs. Identify the most critical jobs and create Google BigQuery tables to store and query data. <br>[ ] C) Review all current data jobs. Identify the most critical jobs and develop Google Cloud Dataflow pipelines to process data. <br>[ ] D) Deploy a Hadoop/Spark cluster to Google Compute Engine virtual machines. Move current jobs from the current technical environment and run them on the Hadoop/Spark cluster.</span></div></div></div><div class="SetPageTerm-side"><div class="SetPageTerm-sideContent"><div class="SetPageTerm-definitionText"><span class="TermText notranslate lang-en">Correct Answer A <br><br>Feedback <br><br>A (Correct Answer) - There is no requirement to migrate the current jobs to a different technology. Using managed services where possible is a requirement. Using Google Cloud Dataproc allows the current jobs to be executed within Google Cloud Platform on a managed service offering. <br><br>B - Migrating the existing data jobs to a different technology such as Google BigQuery, is not a requirement. <br><br>C - Migrating existing data jobs to a different technology such as Google Cloud Dataflow, is not a requirement. <br><br>D - Using managed services where possible is a requirement. The current jobs can run on a Hadoop/Spark cluster in Google Compute Engine but it is not a managed services solution. <br><br>Both A and D are technically correct but D against one of tech requirements &quot;Use managed services whenever possible.&quot; <br><br>Dress4win Existing Technical Environment<br>Apache Hadoop/Spark servers: <br>• Data analysis<br>• Real-time trending calculations<br><br>Technical Requirements<br>• Evaluate and choose an automation framework for provisioning resources in cloud. <br>• Support failover of the production environment to cloud during an emergency. <br>• Identify production services that can migrate to cloud to save capacity. <br>• Use managed services whenever possible. <br>• Encrypt data on the wire and at rest. <br>• Support multiple VPN connections between the production data center and cloud environment.</span></div></div></div></div></div></div></div></div></div><div class="SuggestedSets"><div class="SlidingCarousel SlidingCarousel--dummy"><div class="SlidingCarousel-panes SlidingCarousel-panes--initial"><div class="SlidingCarousel-pane is-stretched is-current"><section class="SetGroup is-dummy"><div class="UIContainer UIContainer--isFullWidth"><div class="SetGroup-inner"><div class="SetGroup-header"><h5 class="UIHeading UIHeading--five">你可能还喜欢...</h5></div><div class="SetGroup-set"><div class="SetPreviewLink"><div class="UILinkBox"><div class="UILinkBox-inner"><div class="SetPreview"><div class="SetPreview-inner"><div class="PreviewCardByline"><span class="SetPreview-cardBylineTermsCount">69个词语</span></div><header class="SetPreview-cardHeader"><span class="SetPreview-cardHeaderTitle">AWS Sol Arch - Mock Exam3</span></header><div class="SetPreviewLink-metadata"><div class="SetPreviewLink-priceTag"><h4 class="UIHeading UIHeading--four"></h4></div></div></div></div></div><div class="UILinkBox-link"><a class="UILink" data-sourcename="" href="https://quizlet.com/199395552/aws-sol-arch-mock-exam3-flash-cards/"></a></div></div></div></div><div class="SetGroup-set"><div class="SetPreviewLink"><div class="UILinkBox"><div class="UILinkBox-inner"><div class="SetPreview"><div class="SetPreview-inner"><div class="PreviewCardByline"><span class="SetPreview-cardBylineTermsCount">66个词语</span></div><header class="SetPreview-cardHeader"><span class="SetPreview-cardHeaderTitle">AWS Pro</span></header><div class="SetPreviewLink-metadata"><div class="SetPreviewLink-priceTag"><h4 class="UIHeading UIHeading--four"></h4></div></div></div></div></div><div class="UILinkBox-link"><a class="UILink" data-sourcename="" href="https://quizlet.com/213765297/aws-pro-flash-cards/"></a></div></div></div></div><div class="SetGroup-set"><div class="SetPreviewLink"><div class="UILinkBox"><div class="UILinkBox-inner"><div class="SetPreview"><div class="SetPreview-inner"><div class="PreviewCardByline"><span class="SetPreview-cardBylineTermsCount">851个词语</span></div><header class="SetPreview-cardHeader"><span class="SetPreview-cardHeaderTitle">AWS Certified Solutions Architect - Associate Practice Questions</span></header><div class="SetPreviewLink-metadata"><div class="SetPreviewLink-priceTag"><h4 class="UIHeading UIHeading--four"></h4></div></div></div></div></div><div class="UILinkBox-link"><a class="UILink" data-sourcename="" href="https://quizlet.com/194513754/aws-certified-solutions-architect-associate-practice-questions-flash-cards/"></a></div></div></div></div><div class="SetGroup-set"><div class="SetPreviewLink"><div class="UILinkBox"><div class="UILinkBox-inner"><div class="SetPreview"><div class="SetPreview-inner"><div class="PreviewCardByline"><span class="SetPreview-cardBylineTermsCount">851个词语</span></div><header class="SetPreview-cardHeader"><span class="SetPreview-cardHeaderTitle">AWS Certified Solutions Architect 851 Q from dathuminh</span></header><div class="SetPreviewLink-metadata"><div class="SetPreviewLink-priceTag"><h4 class="UIHeading UIHeading--four"></h4></div></div></div></div></div><div class="UILinkBox-link"><a class="UILink" data-sourcename="" href="https://quizlet.com/215197486/aws-certified-solutions-architect-851-q-from-dathuminh-flash-cards/"></a></div></div></div></div></div></div></section></div><div class="SlidingCarousel-pane is-hidden"><section class="SetGroup is-dummy"><div class="UIContainer UIContainer--isFullWidth"><div class="SetGroup-inner"><div class="SetGroup-header"><h5 class="UIHeading UIHeading--five">此创建者的其他学习集</h5></div><div class="SetGroup-set"><div class="SetPreviewLink"><div class="UILinkBox"><div class="UILinkBox-inner"><div class="SetPreview"><div class="SetPreview-inner"><div class="PreviewCardByline"><span class="SetPreview-cardBylineTermsCount">50个词语</span></div><header class="SetPreview-cardHeader"><span class="SetPreview-cardHeaderTitle">GCP - Architect Certification 004</span></header><div class="SetPreviewLink-metadata"><div class="SetPreviewLink-priceTag"><h4 class="UIHeading UIHeading--four"></h4></div></div></div></div></div><div class="UILinkBox-link"><a class="UILink" data-sourcename="" href="https://quizlet.com/351828373/gcp-architect-certification-004-flash-cards/"></a></div></div></div></div><div class="SetGroup-set"><div class="SetPreviewLink"><div class="UILinkBox"><div class="UILinkBox-inner"><div class="SetPreview"><div class="SetPreview-inner"><div class="PreviewCardByline"><span class="SetPreview-cardBylineTermsCount">50个词语</span></div><header class="SetPreview-cardHeader"><span class="SetPreview-cardHeaderTitle">GCP - Architect Certification 003</span></header><div class="SetPreviewLink-metadata"><div class="SetPreviewLink-priceTag"><h4 class="UIHeading UIHeading--four"></h4></div></div></div></div></div><div class="UILinkBox-link"><a class="UILink" data-sourcename="" href="https://quizlet.com/350025933/gcp-architect-certification-003-flash-cards/"></a></div></div></div></div><div class="SetGroup-set"><div class="SetPreviewLink"><div class="UILinkBox"><div class="UILinkBox-inner"><div class="SetPreview"><div class="SetPreview-inner"><div class="PreviewCardByline"><span class="SetPreview-cardBylineTermsCount">50个词语</span></div><header class="SetPreview-cardHeader"><span class="SetPreview-cardHeaderTitle">GCP - Architect Certification 002</span></header><div class="SetPreviewLink-metadata"><div class="SetPreviewLink-priceTag"><h4 class="UIHeading UIHeading--four"></h4></div></div></div></div></div><div class="UILinkBox-link"><a class="UILink" data-sourcename="" href="https://quizlet.com/348640679/gcp-architect-certification-002-flash-cards/"></a></div></div></div></div><div class="SetGroup-set"><div class="SetPreviewLink"><div class="UILinkBox"><div class="UILinkBox-inner"><div class="SetPreview"><div class="SetPreview-inner"><div class="PreviewCardByline"><span class="SetPreview-cardBylineTermsCount">16个词语</span></div><header class="SetPreview-cardHeader"><span class="SetPreview-cardHeaderTitle">GCP - Architect Certification 001</span></header><div class="SetPreviewLink-metadata"><div class="SetPreviewLink-priceTag"><h4 class="UIHeading UIHeading--four"></h4></div></div></div></div></div><div class="UILinkBox-link"><a class="UILink" data-sourcename="" href="https://quizlet.com/347387076/gcp-architect-certification-001-flash-cards/"></a></div></div></div></div></div></div></section></div><div class="SlidingCarousel-pane is-hidden"><section class="SetGroup is-dummy"><div class="UIContainer UIContainer--isFullWidth"><div class="SetGroup-inner"><div class="SetGroup-header"><h5 class="UIHeading UIHeading--five">此学习集通常与下列其他学习集保存在一起...</h5></div><div class="SetGroup-set"><div class="SetPreviewLink"><div class="UILinkBox"><div class="UILinkBox-inner"><div class="SetPreview"><div class="SetPreview-inner"><div class="PreviewCardByline"><span class="SetPreview-cardBylineTermsCount">41个词语</span></div><header class="SetPreview-cardHeader"><span class="SetPreview-cardHeaderTitle">Google Cloud Architect Exam - Study Set</span></header><div class="SetPreviewLink-metadata"><div class="SetPreviewLink-priceTag"><h4 class="UIHeading UIHeading--four"></h4></div></div></div></div></div><div class="UILinkBox-link"><a class="UILink" data-sourcename="" href="https://quizlet.com/316938063/google-cloud-architect-exam-study-set-flash-cards/"></a></div></div></div></div><div class="SetGroup-set"><div class="SetPreviewLink"><div class="UILinkBox"><div class="UILinkBox-inner"><div class="SetPreview"><div class="SetPreview-inner"><div class="PreviewCardByline"><span class="SetPreview-cardBylineTermsCount">95个词语</span></div><header class="SetPreview-cardHeader"><span class="SetPreview-cardHeaderTitle">Google Certified Professional - Cloud Architect - Part 3</span></header><div class="SetPreviewLink-metadata"><div class="SetPreviewLink-priceTag"><h4 class="UIHeading UIHeading--four"></h4></div></div></div></div></div><div class="UILinkBox-link"><a class="UILink" data-sourcename="" href="https://quizlet.com/316685710/google-certified-professional-cloud-architect-part-3-flash-cards/"></a></div></div></div></div><div class="SetGroup-set"><div class="SetPreviewLink"><div class="UILinkBox"><div class="UILinkBox-inner"><div class="SetPreview"><div class="SetPreview-inner"><div class="PreviewCardByline"><span class="SetPreview-cardBylineTermsCount">86个词语</span></div><header class="SetPreview-cardHeader"><span class="SetPreview-cardHeaderTitle">GCP Cloud Architect</span></header><div class="SetPreviewLink-metadata"><div class="SetPreviewLink-priceTag"><h4 class="UIHeading UIHeading--four"></h4></div></div></div></div></div><div class="UILinkBox-link"><a class="UILink" data-sourcename="" href="https://quizlet.com/221352227/gcp-cloud-architect-flash-cards/"></a></div></div></div></div><div class="SetGroup-set"><div class="SetPreviewLink"><div class="UILinkBox"><div class="UILinkBox-inner"><div class="SetPreview"><div class="SetPreview-inner"><div class="PreviewCardByline"><span class="SetPreview-cardBylineTermsCount">107个词语</span></div><header class="SetPreview-cardHeader"><span class="SetPreview-cardHeaderTitle">Google Cloud Platform Services</span></header><div class="SetPreviewLink-metadata"><div class="SetPreviewLink-priceTag"><h4 class="UIHeading UIHeading--four"></h4></div></div></div></div></div><div class="UILinkBox-link"><a class="UILink" data-sourcename="" href="https://quizlet.com/300002871/google-cloud-platform-services-flash-cards/"></a></div></div></div></div></div></div></section></div></div><div class="SlidingCarousel-arrowsContainer"><span class="UIIconButton"><button class="UIButton" disabled type="button"><span class="UIButton-wrapper"><svg class="UIIcon UIIcon--wedge-left"><noscript></noscript><use xlink:href="#wedge-left"></use><noscript></noscript></svg><script>QWait('Quizlet.IconContainer',function(){Quizlet.IconContainer.loadIcon("wedge-left")})</script></span></button></span><span class="UIIconButton"><button class="UIButton" disabled type="button"><span class="UIButton-wrapper"><svg class="UIIcon UIIcon--wedge-right"><noscript></noscript><use xlink:href="#wedge-right"></use><noscript></noscript></svg><script>QWait('Quizlet.IconContainer',function(){Quizlet.IconContainer.loadIcon("wedge-right")})</script></span></button></span></div></div></div></div></div></div></div></div></div><div class="SetPageFooter has-adz"><div id="SetPageFooterAdTarget"></div><script>window.Quizlet["setPageFooterAdData"] = {"headingAlignment":"inline","id":"NewFooterLI-17Plus","shouldShowAd":true,"upgradeSource":"remove_ads"}; QLoad("Quizlet.setPageFooterAdData");</script></div><script> window.Quizlet.setPageData = {"alphabeticalIsDifferent":true,"alphabeticalOrder":[11942480658,11942509308,11942471764,11942238878,11942518876,11942256677,11942121095,11941714676,11941604753,11942088636,11941027901,11942412685,11942275003,11941794499,11941822198,11941491395,11941263581,11941167100,11941252416,11942373552,11942328821,11941303746,11941992353,11942402315,11942364513,11937566308,11942019530,11942464087,11942206152,11942454299,11942500100,11942383502,11941105369,11941744001,11942344010,11941758463,11941535164,11942392203,11941570378,11941678687,11942299673,11942429953,11941369150,11942148332,11941410900,11942318319,11942353286,11942185570,11937602817,11942040496],"canAccessStudyableFeatures":true,"canCopySet":true,"canCreateClass":true,"canEditSet":false,"classesToAddSetTo":[],"classProgressUpsellModalShowCount":0,"creator":{"id":107817978,"username":"WJScott","timestamp":1543964740,"lastModified":1546893241,"type":0,"isLocked":false,"_imageUrl":"https:\/\/gimg.quizlet.com\/-f6oMjACGc7Q\/AAAAAAAAAAI\/AAAAAAAAAAA\/AGDgw-jN8aZQWgIUaNu9YXAEVV8WTZ1MdA\/mo\/photo.jpg?sz=150","timeZone":"America\/Chicago","firstName":"Bill","lastName":"Scott","isAdmin":false},"diagramImage":null,"diagramShapes":null,"editableBy":"WJScott","embedInfoByMode":[{"displayName":"\u914d\u5bf9","modeType":5},{"displayName":"\u5b66\u4e60","modeType":1},{"displayName":"\u6d4b\u8bd5","modeType":3},{"displayName":"\u5355\u8bcd\u5361","modeType":2},{"displayName":"\u62fc\u5199","modeType":8}],"isFireflySharingEnabled":false,"foldersToAddSetTo":[{"id":61482863,"isAlreadyAdded":true,"title":"GCP","basePath":"\/algogz\/folders\/gcp"}],"gravityProgress":{"all":null,"starred":null},"hasAnyAnswers":false,"hasClasses":false,"includedInFolder":null,"isClassProgressAvailable":false,"isCreatorUnderageAndUnconfirmed":false,"isDeletable":false,"isDiagramSet":false,"isDiagramSetLoadError":false,"isEditable":false,"isEditableWithPassword":false,"isInfoModalOpen":false,"isMicrosoftTeamsEnabled":false,"isNewSetShareModalOpen":false,"isPaidTeacher":false,"isPopularSetByViews":false,"isPublic":true,"isReportingFlowBlocked":false,"isScoresModalOpen":false,"isSetViableForClassProgress":false,"isTeacher":false,"isUserFromDiagramShowcase":false,"learnProgress":{"all":null,"starred":null},"mainSchool":null,"media":null,"multipleChoiceOptions":null,"numClassesAllowed":8,"numClassesUsed":0,"originalOrder":[11937566308,11937602817,11941027901,11941105369,11941167100,11941252416,11941263581,11941303746,11941369150,11941410900,11941491395,11941535164,11941570378,11941604753,11941678687,11941714676,11941744001,11941758463,11941794499,11941822198,11941992353,11942019530,11942040496,11942088636,11942121095,11942148332,11942185570,11942206152,11942238878,11942256677,11942275003,11942299673,11942318319,11942328821,11942344010,11942353286,11942364513,11942373552,11942383502,11942392203,11942402315,11942412685,11942429953,11942454299,11942464087,11942471764,11942480658,11942500100,11942509308,11942518876],"parentSet":null,"folder":null,"purchasePrice":null,"relevantAdminClasses":null,"relevantSetMembershipsMap":[{"path":"\/algogz\/folders\/gcp","title":"GCP"}],"renderAboveContentSetPageVariation":null,"reportProblemOptions":[{"label":"\u8be5\u5b66\u4e60\u96c6\u4e2d\u6709\u4e00\u4e2a\u9519\u8bef","value":"mistake","additionalText":"\u8bf7\u67e5\u770b\u6211\u4eec\u6709\u5173Quizlet\u9519\u8bef\u4fe1\u606f\u7684\u5e38\u89c1\u95ee\u9898\u89e3\u7b54\u3002","helpLink":{"link":"\/help\/2444157\/how-do-i-report-a-typo-in-a-set","text":"\u67e5\u770b\u5e38\u89c1\u95ee\u9898\u89e3\u7b54"}},{"label":"\u5b66\u4e60\u96c6\u5185\u5bb9\u4e0d\u5f53","value":"inappropriate_content","shouldShowReportBtn":true},{"label":"\u5b66\u4e60\u96c6\u6807\u9898\u6216\u63cf\u8ff0\u4e0d\u5f53","value":"inappropriate_details","shouldShowReportBtn":true},{"label":"\u8be5\u5b66\u4e60\u96c6\u542b\u6709\u7248\u6743\u5185\u5bb9","value":"dmca","additionalText":"\u8bf7\u67e5\u770b\u6211\u4eec\u7684\u300a\u6570\u5b57\u5343\u5e74\u7248\u6743\u6cd5\u300b(DMCA)\u653f\u7b56\u4ee5\u4e3e\u62a5\u7248\u6743\u5185\u5bb9\u3002","helpLink":{"link":"\/dmca","text":"\u67e5\u770b\u300a\u6570\u5b57\u5343\u5e74\u7248\u6743\u6cd5\u300b\u653f\u7b56"}},{"label":"\u8be5\u5b66\u4e60\u96c6\u5305\u542b\u8003\u8bd5\u6216\u6d4b\u9a8c\u7684\u7b54\u6848","value":"testbank","additionalText":"\u8bf7\u70b9\u51fb\u4ee5\u4e0b\u94fe\u63a5\u63d0\u4ea4\u6709\u5173\u8fd9\u79cd\u6750\u6599\u7684\u62a5\u544a\u3002","helpLink":{"link":"\/testbank\/request","text":"\u4e3e\u62a5\u5b66\u4e60\u96c6\u4e2d\u7684\u8003\u8bd5\u6216\u6d4b\u9a8c\u7b54\u6848"}}],"scatterProgress":{"all":null,"starred":null},"selectedOnly":false,"set":{"id":348513265,"timestamp":1544140975,"lastModified":1544161207,"publishedTimestamp":1544160589,"creatorId":107817978,"wordLang":"en","defLang":"en","title":"Google Cloud Professional Cloud Architect 01","passwordUse":false,"passwordEdit":false,"accessType":2,"accessCodePrefix":null,"description":"GPCCA - Test 01 or 03","numTerms":50,"hasImages":false,"parentId":0,"creationSource":1,"privacyLockStatus":0,"hasDiagrams":false,"_webUrl":"https:\/\/quizlet.com\/348513265\/google-cloud-professional-cloud-architect-01-flash-cards\/","_thumbnailUrl":null,"price":null,"mcqCount":0},"setsFromCreator":[{"id":351828373,"timestamp":1544719803,"lastModified":1544723258,"publishedTimestamp":1544723252,"creatorId":107817978,"wordLang":"en","defLang":"en","title":"GCP - Architect Certification 004","passwordUse":false,"passwordEdit":false,"accessType":2,"accessCodePrefix":null,"description":"","numTerms":50,"hasImages":false,"parentId":0,"creationSource":1,"privacyLockStatus":0,"hasDiagrams":false,"_webUrl":"https:\/\/quizlet.com\/351828373\/gcp-architect-certification-004-flash-cards\/","_thumbnailUrl":null,"price":null,"mcqCount":0,"_creator":{"id":107817978,"username":"WJScott","timestamp":1543964740,"lastModified":1546893241,"type":0,"isLocked":false,"_imageUrl":"https:\/\/gimg.quizlet.com\/-f6oMjACGc7Q\/AAAAAAAAAAI\/AAAAAAAAAAA\/AGDgw-jN8aZQWgIUaNu9YXAEVV8WTZ1MdA\/mo\/photo.jpg?sz=150","timeZone":"America\/Chicago","firstName":"Bill","lastName":"Scott"}},{"id":350025933,"timestamp":1544468559,"lastModified":1544494988,"publishedTimestamp":1544494988,"creatorId":107817978,"wordLang":"en","defLang":"en","title":"GCP - Architect Certification 003","passwordUse":false,"passwordEdit":false,"accessType":2,"accessCodePrefix":null,"description":"","numTerms":50,"hasImages":false,"parentId":0,"creationSource":1,"privacyLockStatus":0,"hasDiagrams":false,"_webUrl":"https:\/\/quizlet.com\/350025933\/gcp-architect-certification-003-flash-cards\/","_thumbnailUrl":null,"price":null,"mcqCount":0,"_creator":{"id":107817978,"username":"WJScott","timestamp":1543964740,"lastModified":1546893241,"type":0,"isLocked":false,"_imageUrl":"https:\/\/gimg.quizlet.com\/-f6oMjACGc7Q\/AAAAAAAAAAI\/AAAAAAAAAAA\/AGDgw-jN8aZQWgIUaNu9YXAEVV8WTZ1MdA\/mo\/photo.jpg?sz=150","timeZone":"America\/Chicago","firstName":"Bill","lastName":"Scott"}},{"id":348640679,"timestamp":1544161618,"lastModified":1544161746,"publishedTimestamp":1544161640,"creatorId":107817978,"wordLang":"en","defLang":"en","title":"GCP - Architect Certification 002","passwordUse":false,"passwordEdit":false,"accessType":2,"accessCodePrefix":null,"description":"","numTerms":50,"hasImages":false,"parentId":347387076,"creationSource":1,"privacyLockStatus":0,"hasDiagrams":false,"_webUrl":"https:\/\/quizlet.com\/348640679\/gcp-architect-certification-002-flash-cards\/","_thumbnailUrl":null,"price":null,"mcqCount":0,"_creator":{"id":107817978,"username":"WJScott","timestamp":1543964740,"lastModified":1546893241,"type":0,"isLocked":false,"_imageUrl":"https:\/\/gimg.quizlet.com\/-f6oMjACGc7Q\/AAAAAAAAAAI\/AAAAAAAAAAA\/AGDgw-jN8aZQWgIUaNu9YXAEVV8WTZ1MdA\/mo\/photo.jpg?sz=150","timeZone":"America\/Chicago","firstName":"Bill","lastName":"Scott"}},{"id":347387076,"timestamp":1543964794,"lastModified":1543967517,"publishedTimestamp":1543967516,"creatorId":107817978,"wordLang":"en","defLang":"en","title":"GCP - Architect Certification 001","passwordUse":false,"passwordEdit":false,"accessType":2,"accessCodePrefix":null,"description":"","numTerms":16,"hasImages":false,"parentId":0,"creationSource":1,"privacyLockStatus":0,"hasDiagrams":false,"_webUrl":"https:\/\/quizlet.com\/347387076\/gcp-architect-certification-001-flash-cards\/","_thumbnailUrl":null,"price":null,"mcqCount":0,"_creator":{"id":107817978,"username":"WJScott","timestamp":1543964740,"lastModified":1546893241,"type":0,"isLocked":false,"_imageUrl":"https:\/\/gimg.quizlet.com\/-f6oMjACGc7Q\/AAAAAAAAAAI\/AAAAAAAAAAA\/AGDgw-jN8aZQWgIUaNu9YXAEVV8WTZ1MdA\/mo\/photo.jpg?sz=150","timeZone":"America\/Chicago","firstName":"Bill","lastName":"Scott"}}],"setsFromFolder":[{"id":316938063,"timestamp":1537325233,"lastModified":1538513559,"publishedTimestamp":1538509383,"creatorId":92659858,"wordLang":"en","defLang":"en","title":"Google Cloud Architect Exam - Study Set","passwordUse":false,"passwordEdit":false,"accessType":2,"accessCodePrefix":null,"description":"","numTerms":41,"hasImages":false,"parentId":0,"creationSource":1,"privacyLockStatus":0,"hasDiagrams":false,"_webUrl":"https:\/\/quizlet.com\/316938063\/google-cloud-architect-exam-study-set-flash-cards\/","_thumbnailUrl":null,"price":null,"mcqCount":0,"_creator":{"id":92659858,"username":"lguinn948","timestamp":1536600295,"lastModified":1548367561,"type":2,"isLocked":false,"_imageUrl":"https:\/\/gimg.quizlet.com\/-20obUugo7HM\/AAAAAAAAAAI\/AAAAAAAAABA\/dHSqZQEEO4A\/photo.jpg?sz=150","timeZone":"America\/Los_Angeles","firstName":"Lisa","lastName":"Guinn"}},{"id":316685710,"timestamp":1537293132,"lastModified":1537296075,"publishedTimestamp":1537296075,"creatorId":79810156,"wordLang":"en","defLang":"en","title":"Google Certified Professional - Cloud Architect - Part 3","passwordUse":false,"passwordEdit":false,"accessType":2,"accessCodePrefix":null,"description":"","numTerms":95,"hasImages":false,"parentId":0,"creationSource":1,"privacyLockStatus":0,"hasDiagrams":false,"_webUrl":"https:\/\/quizlet.com\/316685710\/google-certified-professional-cloud-architect-part-3-flash-cards\/","_thumbnailUrl":null,"price":null,"mcqCount":0,"_creator":{"id":79810156,"username":"quizlette828670","timestamp":1519222853,"lastModified":1537423796,"type":0,"isLocked":false,"_imageUrl":"https:\/\/gimg.quizlet.com\/-3emWKe0aL1Y\/AAAAAAAAAAI\/AAAAAAAAAAA\/APUIFaPl7uoe8MKPFSJGZY4ugiWONc6BSw\/mo\/photo.jpg?sz=150","timeZone":"Europe\/Minsk","firstName":"\u041e\u043b\u0435\u0433","lastName":"\u0412\u043b\u0430\u0434\u0438\u043c\u0438\u0440\u043e\u0432\u0438\u0447"}},{"id":221352227,"timestamp":1504663427,"lastModified":1505428248,"publishedTimestamp":1504673604,"creatorId":65576395,"wordLang":"en","defLang":"en","title":"GCP Cloud Architect","passwordUse":false,"passwordEdit":false,"accessType":2,"accessCodePrefix":null,"description":"","numTerms":86,"hasImages":false,"parentId":0,"creationSource":1,"privacyLockStatus":0,"hasDiagrams":false,"_webUrl":"https:\/\/quizlet.com\/221352227\/gcp-cloud-architect-flash-cards\/","_thumbnailUrl":null,"price":null,"mcqCount":0,"_creator":{"id":65576395,"username":"jwcardenas","timestamp":1504663398,"lastModified":1522450747,"type":0,"isLocked":false,"_imageUrl":"\/a\/i\/animals\/46.5T4F.jpg","timeZone":"America\/Los_Angeles"}},{"id":300002871,"timestamp":1527987019,"lastModified":1533723877,"publishedTimestamp":1527990944,"creatorId":39115087,"wordLang":"en","defLang":"en","title":"Google Cloud Platform Services","passwordUse":false,"passwordEdit":false,"accessType":2,"accessCodePrefix":null,"description":"","numTerms":107,"hasImages":false,"parentId":0,"creationSource":1,"privacyLockStatus":0,"hasDiagrams":false,"_webUrl":"https:\/\/quizlet.com\/300002871\/google-cloud-platform-services-flash-cards\/","_thumbnailUrl":null,"price":null,"mcqCount":0,"_creator":{"id":39115087,"username":"thebrimac","timestamp":1458035038,"lastModified":1534326621,"type":0,"isLocked":false,"_imageUrl":"https:\/\/gimg.quizlet.com\/-j8gVEyjYiyM\/AAAAAAAAAAI\/AAAAAAAABFE\/GdLtn1nd76E\/photo.jpg?sz=150","timeZone":"America\/New_York","firstName":"Brian","lastName":"McCarthy"}}],"similarSets":[{"id":199395552,"timestamp":1490841891,"lastModified":1491176684,"publishedTimestamp":1490843570,"creatorId":54188668,"wordLang":"en","defLang":"en","title":"AWS Sol Arch - Mock Exam3","passwordUse":false,"passwordEdit":false,"accessType":2,"accessCodePrefix":null,"description":"","numTerms":69,"hasImages":false,"parentId":0,"creationSource":1,"privacyLockStatus":0,"hasDiagrams":false,"_webUrl":"https:\/\/quizlet.com\/199395552\/aws-sol-arch-mock-exam3-flash-cards\/","_thumbnailUrl":null,"price":null,"mcqCount":0,"_creator":{"id":54188668,"username":"vardaang","timestamp":1483467810,"lastModified":1532466801,"type":0,"isLocked":false,"_imageUrl":"\/a\/i\/animals\/30.VHre.jpg","timeZone":"America\/Los_Angeles"}},{"id":213765297,"timestamp":1497198689,"lastModified":1540916517,"publishedTimestamp":1497210851,"creatorId":52453957,"wordLang":"en","defLang":"en","title":"AWS Pro","passwordUse":false,"passwordEdit":false,"accessType":2,"accessCodePrefix":null,"description":"","numTerms":66,"hasImages":false,"parentId":0,"creationSource":1,"privacyLockStatus":0,"hasDiagrams":false,"_webUrl":"https:\/\/quizlet.com\/213765297\/aws-pro-flash-cards\/","_thumbnailUrl":null,"price":null,"mcqCount":0,"_creator":{"id":52453957,"username":"kimkimvoi","timestamp":1480248900,"lastModified":1522345294,"type":0,"isLocked":false,"_imageUrl":"\/a\/i\/animals\/48.MP8S.jpg","timeZone":"Asia\/Ho_Chi_Minh"}},{"id":194513754,"timestamp":1489004144,"lastModified":1540916517,"publishedTimestamp":1489004530,"creatorId":58082435,"wordLang":"en","defLang":"en","title":"AWS Certified Solutions Architect - Associate Practice Questions","passwordUse":false,"passwordEdit":false,"accessType":2,"accessCodePrefix":null,"description":"","numTerms":851,"hasImages":false,"parentId":152377618,"creationSource":1,"privacyLockStatus":0,"hasDiagrams":false,"_webUrl":"https:\/\/quizlet.com\/194513754\/aws-certified-solutions-architect-associate-practice-questions-flash-cards\/","_thumbnailUrl":null,"price":null,"mcqCount":0,"_creator":{"id":58082435,"username":"dathuminh","timestamp":1489003275,"lastModified":1522450747,"type":0,"isLocked":false,"_imageUrl":"\/a\/i\/animals\/36.mYfN.jpg","timeZone":"Asia\/Ho_Chi_Minh"}},{"id":215197486,"timestamp":1498602193,"lastModified":1498602284,"publishedTimestamp":1498602282,"creatorId":7769021,"wordLang":"en","defLang":"en","title":"AWS Certified Solutions Architect 851 Q from dathuminh","passwordUse":false,"passwordEdit":false,"accessType":2,"accessCodePrefix":null,"description":"","numTerms":851,"hasImages":false,"parentId":194513754,"creationSource":1,"privacyLockStatus":0,"hasDiagrams":false,"_webUrl":"https:\/\/quizlet.com\/215197486\/aws-certified-solutions-architect-851-q-from-dathuminh-flash-cards\/","_thumbnailUrl":null,"price":null,"mcqCount":0,"_creator":{"id":7769021,"username":"mamun001","timestamp":1375015861,"lastModified":1549942356,"type":0,"isLocked":false,"_imageUrl":"https:\/\/gimg.quizlet.com\/-9LX2eWXfXpk\/AAAAAAAAAAI\/AAAAAAAAAQ0\/f6YyB4dSka4\/photo.jpg?sz=150","timeZone":"America\/Chicago","firstName":"Mamun","lastName":"Rashid"}}],"setPaths":{"classProgress":null,"delete":"\/348513265\/delete","edit":"\/348513265\/edit","editBottom":"\/348513265\/edit#addRow","editWithPassword":"\/348513265\/edit-screen?inline=1","info":"\/348513265\/info","print":"\/348513265\/print","remove":"\/qzadmin\/sets\/348513265\/remove","scores":"\/348513265\/scores","show":"\/348513265\/google-cloud-professional-cloud-architect-01-flash-cards\/"},"shareUrls":{"emailUrl":"\/348513265\/email","shortUrl":"https:\/\/quizlet.com\/_5rhuk1"},"shouldRenderTeacherVideoOnboardingModal":false,"shouldShowAd":true,"shouldShowCardsPreview":true,"shouldShowClassProgressUpsellModalOnLoad":false,"shouldShowNewReportingFlow":true,"shouldShowShareOptions":true,"shouldShowSignupWall":false,"shouldShowDownloadCurtain":false,"shouldShowStickyBannerWithStudyButtons":false,"shouldShowTeacherOnboardingStickyBanner":false,"shouldShowUpdatedContentPreviewCards":false,"shouldShowCardTooltip":true,"shouldUseAdBlockerFallback":false,"shouldShowRatingModal":false,"showVerifiedUI":false,"spellerProgress":{"all":null,"starred":null},"studentStatsTimeFrames":null,"studiableItems":null,"studiableMediaConnections":null,"teacherOnboardingPhaseTwoVariant":null,"termIdToCorrectCount":{},"termIdToIncorrectCount":{},"termIdToIsSelectedMap":{"11937566308":false,"11937602817":false,"11941027901":false,"11941105369":false,"11941167100":false,"11941252416":false,"11941263581":false,"11941303746":false,"11941369150":false,"11941410900":false,"11941491395":false,"11941535164":false,"11941570378":false,"11941604753":false,"11941678687":false,"11941714676":false,"11941744001":false,"11941758463":false,"11941794499":false,"11941822198":false,"11941992353":false,"11942019530":false,"11942040496":false,"11942088636":false,"11942121095":false,"11942148332":false,"11942185570":false,"11942206152":false,"11942238878":false,"11942256677":false,"11942275003":false,"11942299673":false,"11942318319":false,"11942328821":false,"11942344010":false,"11942353286":false,"11942364513":false,"11942373552":false,"11942383502":false,"11942392203":false,"11942402315":false,"11942412685":false,"11942429953":false,"11942454299":false,"11942464087":false,"11942471764":false,"11942480658":false,"11942500100":false,"11942509308":false,"11942518876":false},"termIdToTermsMap":{"11937566308":{"id":11937566308,"word":"What information is required to connect to an on-premises network router over VPN using Cloud Router for dynamic routing? \n\nChoose 3 correct answers: \n[ ] A) Remote Router DNS Name\n[ ] B) Remote Router (Peer) IP Address\n[ ] C) Shared Secret\n[ ] D) Border Gateway Protocol Address (BGP)","_wordTtsUrl":"\/tts\/en.mp3?v=14&b=V2hhdCBpbmZvcm1hdGlvbiBpcyByZXF1aXJlZCB0byBjb25uZWN0IHRvIGFuIG9uLXByZW1pc2VzIG5ldHdvcmsgcm91dGVyIG92ZXIgVlBOIHVzaW5nIENsb3VkIFJvdXRlciBmb3IgZHluYW1pYyByb3V0aW5nPyAKCkNob29zZSAzIGNvcnJlY3QgYW5zd2VyczogClsgXSBBKSBSZW1vdGUgUm91dGVyIEROUyBOYW1lClsgXSBCKSBSZW1vdGUgUm91dGVyIChQZWVyKSBJUCBBZGRyZXNzClsgXSBDKSBTaGFyZWQgU2VjcmV0ClsgXSBEKSBCb3JkZXIgR2F0ZXdheSBQcm90b2NvbCBBZGRyZXNzIChCR1Ap&s=vLGucn11","_wordSlowTtsUrl":"\/tts\/en.mp3?v=14&b=V2hhdCBpbmZvcm1hdGlvbiBpcyByZXF1aXJlZCB0byBjb25uZWN0IHRvIGFuIG9uLXByZW1pc2VzIG5ldHdvcmsgcm91dGVyIG92ZXIgVlBOIHVzaW5nIENsb3VkIFJvdXRlciBmb3IgZHluYW1pYyByb3V0aW5nPyAKCkNob29zZSAzIGNvcnJlY3QgYW5zd2VyczogClsgXSBBKSBSZW1vdGUgUm91dGVyIEROUyBOYW1lClsgXSBCKSBSZW1vdGUgUm91dGVyIChQZWVyKSBJUCBBZGRyZXNzClsgXSBDKSBTaGFyZWQgU2VjcmV0ClsgXSBEKSBCb3JkZXIgR2F0ZXdheSBQcm90b2NvbCBBZGRyZXNzIChCR1Ap&s=vLGucn11&speed=70","_wordAudioUrl":"\/tts\/en.mp3?v=14&b=V2hhdCBpbmZvcm1hdGlvbiBpcyByZXF1aXJlZCB0byBjb25uZWN0IHRvIGFuIG9uLXByZW1pc2VzIG5ldHdvcmsgcm91dGVyIG92ZXIgVlBOIHVzaW5nIENsb3VkIFJvdXRlciBmb3IgZHluYW1pYyByb3V0aW5nPyAKCkNob29zZSAzIGNvcnJlY3QgYW5zd2VyczogClsgXSBBKSBSZW1vdGUgUm91dGVyIEROUyBOYW1lClsgXSBCKSBSZW1vdGUgUm91dGVyIChQZWVyKSBJUCBBZGRyZXNzClsgXSBDKSBTaGFyZWQgU2VjcmV0ClsgXSBEKSBCb3JkZXIgR2F0ZXdheSBQcm90b2NvbCBBZGRyZXNzIChCR1Ap&s=vLGucn11","definition":"Correct answers B, C, and D \n\nUsing Cloud Router for dynamic routing requires a BGP address along with the peer address and the shared secret for secure access.","_definitionTtsUrl":"\/tts\/en.mp3?v=14&b=Q29ycmVjdCBhbnN3ZXJzIEIsIEMsIGFuZCBEIAoKVXNpbmcgQ2xvdWQgUm91dGVyIGZvciBkeW5hbWljIHJvdXRpbmcgcmVxdWlyZXMgYSBCR1AgYWRkcmVzcyBhbG9uZyB3aXRoIHRoZSBwZWVyIGFkZHJlc3MgYW5kIHRoZSBzaGFyZWQgc2VjcmV0IGZvciBzZWN1cmUgYWNjZXNzLg&s=ZhRNCs8-","_definitionSlowTtsUrl":"\/tts\/en.mp3?v=14&b=Q29ycmVjdCBhbnN3ZXJzIEIsIEMsIGFuZCBEIAoKVXNpbmcgQ2xvdWQgUm91dGVyIGZvciBkeW5hbWljIHJvdXRpbmcgcmVxdWlyZXMgYSBCR1AgYWRkcmVzcyBhbG9uZyB3aXRoIHRoZSBwZWVyIGFkZHJlc3MgYW5kIHRoZSBzaGFyZWQgc2VjcmV0IGZvciBzZWN1cmUgYWNjZXNzLg&s=ZhRNCs8-","_definitionAudioUrl":"\/tts\/en.mp3?v=14&b=Q29ycmVjdCBhbnN3ZXJzIEIsIEMsIGFuZCBEIAoKVXNpbmcgQ2xvdWQgUm91dGVyIGZvciBkeW5hbWljIHJvdXRpbmcgcmVxdWlyZXMgYSBCR1AgYWRkcmVzcyBhbG9uZyB3aXRoIHRoZSBwZWVyIGFkZHJlc3MgYW5kIHRoZSBzaGFyZWQgc2VjcmV0IGZvciBzZWN1cmUgYWNjZXNzLg&s=ZhRNCs8-","_imageUrl":null,"setId":348513265,"rank":0,"lastModified":1544152647,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11937602817":{"id":11937602817,"word":"You want to ensure Dress4Win's sales and tax records remain available for infrequent viewing by auditors for at least 10 years. Cost optimization is your top priority. Which cloud services should you choose?\n\n[ ] A) Google Bigtable with US or EU as location to store the data, and gcloud to access the data. \n[ ] B) BigQuery to store the data, and a web server cluster in a managed instance group to access the data. Google Cloud SQL mirrored across two distinct regions to store the data, and a Redis cluster in a managed instance group to access the data. \n[ ] C) Google Cloud Storage Nearline to store the data, and gsutil to access the data. \n[ ] D) Google Cloud Storage Coldline to store the data, and gsutil to access the data.","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct Answer D \n\nFeedback:\nA and B are not suitable for this type of task \"infrequent viewing by auditors for at least 10 years\" and they are not cost-effective, either \n\nD (Correct answer) - \"for infrequent viewing by auditors\" and \"for at least 10 years\" fit the usage pattern for Coldline and qualify Answer D for meeting the requirements \"Cost optimization is your top priority\" due to its lowest storage cost. \n\nExplanation: \nThis is about choosing the storage solution for backup or achieving, depending the required access frequency which in turn impact the cost, you have the option between Nearline and Coldline.\nhttps:\/\/cloud.google.com\/images\/storage\/storage-classes-desktop.svg","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":1,"lastModified":1544152878,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11941027901":{"id":11941027901,"word":"Mountkirk Games has deployed their new backend on Google Cloud Platform (GCP). You want to create a thorough testing process for new versions of the backend before they are released to the public. You want the testing environment to scale in an economical way.\n \nHow should you design the process?\n[ ] A)Create a scalable environment in GCP for simulating production load. \n[ ] B) Build stress tests into each component of your application using resources internal to GCP to simulate load. \n[ ] C) Use the existing infrastructure to test the GCP-based backend at scale. \n[ ] D) Create a set of static environments in GCP to test different levels of load - for example, high, medium, and low.","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct Answer A \n\nFeedback \n\nA) (Correct Answer) With this disposable and repeatable testing resources, you can do load test whenever needed. Shutdown or stop the services or simplify delete and recreate it based on the test plans, to keep the cost low. \n\nIt meets the requirements \"create a thorough testing process for new versions of the backend before they are released to the public\" and\" testing environment to scale in an economical way\". Doing thorough testing on production infrastructure is risky to other running application, not feasible, not scale in economical way. \n\nB) This is not scale nor economical and too complicated to implement. \n\nC) At first glance, reuse exiting environments so it'll be scalable, economical, and in real situation. If Read the case study again, we know Mountkirk Games is popular game platform targeting to global users with very high traffic and heavy load. Doing load test on the production is no longer an option, nor is it necessary a scale in an economical way if you mix the production and testing load. Comparing to the solution creating disposable and reputable testing environment simulating production load and execute test plans on demanding, Answer A is the winner. \n\nD) This is not scalable or economical","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":2,"lastModified":1544153317,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11941105369":{"id":11941105369,"word":"You have been asked to select the storage system for the click-data of your company's large portfolio of websites. This data is streamed in from a custom website analytics package at a typical rate of 6,000 clicks per minute, with bursts of up to 8,500 clicks per second. It must be stored for future analysis by your data science and user experience teams.\n \nWhich storage infrastructure should you choose?\n[ ] A) Google cloud Datastore \n[ ] B) Google Cloud SQL \n[ ] C) Google Cloud Bigtable \n[ ] D) Google Cloud Storage","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct Answer C \n\nFeedback \n\nA) Doesn't not meet this requirement \"It must be stored for future analysis by your data science and user experience teams.\" Google Cloud Datastore is a NoSQL document database built for automatic scaling, high performance, and ease of application development and integrating well with App Engine. \n\nDatastore: A scalable, fully-managed NoSQL document database for your web and mobile applications. \n\nGood for: \n - Semi-structured application data \n - Hierarchical data \n - Durable key-value data \n\nWorkload: \n - User profiles \n - Product catalogs \n - Game state \n\nB) Cloud SQL is mainly for OLTP (Transactional, CRUD) not for taking and storing streaming data. It does not have the scalability and elasticity to absorb this amount of data in real time. \n\nC) (Correct Answer) The reason is that data is in IoT nature and it will be used for analytics. \n\nBigtable: A scalable, fully-managed NoSQL wide-column database that is suitable for both real-time access and analytics workloads. Bigtable is ideal for very large NoSQL datasets and is useful for high-speed transactions and analysis. It integrates well with ML. Dataproc, and analytics \n\nGood for \n - Low-latency read\/write access \n - High-throughput analytics \n - Native time series support \n\nWork load \n - IoT, finance, adtech \n - Personalization, recommendations \n - Monitoring \n - Geospatial datasets \n - Graphs \n\nAlthough both Datastore and Bigtable are NoSQL databases, only Bigtable is able to support over a petabyte of data and is useful for high speed analytics as well, whereas Datastore is not. \n\nD) GCS is ideally for Object storage purpose although it has pretty good scalability. It's not suitable for IoT kind of spiky streaming data. Its buckets initially support roughly 1000 writes per second and then scale as needed. As the request rate for a given bucket grows, Cloud Storage automatically increases the IO capacity for that bucket by distributing the request load across multiple servers. Especially considering the click stream rate of 6,000 clicks per minute, with bursts of up to 8,500 clicks per second, the way GCS handle and absorb this kind high and low data stream by scale up and down make it not suitable for this task.","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":3,"lastModified":1544153544,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11941167100":{"id":11941167100,"word":"Over time, you've created 5 snapshots of a single instance. To save space, you delete snapshots number 3 and 4. What has happened to the fifth snapshot?\n\n[ ] A) The data from both snapshots 3 and 4 necessary for continuance are transferred to snapshot 5. \n[ ] B) It is no longer useable and cannot restore data. \n[ ] C) All later snapshots, including 5, are automatically deleted as well. \n[ ] D) The data from snapshot 4 necessary for continuance was transferred to snapshot 5, however snapshot 3's contents were transferred to snapshot 2.","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct Answer A \n\nExplanation \n\nDeleting a snapshot: \nhttps:\/\/cloud.google.com\/compute\/docs\/disks\/restore-and-delete-snapshots \n\nWhen you delete a snapshot, Compute Engine immediately marks the snapshot as DELETED in the system. If the snapshot has no dependent snapshots, it is deleted outright. However, if the snapshot does have dependent snapshots: \n\n1) Any data that is required for restoring other snapshots is moved into the next snapshot, increasing its size. \n2) Any data that is not required for restoring other snapshots is deleted. This lowers the total size of all your snapshots. \n3) The next snapshot no longer references the snapshot marked for deletion, and instead references the snapshot before it. \n\nBecause subsequent snapshots might require information stored in a previous snapshot, keep in mind that deleting a snapshot does not necessarily delete all the data on the snapshot. As mentioned in the first bullet above, if any data on a snapshot that is marked for deletion is needed for restoring subsequent snapshots, that data is moved into the next corresponding snapshot. To definitively delete data from your snapshots, you should delete all snapshots. \n\nThe linked diagram below illustrates the process described above: https:\/\/cloud.google.com\/compute\/images\/deleting-snapshot.png","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":4,"lastModified":1544153883,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11941252416":{"id":11941252416,"word":"A small number of API requests to your microservices-based application take a very long time. You know that each request to the API can traverse many services. You want to know which service takes the longest in those cases. What should you do? \n[ ] A) Set timeouts on your application so that you can fail requests faster. \n[ ] B) Instrument your application with StackDriver Trace to break down the request latencies at each microservice. \n[ ] C) Send custom metrics for each of your requests to Stackdriver Monitoring. \n[ ] D) Use Stackdriver Monitoring to look for insights that show when your API latencies are high.","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct Answer B \n\nExplanation \n\nA) This won't be able to tell you directly where the bottleneck is. \n\nB) (Correct Answer) This is exactly StackDriver Trace comes to play. \n\nC) Without knowing where the bottleneck is beforehand, it's not easy, if not impossible, to setup custom metrics to capture the latency causes. Besides, the question itself is about to find where the latency\/bottleneck exists. \n\nD) This could tell you when the API call latency reaching to certain threshold\/criteria but can hardly tell where the root causes is without additional setup and analysis. \n\nReference Resources:\n\nStackdriver Trace can help you answer the following questions: \nhttps:\/\/cloud.google.com\/trace\/docs\/overview\n\u2022 How long does it take my application to handle a given request? \n\u2022 Why is it taking my application so long to handle a request? \n\u2022 Why do some of my requests take longer than others? \n\u2022 What is the overall latency of requests to my application? \n\u2022 Has latency for my application increased or decreased over time? \n\u2022 What can I do to reduce application latency? \n\n\"As micro-services become more popular, the cross-application tracing provided by Stackdriver Trace becomes essential in pinpointing the root cause of latency issues.\"","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":5,"lastModified":1544154089,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11941263581":{"id":11941263581,"word":"The operations manager asks you for a list of recommended practices that she should consider when migrating a J2EE application to the cloud. Which three practices should you recommend? \n\nChoose 3 answers:\n[ ] A) Port the application code to run on Google App Engine\n[ ] B) Integrate Cloud Dataflow into the application to capture real-time metrics. \n[ ] C) Instrument the application with a monitoring tool like Stackdriver Debugger. \n[ ] D) Select an automation framework to reliably provision the cloud infrastructure. \n[ ] E) Deploy a continuous integration tool with automated testing in a staging environment. \n[ ] F) Migrate from MySQL to a managed NoSQL database like Google Cloud Datastore or Bigtable.","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct Answer A, E, and F \n\nFeedback:\n\nA) (Correct answer) For Java applications, App Engine provides a J2EE standard servlet container with a complete Java 7 JVM and standard library. Because App Engine supports common Java API standards, your code stays clean and portable. \n\nB) Cloud Dataflow is a fully-managed service for transforming and enriching data in stream (real time) and batch (historical) modes. It is not necessary apply to J2EE migration to Cloud. \n\nC) If using GAE, no configuration is required for this feature - Google App Engine standard environment is configured to use Google Stackdriver Error Reporting and Debugger automatically. The following runtimes are supported (Java, Python, Go, PHP) for debugging at this time. \n\nD) GAE will take care of this for you: GAE is Fully managed serverless application platform. Build and deploy applications on a fully managed platform. Scale your applications seamlessly from zero to planet scale without having to worry about managing the underlying infrastructure. With zero server management and zero configuration deployments, developers can focus only on building great applications without the management overhead. \n\nE) (Correct answer) When you migrate, you would not move you J2EE application directly to production, you would do some testing before roll to production. Ideally automation CI tool should use in staging to test the any changes introduce including code and configuration before roll into production. \n\nF) (Correct answer) In GAE you can access Datastore which is built on top of Google's NoSQL database, Bigtable, and is subject to Bigtable's performance characteristics. \n\nJava Persistence API (JPA) is a standard interface for accessing databases in Java, providing an automatic mapping between Java classes and database tables. There is an open-source plugin available for using JPA with Datastore.","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":6,"lastModified":1544154346,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11941303746":{"id":11941303746,"word":"TerramEarth's 20 million vehicles are scattered around the world. Based on the vehicle's location its telemetry data is stored in a Google Cloud Storage (GCS) regional bucket (US. Europe, or Asia). The CTO has asked you to run a report on the raw telemetry data to determine why vehicles are breaking down after 100 K miles. You want to run this job on all the data. What is the most cost-effective way to run this job?\n\n[ ] A) Launch a cluster in each region to preprocess and compress the raw data, then move the data into a regional bucket and use a Cloud Dataproc cluster to finish the job. \n[ ] B) Move all the data into 1 region, then launch a Google Cloud Dataproc cluster to run the job. \n[ ] C) Launch a cluster in each region to preprocess and compress the raw data, then move the data into a multi-region bucket and use a Dataproc cluster to finish the job. \n[ ] D) Move all the data into 1 zone, then launch a Cloud Dataproc cluster to run the job.","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct Answer A \n\nFeedback \n\nA (Correct answer) Since the raw data are saved based on the vehicle's location all over the world, most likely they'll scatter in many different regions and eventually they need to move to a centralized location for final processing. \n\nPreprocessing raw data and compressing them from each location to reduce the size so to save the between-region data egress cost. \n\nDataproc is Zone-specific resources and since you want to run this job on all data and you or your group probably are the only consumers for the data, moving the data into a regional bucket same or closest to the DataProc cluster zone's region for final analysis is most cost effective. \n\nUse a regional location to help optimize latency, availability, and network bandwidth for data consumers grouped in the same region. \n\nUse a multi-regional location when you want to serve content to data consumers that are outside of the Google network and distributed across large geographic areas. \n\u2022 Store frequently accessed data, or data that needs to be geo-redundant as Multi-Regional Storage. \n\nB) Since the raw data are save based on the vehicles' location all over the world, moving them to a centralized region without preprocessing and compressing would incur additional between-region data egress cost \n\nC) Dataproc is Zone-specific resources and since you want to run this job on all data and data consumption occurs in a centralized location, then moving the data into a multi-region bucket for Dataproc cluster jobs is not most cost effective. \n\nUse a multi-regional location when you want to serve content to data consumers that are outside of the Google network and distributed across large geographic areas. \n\u2022 Store frequently accessed data, or data that needs to be geo-redundant as Multi-Regional Storage.","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":7,"lastModified":1544154525,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11941369150":{"id":11941369150,"word":"Your company just finished a rapid lift and shift to Google Compute Engine for your compute needs. You have another 9 months to design and deploy a more cloud-native solution. Specifically, you want a system that is no-ops and auto-scaling. Which options of following compute products should you choose? \n\nChoose 2 answers:\n[ ] A) Google Container Engine with containers \n[ ] B) Compute Engine with custom instance types\n[ ] C) Google App Engine Standard Environment\n[ ] D) Compute Engine with containers\n[ ] E) Compute Engine with managed instance groups","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct Answer A and C \n\nFeedback: \nOrdering the answers from most to least \"no-ops\" since \"you want a system that is no-ops and auto-scaling.\": \n\nC) (Part of correct answer): This is most to \"no-ops and auto-scaling\" since App Engine is fully managed. \n\nA) (Part of correct answer): The 2nd most toward \"no-ops\" \n\nD) The Third most to \"no-ops\" \n\nE) The least to \"no-ops\", but the instance could be predefined or custom type, so put it slightly closer to \"no-ops\" than answer B \n\nB The least \"no-ops\" \n\nNote: You may also consider D, E, and B as similar level of \"no-ops\" \n\nAlso, C (AppEngine) and A (Container Engine) both have the autoscale capability \n\nSo, the correct answers are A and C \n\nReference Resource:\nYou can imagine a spectrum where, at one end, you have most of the responsibilities for resource management and, at the other end, \n\nGoogle has most of those responsibilities: \nhttps:\/\/cloud.google.com\/docs\/images\/overview\/ops-continuum.svg","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":8,"lastModified":1544154910,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11941410900":{"id":11941410900,"word":"Your company's test suite is a custom C++ application that runs tests throughout each day on Linux virtual machines. The full test suite takes several hours to complete, running on a limited number of on premises servers reserved for testing. Your company wants to move the testing infrastructure to the cloud, to reduce the amount of time it takes to fully test a change to the system, while changing the tests as little as possible. \n\nWhich cloud infrastructure should you recommend? \n[ ] A) Google Cloud Dataproc to run Apache Hadoop jobs to process each test \n[ ] B) Google App Engine with Google Stackdriver for logging \n[ ] C) Google Compute Engine managed instance groups with auto-scaling \n[ ] D) Google Compute Engine unmanaged instance groups and Network Load Balancer","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct Answer C Feedback \n\nA) Apache Hadoop run Java not C++; If the questions meant to use Hadoop to manage and process the test, it's overkill and also need significant changes to the testing infrastructure to integrate with Dataproc. \n\nB) App Engine did not natively support C++, also it's probably hard to port their \"runs tests throughout each day on Linux virtual machines\" to App Engine \"while changing the tests as little as possible\"; StackDriver logging won't help porting the test to GCP, either. \n\nBetween C and D, the main difference is managed or unmanaged instance group \n\nUnmanaged instance groups are groups of dissimilar instances that you can arbitrarily add and remove from the group. Unmanaged instance groups do not offer autoscaling, rolling update support, or the use of instance templates so Google recommends creating managed instance groups whenever possible. Use unmanaged instance groups only if you need to apply load balancing to your pre-existing configurations or to groups of dissimilar instances. \n\nhttps:\/\/cloud.google.com\/compute\/docs\/instance-groups\/ \n\nFrom the question there is no such requirement for unmanaged instance group and not mention that dissimilar Linux machine types are required. \n\nIn addition, judging from what they suffered \"The full test suite takes several hours to complete, running on a limited number of on premises servers\", it seems they simply need more computation power - bigger and\/or more instances for the testing. So the managed instance group with autoscaling is the preferred.","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":9,"lastModified":1544155017,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11941491395":{"id":11941491395,"word":"Operational parameters such as oil pressure are adjustable on each of TerramEarth's vehicles to increase their efficiency, depending on their environmental conditions. Your primary goal is to increase the operating efficiency of all 20 million cellular and unconnected vehicles in the field. \n\nHow can you accomplish this goal?\n[ ] A) Have your engineers inspect the data for patterns, and then create an algorithm with rules that make operational adjustments automatically. \n[ ] B) Implement a Google Cloud Dataflow streaming job with a sliding window and use Google Cloud Messaging (GCM) to make operational adjustments automatically. \n[ ] C) Capture all operating data, train machine learning models that identify ideal operations, and host in Google Cloud Machine Learning (ML) Platform to make operational adjustments automatically. \n[ ] D) Capture all operating data, train machine learning models that identify ideal operations, and run locally to make operational adjustments automatically.","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct Answer D \n\nFeedback:\nA) This won't work - the engineer simply won't be able just to inspect the data for patterns for 20 million vehicles whether the algorithm created run local or in-cloud \n\nB) Without data analytics and machine learning, the two technologies just won't create meaningful algorithm for operational adjustments automatically. Besides, majority (99%) of the 20M vehicles are unconnected and the two technologies have to run on GCP for scalability so there is no way to communicated between local and GCP for adjustments automatically. \n\nC) Again, majority (99%) of the 20M vehicles are unconnected and if the trained model was host in Google Cloud Machine Learning (ML) Platform then there is no way to use the model generated parameters to command the field vehicles to make operational adjustments automatically. \n\nD) (Correct Answer) After creating good ML model by \"Capture all operating data, train machine learning models that identify ideal operations\", you can run the model in the vehicle to make operational adjustments automatically based on each specific vehicle's parameters. Probably run the model in the onboard computer or computer connected to the maintenance port. \n\nTerramEarth connection related Information in the Case Study. There are 20 million TerramEarth vehicles in operation that collect 120 fields of data per second. Data is stored locally on the vehicle and can be accessed for analysis when a vehicle is serviced. The data is downloaded via a maintenance port. This same port can be used to adjust operational parameters, allowing the vehicles to be upgraded in the field with new computing modules. \n\nApproximately 200,000 vehicles are connected to a cellular network, allowing TerramEarth to collect data directly.","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":10,"lastModified":1544155169,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11941535164":{"id":11941535164,"word":"You need to regularly create disk level backups of the root disk of a critical instance. These backups need to be able to be converted into new instances that can be used in different projects. \n\nHow should you do this?\n[ ] A) Create snapshots, turn the snapshot into a custom image, and share the image across projects. \n[ ] B) Use the VM migration tools in Compute Engine to copy a VM to a different project. \n[ ] C) Create snapshots and share them to other projects. \n[ ] D) Stream your VM's data into Cloud Storage and share the exported data in the storage bucket with another project","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct Answer A \n\nExplanation:\nA) (Correct answer) - The proper method is to create a custom image either from an existing, stopped instance, or snapshots of a boot disk, which can then be shared across projects and used to create additional instances. \n\nhttps:\/\/cloud.google.com\/compute\/docs\/instances\/create-start-instance \n\nB) Is for migration not for \"regularly create disk level backups of the root disk of a critical instance\". There are tools allowing copying (importing) on-premises virtual disk to Compute engine but you cannot copy GCP VM. \n\nC) Snapshots cannot be shared across projects. \n\nD) Doesn't meet the requirement \"regularly create disk level backups of the root disk of a critical instance\" nor is it easy to convert into new instance.","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":11,"lastModified":1544155311,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11941570378":{"id":11941570378,"word":"Your company has decided to build a backup replica of their on-premises user authentication PostgreSQL database on Google Cloud Platform. The database is 4 TB, and large updates are frequent. Replication requires private address space communication. \n\nWhich networking approach should you use? \n[ ] A) A Google Compute Engine instance with a VPN server installed connected to the data center network \n[ ] B) A NAT and TLS translation gateway installed on-premises \n[ ] C) Google Cloud Dedicated Interconnect \n[ ] D) Google Cloud VPN connected to the data center network","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct Answer C \n\nExplanation:\n\nA) Single interconnect can be a single 10G link or a link bundle, connected to a single Google router.\n\nB) Does not exist.\n\nAnswer A and B either are not applicable or feature doesn't not exist. \n\nC) (Correct answer) Both VPN and Dedicated Interconnect provide private address space communication. \"The database is 4 TB, and large updates are frequent\" makes the Dedicated Interconnect a suitable solution due to its bandwidth capability and SLA \n\nD) Each VPN tunnel has a max speed of 1.5 Gbps, though you can create multiple VPN tunnels to increase bandwidth, the internet connection from on-premises to GCP may be also a limiting factor \n\nLet assume VPN can reach to 1.5 Gbps speed, to transfer 4 TB data, you need: \n\n4000 * 1024\/1.5 = 4096000 seconds, Approximately equal 47.4 days. \n\nThis is maximum for full set of data replicating, though it won't really happen, but the math is here for the reference \n\nReference \n\nGoogle Cloud Interconnect https:\/\/cloud.google.com\/interconnect\/ \n\nDedicated Interconnect Overview\nhttps:\/\/cloud.google.com\/interconnect\/docs\/concepts\/dedicated-overview\n\nDiagram: https:\/\/s3.amazonaws.com\/whizlabs-pub\/GCP+Professional+Cloud+Architect+Images\/GCP+PCA_PT1\/PT1_Q13.png","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":12,"lastModified":1544155693,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11941604753":{"id":11941604753,"word":"JencoMart wants to migrate their current computing environment to GCP. They want to modify their existing setup to scale for peak traffic instead of needing to provision in advance to meet peak load. When scaling, they want their machines to have as identical of performance as possible to their existing servers. What two actions can they take? \n\nChoose two:\n[ ] A) Convert their compute environment into an App Engine application.\n[ ] B) Set machine type to a custom machine type to match their current individual machines. \n[ ] C) Select the next step higher standard machine type to allow for capacity.\n[ ] D) Create a managed instance group with autoscaling enabled to scale with demand.","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct answer B and D \n\nExplanation \n\nWhile they technically could convert their application into App Engine, it is not necessary to do so. A managed instance group that auto scales would meet their capacity requirements. For each instance group machine, they can use a custom machine type to match their current machine environment. \n\nJencoMart Existing Technical Environment \n\nJencoMart hosts all of its applications in 4 data centers: 3 in North American and 1 in Europe; most applications are dual-homed. ... ... ... \n\nCompute\n\u2022 30 machines in US West Coast, each machine has: \n\u2022 Twin, dual core CPUs\n\u2022 32GB of RAM\n\u2022 Twin 250 GB HDD (RAID 1) \n\u2022 20 machines in US East Coast, each machine has: \n\u2022 Single, dual-core CPU\n\u2022 24 GB of RAM\n\u2022 Twin 250 GB HDD (RAID 1)","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":13,"lastModified":1544155779,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11941678687":{"id":11941678687,"word":"Your company has successfully migrated to the cloud and wants to analyze their data stream to optimize operations. They do not have any existing code for this analysis, so they are exploring all their options. These options include a mix of batch and stream processing, as they are running some hourly jobs and live-processing some data as it comes in. \n\nWhich technology should they use for this? \n[ ] A) Google Cloud Dataflow\n[ ] B) Google Compute Engine with Google BigQuery\n[ ] C) Google Container Engine with Bigtable\n[ ] D) Google Cloud Dataproc","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct Answer A \n\nFeedback \n\nCloud Dataflow (https:\/\/cloud.google.com\/dataflow\/) is a fully-managed service for transforming and enriching data in stream (real time) and batch (historical) modes with equal reliability and expressiveness - no more complex workarounds or compromises needed. And with its serverless approach to resource provisioning and management, you have access to virtually limitless capacity to solve your biggest data processing challenges, while paying only for what you use. \n\nCloud Dataflow unlocks transformational use cases across industries, including: \n\u2022 check Clickstream, Point-of-Sale, and segmentation analysis in retail\n\u2022 check Fraud detection in financial services\n\u2022 check Personalized user experience in gaming\n\u2022 check IoT analytics in manufacturing, healthcare, and logistics\n\nDataflow acts as your data processing pipeline for ETL functions on both streaming and batch data. \nDiagram: https:\/\/s3.amazonaws.com\/whizlabs-pub\/GCP+Professional+Cloud+Architect+Images\/GCP+PCA_PT1\/PT1_Q15.png","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":14,"lastModified":1544155892,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11941714676":{"id":11941714676,"word":"JencoMart is evaluating what managed services (if any) they can migrate their databases to, and which databases will need to be modified to do so. Of their Oracle and PostgreSQL databases, which one needs to be modified, and what service(s) can they move to? \n\nChoose two:\n[ ] A) Oracle will need to be modified into a relational database and can be hosted on Cloud Spanner. \n[ ] B) PostgreSQL will need to be modified to NoSQL and can be hosted on Datastore.\n[ ] C) Oracle can be imported without modification and can be hosted on Cloud Bigtable. \n[ ] D) PostgreSQL can be imported without modification and can be hosted on Cloud SQL.","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct answer A and D \n\nExplanation \n\nOracle is a relational database and cannot be imported into a managed GCP storage option. It will need to be converted to a relational database and can be hosted on Cloud Spanner. Although Cloud SQL would be the more direct 'lift and shift' option, it only holds up to 10TB (their existing database is 20TB) and Spanner can support that amount using additional nodes. PostgreSQL can be migrated in its current form, as Cloud SQL natively supports PostgreSQL as well. \n\nJencoMart Existing Technical Environment - Database\nOracle Database stores user profiles\n\u2022 20 TB\nPostgreSQL database stores user credentials","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":15,"lastModified":1544155980,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11941744001":{"id":11941744001,"word":"You have created several preemptible Linux virtual machine instances using Google Compute Engine. You want to properly shut down your application before the virtual machines are preempted. \n\nWhat should you do? \n[ ] A) Create a shutdown script registered as a xinetd service in Linux and configure a StackDriver endpoint check to call the service.\n[ ] B) Create a shutdown script, registered as a xinetd service in Linux, and use the gcloud compute instances add-metadata command to specify the service URL as the value for a new metadata entry with the key shutdown-script-url\n[ ] C) Create a shutdown script named k99.shutdown in the \/etc\/rc.6.d\/ directory. \n[ ] D) Create a shutdown script and use it as the value for a new metadata entry with the key shutdown-script in the Cloud Platform Console when you create the new virtual machine instance.","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct Answer D \n\nFeedback \n\nRunning Shutdown Scripts: Create and run shutdown scripts that execute commands right before an instance is terminated or restarted, on a best-effort basis. This is useful if you rely on automated scripts to start up and shut down instances, allowing instances time to clean up or perform tasks, such as exporting logs, or syncing with other systems. https:\/\/cloud.google.com\/compute\/docs\/shutdownscript \n\nTo setup Shutdown Scripts, go to GCP console and follow the steps: \nCompute Engine -\u003E VM instance -\u003E Create Instance -\u003E (Expand) Management, disks, networking, SSH keys \n\nEnter the key \"shutdown-script\" and proper value (Diagram Link): https:\/\/s3.amazonaws.com\/whizlabs-pub\/GCP+Professional+Cloud+Architect+Images\/GCP+PCA_PT1\/PT1_Q17.png","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":16,"lastModified":1544156104,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11941758463":{"id":11941758463,"word":"You need to allow traffic from specific virtual machines in 'subnet-a' network access to machines in 'subnet-b' without giving the entirety of subnet-a access. \n\nHow can you accomplish this?\n[ ] A) Create a firewall rule to allow traffic from resources with specific network tags, then assign the machines in subnet-a the same tags.\n[ ] B) Relocate the subnet-a machines to a different subnet and give the new subnet the needed access.\n[ ] C) Create a rule to deny all traffic to the entire subnet, then create a second rule with higher priority giving access to tagged VM's in subnet-a.\n[ ] D) You can only grant firewall access to an entire subnet and not individual VM's inside.","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct Answer A \n\nExplanation \n\nA) (Correct answer) Network tags allow more granular access based on individually tagged instances - Instances by target tags: The firewall rule is applicable only to VMs if they have a matching network tag. \n\nB) This would give the entire subnet access which is against the requirements: allow traffic from specific virtual machines in 'subnet-a' network access to machines in 'subnet-b' without giving the entirety of subnet-a access. \n\nC) Creating overlapping rules with higher priority might technically work, but since traffic defaults to denied if no rule is in place, this is unnecessary. Assigning rules and instances by tags is the best answer. \n\nD) This is not true per answer A","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":17,"lastModified":1544156264,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11941794499":{"id":11941794499,"word":"A news feed web service has the following code running on Google App Engine. During peak load, users report that they can see news articles they already viewed. \n\n1. import news\n2. from flash import flask, redirect request\n3. from flask.ext.api import status\n4. from google.appengineapl import users\n5. app = falsk (__name__)\n6. sessions = {}\n7. @app. Route (\"\/\")\n8. def homepage ():\n9. user = users.get current_user ()\n10. if not user:\n11. return \"invalid login\", status.http_401_uhautorized\n12. if user not in session:\n13. sessions [user] {\"viewed\"} : []}\n14. news_articles = news.get_new_news (user, session [user] {\"viewed\"}\n15. sessions[user] {\"viewed\"} += [n[\"id\"] for n in news_artides]\n16. return news, render (news articles)\n17. if __name__ == \"__main__\":\n18. app.run()\n\nWhat is the most likely cause of this problem?\n \n[ ] A) The session variable is local to just a single instance. \n[ ] B) The session variable is being overwritten in Cloud Datastore.\n[ ] C) The URL of the API needs to be modified to prevent caching. \n[ ] D) The HTTP Expires header needs to be set to -1 to stop caching.","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct Answer A \n\nDetailed Explanation \n\nAnswer A is the correct - The session variable is local to just a single instance. \n\nThe question described \"users report that they can see news articles they already viewed\", which means the correct behavior is, user should only be able to read article they did not reviewed before. \n\nHere is how: \n\nLine 6 declared new session variable: sesions = {}, initially is empty\nThen the code somehow gets the all user, and somehow get the article\nLine 13, 14, 15: basically, save the article(s) the current specific user viewed in session variable. The sessios variable is key value pair data type, key is \"viewed\", value is a list VIEWED [article 1, article 2...]. Of course, if THE user just started or never viewed nay article, the list would be empty \nRemember that session variable host list articles only if they viewed by that user \n\nThen you deploy and run the app in AppEngine. \"During peak load\" most likely means you have many instances run the same codebase independently from each other. If a user hit instance #9, read an article A, then made another request, most likely he'd hit another instance, say #1000. The session variable in the code running in instance #1000 would not have had that information and the article A might be displayed again treated as not viewed before.","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":18,"lastModified":1544157079,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11941822198":{"id":11941822198,"word":"One of the microservices in your application has an intermittent performance problem. You have not observed the problem when it occurs but when it does, it triggers a particular burst of log lines. You want to debug a machine while the problem is occurring. \n\nWhat should you do? \n[ ] A) Log into one of the machines running the microservice and wait for the log storm.\n[ ] B) In the Stackdriver Error Reporting dashboard, look for a pattern in the times the problem occurs.\n[ ] C) Configure your microservice to send traces to Stackdriver Trace so you can find what is taking so long.\n[ ] D) Set up a log metric in Stackdriver Logging, and then set up an alert to notify you when the number of log lines increases past a threshold.","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct Answer D \n\nFeedback:\n\nA) Logging into an individual machine may not see the specific performance problem as multiple machines may be in the configuration and reducing the chances of interacting with an intermittent performance problem. \n\nB) Error reporting won't necessarily catch the log lines unless they are stack traces in the proper format. Additionally, just because there is a pattern doesn't mean you will know exactly when and where to log in to debug. \n\nC) Trace may tell you where time is being spent but won't let you know in on the exact host that the problem is occurring on because you generally only send samples of traces. There is also no alerting on traces to notify exactly when the problem is happening. \n\nD) (Correct Answer) - Since you know that there is a burst of log lines you can set up a metric that identifies those lines. Stackdriver will also allow you to set up a text, email or messaging alert that can notify promptly when the error is detected so you can hop onto the system to debug. \n\nAdditional Resource:\nhttps:\/\/cloud.google.com\/logging\/docs\/logs-based-metrics\/","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":19,"lastModified":1544157220,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11941992353":{"id":11941992353,"word":"To ensure that your application will handle the load even if an entire zone fails, what should you do? \n[ ] A) Don't select the \"Multizone\" option when creating your managed instance group.\n[ ] B) Spread your managed instance group over two zones and overprovision by 100%. (for Two Zone)\n[ ] C) Create a regional unmanaged instance group and spread your instances across multiple zones.\n[ ] D) Overprovision your regional managed instance group by at least 50%. (for Three Zones)","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct answer B and D \n\nFeedback:\n\nB) is correct if one zone fails you still have 100% desired capacity in another zone \n\nD) is correct since you have at least total 150% desired capacity spread over 3 zones, each zone has 50% capacity. You'll have 100% desired capacity in two zones if any single zone failed at given time. \n\nReference Resources: \nhttps:\/\/cloud.google.com\/compute\/docs\/instance-groups\/distributing-instances-with-regional-instance-groups \n\nIf you are creating a regional managed instance group in a region with at least three zones, Google recommends overprovisioning your instance group by at least 50%.","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":20,"lastModified":1544157325,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11942019530":{"id":11942019530,"word":"You are creating a single preemptible VM instance named \"preempt\" to be used as scratch space for a single workload. If your VM is preempted, you need to ensure that disk contents can be re-used. \n\nWhich gcloud command would you use to create this instance? \n[ ] A) gcloud compute instances create \"preempt\" --preemptible --no-boot-disk-auto-delete\n[ ] B) gcloud compute instances create \"preempt\" --preemptible --boot-disk-auto-delete=no\n[ ] C) gcloud compute instances create \"preempt\" --preemptible\n[ ] D) gcloud compute instances create \"preempt\" --no-auto-delete","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct Answer A \n\nExplanation \n\nA (Correct answer) - Specifying '--no-boot-disk-auto-delete' preserves the disk. This flag is not enabled by default so if not specify, it causes the disk to be auto-deleted. \n\nB - The default is boot disk automatically delete and no flag needed, also the syntax is incorrect for this type of flags \n\nC - if you don't specify '--no-boot-disk-auto-delete'. The default would be boot disk automatically delete Here is the corresponding console setting displaying the default option (Diagram Link):\nhttps:\/\/s3.amazonaws.com\/whizlabs-pub\/GCP+Professional+Cloud+Architect+Images\/GCP+PCA_PT1\/PT1_Q22.png\n\nD - when instance created without this flag: --preemptible, it'll be standard instance \n\nHere is the corresponding console setting in \"Availability Policy\" when you create instance with --preemptible flag (Diagram Link):\nhttps:\/\/s3.amazonaws.com\/whizlabs-pub\/GCP+Professional+Cloud+Architect+Images\/GCP+PCA_PT1\/PT1_Q22.1.png","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":21,"lastModified":1544157556,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11942040496":{"id":11942040496,"word":"You want to make a copy of a production Linux virtual machine in the US-Central region. You want to manage and replace the copy easily if there are changes on the production virtual machine. You will deploy the copy as a new instance in a different project in the US-East region. \n\nWhat steps must you take? \n[ ] A) Use the Linux dd and netcat commands to copy and stream the root disk contents to a new virtual machine instance in the US-East region.\n[ ] B) Create a snapshot of the root disk and select the snapshot as the root disk when you create a new virtual machine instance in the US-East region.\n[ ] C) Create an image file from the root disk with Linux dd command, create a new disk from the image file, and use it to create a new virtual machine instance in the US-East region.\n[ ] D) Create a snapshot of the root disk, create an image file in Google Cloud Storage from the snapshot, and create a new virtual machine instance in the US-East region using the image file for the root disk.","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct Answer D \n\nFeedback:\nA) This approach affects performance of the existing machine and incurs significant network costs. \n\nB) This approach does not allow you to create the VM in the new project since snapshots are limited to the project in which they are taken. \n\nC) dd will not work correctly on a mounted disk. \n\nD) (Correct Answer) - This approach meets all of the requirements, it is easy to do and works cross project and cross region. \n\nReference Resources:\nhttps:\/\/cloud.google.com\/compute\/docs\/images\/sharing-images-across-projects","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":22,"lastModified":1544157731,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11942088636":{"id":11942088636,"word":"A lead software engineer tells you that his new application design uses websockets and HTTP sessions that are not distributed across the web servers. You want to help him ensure his application will run properly on Google Cloud Platform. \n\nWhat should you do? \n[ ] A) Help the engineer to convert his websocket code to use HTTP streaming. \n[ ] B) Review the encryption requirements for websocket connections with the security team. \n[ ] C) Meet with the cloud operations team and the engineer to discuss load balancer options.\n[ ] D) Help the engineer redesign the application to use a distributed user session service that does not rely on websockets and HTTP sessions.","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct Answer C \n\nFeedback:\nA) There is no compelling reason to move away from websockets as part of a move to GCP. \n\nB) This may be a good exercise anyway, but it doesn't really have any bearing on the GCP migration. \n\nC) (Correct Answer) The HTTP(S) load balancer in GCP handles websocket traffic natively. Backends that use WebSocket to communicate with clients can use the HTTP(S) load balancer as a front end, for scale and availability. \n\nD) There is no compelling reason to move away from websockets as part of a move to GCP.","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":23,"lastModified":1544157854,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11942121095":{"id":11942121095,"word":"JencoMart has decided to migrate user profile storage to Google Cloud Datastore and the application servers to Google Compute Engine (GCE). During the migration, the existing infrastructure will need access to Datastore to upload the data. \n\nWhat service account key-management strategy should you recommend?\n[ ] A) Provision service account keys for the on-premises infrastructure and use Google Cloud Platform (GCP) managed keys for the VMs \n[ ] B) Authenticate the on-premises infrastructure with a user account and provision service account keys for the VMs.\n[ ] C) Deploy a custom authentication service on GCE\/Google Container Engine (GKE) for the on-premises infrastructure and use GCP managed keys for the VMs.\n[ ] D) Provision service account keys for the on-premises infrastructure and for the GCE virtual machines (VMs).","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct Answer A \n\nFeedback:\n\nA) (correct answer) This addresses both of data migration and application server migration properly. \n\n\"Provision service account keys for the on-premises infrastructure\": For code running on systems outside Google, you cannot use GCP-managed keys. You need to create Service account for it and provision User-managed keys. These keys are created, downloadable, and managed by users - This is solution for on-premises access to GCP datastore during migration \n\n\"use Google Cloud Platform (GCP) managed keys for the VMs\" - this is solution for Application server migration since there is no external access to GCP is required during the migration. \n\nAnswer B is incorrect: First, the applications running on-premises to access GCP Datastore assume the identity of the service account to call Google APIs, so that the users aren't directly involved. \n\nSecondly, for the application server migration to GCP VMs, you can use GCP managed keys for the VMs. It's simple and effective. There is no need to provision and manage keys (User-managed keys) by yourself for the VMs. \n\nGCP-managed keys are used by Cloud Platform services such as App Engine and Compute Engine. These keys cannot be downloaded. Google will keep the keys and automatically rotate them on an approximately weekly basis. \n\nC) is incorrect in the solution for on-premises access to GCP Datastore - This is possible options that might require more setup than worthwhile for the requirements. \n\nD) is incorrect for reason of application server migration: you can use GCP managed keys for the VMs. It's simple and effective. There is no need to provision and manage keys (User-managed keys) by yourself for the application VMs","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":24,"lastModified":1544158072,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11942148332":{"id":11942148332,"word":"Your company processes high volumes of IoT data that are time-stamped. The total data volume can be several petabytes. The data needs to be written and changed at a high speed. You want to use the most performant storage option for your data. \n\nWhich product should you use? \n[ ] A) Cloud Datastore \n[ ] B) Cloud Storage\n[ ] C) Cloud Bigtable \n[ ] D) BigQuery","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct answer C \n\nFeedback:\nA) is not correct because Cloud Datastore is not the most performant product for frequent writes or timestamp-based queries. \n\nB) is not correct because Cloud Storage is designed for object storage not for this type of data ingestion and collection. \n\nC) is correct because Cloud Bigtable is the most performant storage option to work with IoT and time series data. \n\nD) is not correct because although it can store the data, BigQuery is very slow at changing data. \n\nReference:\nCloud Bigtable Schema Design for Time Series Data: \n\nhttps:\/\/cloud.google.com\/bigtable\/docs\/schema-design-time-series","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":25,"lastModified":1544158183,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11942185570":{"id":11942185570,"word":"You set up an autoscaling instance group to serve web traffic for an upcoming launch. After configuring the instance group as a backend service to an HTTP(S) load balancer, you notice that virtual machine (VM) instances are being terminated and re-launched every minute. The instances do not have a public IP address. You have verified the appropriate web response is coming from each instance using the curl command. You want to ensure the backend is configured correctly. \n\nWhat should you do? \n[ ] A) Ensure that a firewall rule exists to allow source traffic on HTTP\/HTTPS to reach the load balancer. \n[ ] B) Create a tag on each instance with the name of the load balancer. Configure a firewall rule with the name of the load balancer as the source and the instance tag as the destination. \n[ ] C) Ensure that a firewall rule exists to allow load balancer health checks to reach the instances in the instance group. \n[ ] D) Assign a public IP to each instance and configure a firewall rule to allow the load balancer to reach the instance public IP.","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct Answer C \n\nFeedback:\nA) Firewall controls access at instance level, not load balancer. Must allow load balancer traffic to connect backend instance allowing health check \n\nB) At this moment it is not possible to set firewall rules over the GCE Load Balancers. You need to create firewall rules that at subnet or instances level allowing specific health check IP ranges (See Answer A above), not the LB tags, to connect to all your load balanced instances. \n\nC) (correct answer) HTTP health check probes are sent from the IP ranges depending on LB types used. These are IP address ranges that the load balancer uses to connect to backend instances. You must create firewall rules that allows traffic from those ranges to reach your instances \n\nFor Network load balancing \n\nWhen a health check is used with Network load balancing, the health check probes come from addresses in the ranges 209.85.152.0\/22, 209.85.204.0\/22, and 35.191.0.0\/16. \n\nFor HTTP(S). SSL proxy. TCP proxy, and Internal load balancing\nWhen a health check is used with HTTP(S), SSL proxy, TCP proxy, or Internal load balancing, the health check probes come from addresses in the ranges 130.211.0.0\/22 and 35.191.0.0\/16. \n\nD) This is not mandatory since your LB could be Internal load balancing so instances' external IPs may be removed","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":26,"lastModified":1544158358,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11942206152":{"id":11942206152,"word":"You are working on a project with two compliance requirements. The first requirement states that your developers should be able to see the Google Cloud Platform billing charges for only their own projects. The second requirement states that your finance team members can set budgets and view the current charges for all projects in the organization. The finance team should not be able to view the project contents. You want to set permissions. \n\nWhat should you do? \n[ ] A) Add the finance team members to the default IAM Owner role. Add the developers to a custom role that allows them to see their own spend only. \n[ ] B) Add the finance team members to the Billing Administrator role for each of the billing accounts that they need to manage. Add the developers to the Viewer role for the Project. \n[ ] C) Add the developers and finance managers to the Viewer role for the Project. \n[ ] D) Add the finance team to the Viewer role for the Project. Add the developers to the Security Reviewer role for each of the billing accounts.","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct answer B \n\nFeedback:\nB) (Correct Answer) Is correct because it uses the principle of least privilege for IAM roles; use the Billing Administrator IAM role for that job function. \n\nA, C, and D are not correct because is it a Google best practice to use pre-defined IAM roles when they exist and match your business scenario; see the link below. \n\nReference\nIAM for Billing:","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":27,"lastModified":1544158453,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11942238878":{"id":11942238878,"word":"Dress4Win has configured a new uptime check with Google Stackdriver for several of their legacy services. The Stackdriver dashboard is not reporting the services as healthy. \n\nWhat should they do?\n[ ] A) In the Cloud Platform Console download the list of the uptime servers' IP addresses and create an inbound firewall rule \n[ ] B) Install the Stackdriver agent on all of the legacy web servers. \n[ ] C) Configure their legacy web servers to allow requests that contain user-Agent HTTP header when the value matches GoogleStackdriverMonitoring- UptimeChecks (https:\/\/cloud.google.com\/monitoring) \n[ ] D) Configure their load balancer to pass through the User-Agent HTTP header when the value matches GoogleStackdriverMonitoring-UptimeChecks (https:\/\/cloud.google.com\/monitoring)","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct Answer A \n\nExplanation \n\nA) (Correct Answer) \"If you are checking a service that is behind a firewall, you can configure your service's firewall to accept traffic from the current set of IP addresses used for uptime checking (Getting uptime-check IP addresses \n\nhttps:\/\/cloud.google.com\/monitoring\/uptime-checks\/#monitoring_uptime_check_list_ips-console). https:\/\/cloud.google.com\/monitoring\/uptime-checks\/#identifying_uptime_check_traffic): \n\nGoogleStackdriverMonitoring-UptimeChecks \n(https:\/\/cloud.google.com\/monitoring): \n\nRegardless on instance or LoadBalancer level, as long as the firewall allowed, this user-agent can pass through; also, there is no feature supporting User-Agent header value associated firewall rule configuration. \n\nAdditional Resource \n\nFor your quick reference, here are the part of Dress4win existing Application servers in a single data center location: \n\u2022 Tomcat - Java micro-services\n\u2022 Nginx - static content\n\u2022 Apache Beam - Batch processing","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":28,"lastModified":1544158562,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11942256677":{"id":11942256677,"word":"In moving their test and development environments to Google Cloud, what is the best practice for Dress4Win to follow to ensure proper isolation between both environments using the principle of least privilege? \n[ ] A) Separate the test and dev environments into different projects, giving each team access to only their own projects. \n[ ] B) Separate the test and dev environments into different projects, with each team sharing a single account to access each. \n[ ] C) Host both environments in the same project but different VPC's. \n[ ] D) Separate the test and dev environments into different projects, with different levels of access for each team.","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct Answer A \n\nExplanation \n\nA) (Correct answer) For least privilege and separation of duties, the best practice is to separate both environments into different projects, development or test team gets their own accounts, and each team is assigned to only their projects. \n\nThe best practices: \n\u2022 You should not use same account for both Development and Test environments regardless how do you create projects inside that account for different environments. You should use different account for each environment which associated with different group of users. You should use project to isolate user access to resource not to manage users. \n\n\u2022 Using a shared VPC allows each team to individually manage their own application resources, while enabling each application to communicate between each other securely over RFC1918 address space. So VPC's isolate resources but not user\/service accounts. \n\nAnswers B, C, and D are incorrect \n\nB) is the scenario that use same account for both development and test environments attempting to isolate user access with different projects \n\nC) is the scenario that use same account for both development and test environments with same project attempting to isolate user access with network separation. Note, VPC's isolate resources but not user or service accounts. \n\nD) is the scenario that use same account for both development and test environments attempting to isolate user access with different projects \n\nYou can add team members to projects you own and grant the members different levels of access to the project's resources and APIs. This is not the best practice for managing users and their privileges with different environments. It might work for small shop but not for the origination size like Dress4Win. \n\nReference Resources \nHere is the Dress4Win Solution Concept (partial): \n\n\"For the first phase of their migration to the cloud, Dress4win is considering moving their development and test environments...\"","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":29,"lastModified":1544158686,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11942275003":{"id":11942275003,"word":"Mountkirk Games wants to set up a real-time analytics platform for their new game. The new platform must meet their technical requirements. \n\nWhich combination of Google technologies will meet all of their requirements?\n[ ] A) Cloud Dataflow, Cloud Storage, Cloud Pub\/Sub, and BigQuery \n[ ] B) Cloud SQL, Cloud Storage, Cloud Pub\/Sub, and Cloud Dataflow \n[ ] C) Container Engine, Cloud Pub\/Sub, and Cloud SQL \n[ ] D) Cloud Pub\/Sub, Compute Engine, Cloud Storage, and Cloud Dataproc \n[ ] E) Cloud Dataproc, Cloud Pub\/Sub, Cloud SQL, and Cloud Dataflow","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct Answer A \n\nFeedback \n\n(see Mountkirk Games case study for details or below for briefing summary) \n\nFor requirements: Process incoming data on the fly directly from the game servers - Cloud Dataflow (Both \nStream and Batch), reference architect component , we can eliminate C and D since they don't have DataFlow \nC - Container Engine, Cloud Pub\/Sub, and Cloud SQL \nD - Cloud Pub\/Sub, Compute Engine, Cloud Storage, and Cloud Dataproc \nFor requirements: Allow SQL queries to access at least 10 TB of historical data - BigQuery, reference architect \n\ncomponent, we can eliminate B and E since they don't have BigQuery \n\nB - Cloud SQL, Cloud Storage, Cloud Pub\/Sub, and Cloud Dataflow \n\nE - Cloud Dataproc, Cloud Pub\/Sub, Cloud SQL, and Cloud Dataflow \n\nThe only correct answer left is A, which meets all of their requirements \n\nA - Cloud Dataflow, Cloud Storage, Cloud Pub\/Sub, and BigQuery \n\nBelow is a reference architect Google recommending for similar scenario in data collection and analysis \n\nhttps:\/\/cloud.google.com\/solutions\/mobile\/mobile-gaming-analysis-telemetry \n\nBuilding a Mobile Gaming Analytics Platform - a Reference Architecture (Diagram Link):\nhttps:\/\/s3.amazonaws.com\/whizlabs-pub\/GCP+Professional+Cloud+Architect+Images\/GCP+PCA_PT1\/PT1_Q31.png\n\nMountkirk Games real-time analytics platform \n\nSolution Concept \n\nMountkirk Games is building a new game, which they expect to be very popular. They plan to deploy the game's backend on Google Compute Engine so they can capture streaming metrics, run intensive analytics, and take advantage of its autoscaling server environment and integrate with a managed NoSQL database. \n\nTechnical Requirements \n\nRequirements for Game Analytics Platform\n\u2022 Dynamically scale up or down based on game activity - Compute engine, container engine, Cloud Storage\n\u2022 Process incoming data on the fly directly from the game servers - Cloud Dataflow (Both Stream and Batch) \n\u2022 Process data that arrives late because of slow mobile networks - Cloud Pub\/Sub\n\u2022 Allow SQL queries to access at least 10 TB of historical data - BigQuery\n\u2022 Process files that are regularly uploaded by users' mobile devices - Cloud Pub\/Sub\n\u2022 Use only fully managed services - BigQuery, DataFlow, Cloud SQL","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":30,"lastModified":1544158785,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11942299673":{"id":11942299673,"word":"Your company is forecasting a sharp increase in the number and size of Apache Spark and Hadoop jobs being run on your local datacenter. You want to utilize the cloud to help you scale this upcoming demand with the least amount of operations work and code change.\n \nWhich product should you use?\n[ ] A) Google Cloud Dataflow \n[ ] B) Google Compute Engine \n[ ] C) Google Container Engine \n[ ] D) Google Cloud Dataproc","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct Answer D \n\nFeedback \n\nCloud Dataproc is the only choice in the answers you can (almost) directly map to your on-premises Apache Spark\/Hadoop platform and meet the requirements \"scale this upcoming demand with the least amount of operations work and code change\". \n\nCloud Dataproc is a fast, easy-to-use, fully-managed cloud service for running Apache Spark and Apache Hadoop clusters in a simpler, more cost-efficient way. Operations that used to take hours or days take seconds or minutes instead, and you pay only for the resources you use (with per-second billing). Cloud Dataproc also easily integrates with other Google Cloud Platform (GCP) services, giving you a powerful and complete platform for data processing, analytics and machine learning. \nhttps:\/\/cloud.google.com\/dataproc\/","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":31,"lastModified":1544158848,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11942318319":{"id":11942318319,"word":"Your customer is receiving reports that their recently updated Google App Engine application is taking approximately 30 seconds to load for some of their users. This behavior was not reported before the update. \n\nWhat strategy should you take? \n[ ] A) Work with your ISP to diagnose the problem. \n[ ] B) Open a support ticket to ask for network capture and flow data to diagnose the problem, then roll back your application. \n[ ] C) Roll back to an earlier known good release initially, then use Stackdriver Trace and logging to diagnose the problem in a development\/test\/staging environment. \n[ ] D) Roll back to an earlier known good release, then push the release again at a quieter period to investigate. Then use Stackdriver Trace and logging to diagnose the problem.","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct Answer C \n\nExplanation \n\nA - You ISP normally won't help in this level. Also, the problem most likely is caused by recent update. The good approach is to rollback first and then investigate later. Similarly, this also apply to answer B. \n\nTo investigate this kind of issue, use Stackdriver Trace and logging to diagnose the bottleneck \n\nC and D have something in common for both \"use Stackdriver Trace and logging\", either in test\/dev or in production environment and \"Roll back to an earlier known good release\". At this moment, only the \"earlier known good release\" version starts receiving traffic. \n\nThe difference lines between C's \"to diagnose the problem in a development\/test\/staging environment.\" and D's \"then push the release again at a quieter period to investigate\". \n\nIf you want to debug in production environments, \"then push the release again at a quieter period to investigate\" is not necessary - you can simply switch \"default\" version or split the traffic between the \"earlier known good release\" version and the new problem version. \n\nEssentially D's \"then push the release again at a quieter period to investigate\" disqualifies itself as good answer - the default would be the new pushed version (the one with problem) starts receiving traffic \"at a quieter period\", and the slow loading users may not present. But with answer C in development\/test\/staging environment, you can arbitrarily load those suffering users if you know them or simulate production load to reveal the problem users and then do further investigation. \n\nSo, C is the correct answer: First, rollback to \"the earlier known good release\" and then use the test\/dev\/staging envs to investigate. \n\nAdditional Resource\n\nhttps:\/\/cloud.google.com\/appengine\/docs\/flexible\/python\/testing-and-deploying-your-app","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":32,"lastModified":1544158926,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11942328821":{"id":11942328821,"word":"TerramEarth plans to connect all 20 million vehicles in the field to the cloud. This increases the volume to 20 million 600 byte records a second for 40 TB an hour. \n\nHow should you design the data ingestion?\n[ ] A) Vehicles write data directly to GCS. \n[ ] B) Vehicles stream data directly to Google BigQuery. \n[ ] C) Vehicles continue to write data using the existing system (FTP). \n[ ] D) Vehicles write data directly to Google Cloud Pub\/Sub.","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct Answer D \n\nFeedback \n\nHere is the volume to 20 million 600 byte records a second for 40 TB an hour streaming data need to ingest to and absorb by the system \n\nA - Vehicles write data directly to GCS - GCS is mainly for storage and it cannot stand for this amount of data streaming ingestion.\n\nGCS is ideally for Object storage purpose although it has pretty good scalability. It's not suitable for IOT kind of streaming data. Its Buckets initially support roughly 1000 writes per second and then scale as needed. As the request rate for a given bucket grows, Cloud Storage automatically increases the IO capacity for that bucket by distributing the request load across multiple servers. Especially considering the volume to 20 million 600 byte records a second for 40 TB an hour streaming data, it makes unsuitable for this task. \n\nB - Vehicles stream data directly to Google BigQuery GCS - BigQuery is mainly for BI analysis though it also provides storage capacity and price similar to GCS and it cannot stand for this amount of data streaming ingestion \n\nC - Vehicles continue to write data using the existing system (FTP) - this is exiting solution we already know it's not scalable. Please refer to the case study for details \n\nD (Correct answer) - Vehicles write data directly to Google Cloud Pub\/Sub - Pub\/Sub is acting as 'shock absorber', allowing asynchronous messaging between large numbers of devices.","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":33,"lastModified":1544158987,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11942344010":{"id":11942344010,"word":"You have data stored in a Cloud Storage dataset and also in a BigQuery dataset. You need to secure the data and provide 3 different types of access levels for your Google Cloud Platform users: administrator, read\/write, and read-only. You want to follow Google-recommended practices. \n\nWhat should you do? \n[ ] A) Create 3 custom IAM roles with appropriate policies for the access levels needed for Cloud Storage and BigQuery. Add your users to the appropriate roles. \n[ ] B) At the Organization level, add your administrator user accounts to the Owner role, add your read\/write user accounts to the Editor role, and add your read-only user accounts to the Viewer role. \n[ ] C) At the Project level, add your administrator user accounts to the Owner role, add your read\/write user accounts to the Editor role, and add your read-only user accounts to the Viewer role. \n[ ] D) Use the appropriate pre-defined IAM roles for each of the access levels needed for Cloud Storage and BigQuery. Add your users to those roles for each of the services.","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct answer D \n\nFeedback \n\nD (Correct Answer) - D is correct because the principle of least privilege favors using pre-created roles with associated policies when they match your requirements. \n\nA, B, and C are not correct because it is a Google best practice to use pre-defined IAM roles when they exist and match your business scenario \n\nReference\nStorage Access Control\nhttps:\/\/cloud.google.com\/storage\/docs\/access-control\/ \nBigQuery access control \nhttps:\/\/cloud.google.com\/bigquery\/docs\/access-control \nIAM Overview \nhttps:\/\/cloud.google.com\/iam\/docs\/overview \nIdentity and Access Management https:\/\/cloud.google.com\/iam\/docs\/overview","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":34,"lastModified":1544159048,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11942353286":{"id":11942353286,"word":"Your office is connected to GCP via a VPN connection. How can you increase the speed of your VPN connection, assuming that your office Internet is not the bottleneck? \n[ ] A) Apply for a dedicated interconnect option \n[ ] B) Enable high speed routing in your VPN settings \n[ ] C) Create an additional VPN tunnel \n[ ] D) Submit request to increase bandwidth quota","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct answer C \n\nExplanation \n\nA - Apply for a dedicated interconnect option. A dedicated interconnect will also increase speeds, however the question asked how to speed up your VPN connection, not create a new type of connection. \n\nC (Correct answer) - Create an additional VPN tunnel. Each VPN tunnel has a max speed of 1.5 Gbps. However, you can create multiple VPN tunnels to increase bandwidth. \n\nAnswer B and D either are not applicable or feature doesn't not exist.","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":35,"lastModified":1544159114,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11942364513":{"id":11942364513,"word":"Using principal of least privilege and allowing for maximum automation, what steps can you take to store audit logs for long-term access and to allow access for external auditors to view? \n\nChoose two:\n[ ] A) Generate a signed URL to the Stackdriver export destination for auditors to access. \n[ ] B) Create an account for auditors to have view access to Stackdriver Logging. \n[ ] C) Export audit logs to Cloud Storage via an export sink. \n[ ] D) Export audit logs to BigQuery via an export sink.","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct Answer A and C \n\nExplanation \n\nC (Correct answer) - Export audit logs to Cloud Storage via an export sink. Cloud Storage is perfect solution for long-term logs storage. \n\nThere are 3 type of sink destinations you can export StackDriver Logs to: Cloud Storage, Cloud Pub\/Sub, BigQuery. While you could export to BigQuery for low-cost storage, BigQuery is mainly and best for analysis not for long-term storage. Besides, whenever you need to do analysis with BigQuery, you can always easily export the logs from GCS to BigQuery or do query directly against data in GCS bucket. \n\nA (Correct answer) - You could either create a GCP account for auditor ACL object access or signed URL's depending on if they need to have a GCP account or not. Since the requirement is \"allow access for external auditors to view\", hence signed URL is the right choice \nB - Does not meet the \"for long-term access\" requirement \n\nD - It works but for the \"for long-term access\" storage consideration, Cloud Storage is better choice over BigQuery \n\nAdditional Resources\nhttps:\/\/cloud.google.com\/logging\/docs\/export\/\nhttps:\/\/cloud.google.com\/logging\/docs\/export\/configure_export_v2","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":36,"lastModified":1544159173,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11942373552":{"id":11942373552,"word":"Suppose you have a web server that is working properly, but you can't connect to its instance VM over SSH. Which of these troubleshooting methods can you use without disrupting production traffic? \n\nSelect 3 answers:\n[ ] A) Create a snapshot of the disk and use it to create a new disk; then attach the new disk to a new instance \n[ ] B) Use netcat to try to connect to port 22 \n[ ] C) Access the serial console output \n[ ] D) Create a startup script to collect information.","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct answer A, B, and C \n\nFeedback \n\nAnswers A, B, and C are valid methods to diagnose the problem without stop\/start the instance. Answer D need to restart the instance for the script to take effect. \n\nTroubleshooting SSH\nhttps:\/\/cloud.google.com\/compute\/docs\/troubleshooting\/troubleshooting-ssh \n\nUnder certain conditions, it is possible that a Google Compute Engine instance no longer accepts SSH connections. There are many reasons this could happen, from a full disk to an accidental misconfiguration of sshd. This section describes a number of tips and approaches to troubleshoot and resolve common SSH issues. \n\n1) Check your firewall rules ... ... ...\n\n2) Debug the issue in the serial console\nYou can enable read-write access to an instance's serial console so you can log into the console and troubleshoot problems with the instance. This is particularly useful when you cannot log in with SSH or if the instance has no connection to the network. The serial console remains accessible in both these conditions. \n\n3) Test the network\nYou can use the netcat tool to connect to your instance on port 22 and see if the network connection is working. If you connect and see an ssh banner (e.g. SSH-2.0-OpenSSH_6.0p1 Debian-4), your network connection is working, and you can rule out firewall problems. First, use the gcloud tool to obtain the external natIP for your instance: \n\ngcloud compute instances describe example-instance --format='get(networkInterfaces[0].accessConfigs[0].natIP)' 198.51.100.8 \n\nUse the nc command to connect to your instance: # Check for SSH banner user@local:~$ nc [EXTERNAL.IP] 22 SSH-2.0-OpenSSH_6.0p1 Debian-4\n\n4) Try a new user ... ... ...\n5) Use your disk on a new instance ... ... ...\n\n6) Inspect an instance without shutting it down\nYou might have an instance you can't connect to that continues to correctly serve production traffic. In this case, you might want to inspect the disk without interrupting the instance's ability to serve users. First, take a snapshot of the instance's boot disk, then create a new disk from that snapshot, create a temporary instance, and finally attach and mount the new persistent disk to your temporary instance to troubleshoot the disk. \n\n7) Use a startup script If none of the above helped, you can create a startup script to collect information right after the instance starts. Follow the instructions for running a startup script.","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":37,"lastModified":1544159231,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11942383502":{"id":11942383502,"word":"You have a Kubernetes cluster with 1 node-pool. The cluster receives a lot of traffic and needs to grow. You decide to add a node. \n\nWhat should you do? \n[ ] A) Use \"gcloud container clusters resize\" with the desired number of nodes. \n[ ] B) Use \"kubectl container clusters resize\" with the desired number of nodes. \n[ ] C) Edit the managed instance group of the cluster and increase the number of VMs by 1. \n[ ] D) Edit the managed instance group of the cluster and enable autoscaling.","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct answer A \n\nFeedback:\nA is correct because this resizes the cluster to the desired number of nodes. \n\nB is not correct because you need to use gcloud, not kubectl. \n\nC is not correct because you should not manually manage the MIG behind a cluster. \n\nD is not correct because you should not manually manage the MIG behind a cluster.","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":38,"lastModified":1544159294,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11942392203":{"id":11942392203,"word":"Your App Engine application needs to store stateful data in a proper storage service. Your data is non-relational database data. You do not expect the database size to grow beyond 10 GB and you need to have the ability to scale down to zero to avoid unnecessary costs. \n\nWhich storage service should you use? \n[ ] A) Cloud Datastore \n[ ] B) Cloud Dataproc \n[ ] C) Cloud SQL \n[ ] D) Cloud Bigtable","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct answer A \n\nCloud Datastore is for storing non-relational\/NoSQL data and scales down to zero and up to several TB, which fits all of the requirements. \n\nDatastore: A scalable, fully-managed NoSQL document database for your web and mobile applications. \n\nGood for: \nSemi-structured application data\nHierarchical data\nDurable key-value data\n\nWorkload: \nUser profiles\nProduct catalogs\nGame state","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":39,"lastModified":1544159356,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11942402315":{"id":11942402315,"word":"To reduce costs, the Director of Engineering has required all developers to move their development infrastructure resources from on-premises virtual machines (VMs) to Google Cloud Platform. These resources go through multiple start\/stop events during the day and require state to persist. You have been asked to design the process of running a development environment in Google Cloud while providing cost visibility to the finance department. Which two steps should you take? \n\nChoose 2 answers:\n[ ] A) Store all state in Google Cloud Storage, snapshot the persistent disks, and terminate the VM\n[ ] B) Use the --no-auto-delete flag on all persistent disks and stop the VM. \n[ ] C) Apply VM CPU utilization label and include it in the BigQuery billing export.\n[ ] D) Use Google BigQuery billing export and labels to associate cost to groups.\n[ ] E) Use the -auto-delete flag on all persistent disks and terminate the VM.\n[ ] F) Store all state into local SSD, snapshot the persistent disks, and terminate the VM.","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct answers are B and D\n\nB (Correct Answer) - Use the --no-auto-delete flag on all persistent disks and stop the VM - with this flag set, when you terminate the instance, the persistence disk will not be deleted so the disk contents are preserved between start and stop. When the instance in stop status, you are only got charged for very low-cost disk storage\nauto-delete for the given disk is enabled by default, use --no-auto-delete to disable.\nhttps:\/\/cloud.google.com\/sdk\/gcloud\/reference\/compute\/instances\/set-disk-auto-delete\nC - Apply VM CPU utilization label and include it in the BigQuery billing export - this is simply not doable D (Correct Answer) - Use Google BigQuery billing export and labels to associate cost to groups. Billing export to BigQuery enables you to export your daily usage and cost estimates automatically throughout the day to a BigQuery dataset you specify. You can then access your billing data from BigQuery. About labels: You'll see columns for labels in your BigQuery dataset, but for the current release some label values will be empty. Label export data will be populated at different times for different services, depending on when each service provides it. E - Use the -auto-delete flag on all persistent disks and terminate the VM - This is totally against the requirements. Since the instance is terminated and disk is gone when this flag is on, there is no way to restart the same instance and needless to say the disk content are not persisted. Answer A and F are incorrect, or at least not as good as Answer B - they are not a suitable solution for frequently start\/stop and require state to persist. The correct answers are: Use the --no-auto-delete flag on all persistent disks and stop the VM., Use Google BigQuery billing export and labels to associate cost to groups.","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":40,"lastModified":1544159451,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11942412685":{"id":11942412685,"word":"MountKirk Games needs to build out their streaming data analytics pipeline to feed from their game backend application. \n\nWhat GCP services in which order will achieve this?\n[ ] A) Cloud Storage - Cloud Dataflow - BigQuery \n[ ] B) Cloud Dataproc - Cloud Storage - BigQuery \n[ ] C) Cloud Pub\/Sub - Cloud Dataflow - Cloud Bigtable \n[ ] D) Cloud Pub\/Sub - Cloud Dataflow - BigQuery","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct answer D \n\nExplanation \n\nPub\/Sub is kind of 'shock absorber', allowing asynchronous messaging between large numbers of devices. Cloud Dataflow acts as your data processing pipeline for ETL functions on both streaming and batch data. BigQuery is a data warehouse, able to run analysis on petabytes of data using SQL queries. \n\nBelow is a reference architect Google recommending for similar scenario in Real-time streaming data collection and analysis https:\/\/cloud.google.com\/solutions\/mobile\/mobile-gaming-analysis-telemetry \n\nReal-time processing of events from game clients and game servers(Diagram Link):\nhttps:\/\/s3.amazonaws.com\/whizlabs-pub\/GCP+Professional+Cloud+Architect+Images\/GCP+PCA_PT1\/PT1_Q42.png\n\n\nData Transformation with Cloud Dataflow - Dataflow acts as your data processing pipeline for ETL functions on both streaming and batch data. (Diagram Link):\nhttps:\/\/s3.amazonaws.com\/whizlabs-pub\/GCP+Professional+Cloud+Architect+Images\/GCP+PCA_PT1\/PT1_Q42.1.png","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":41,"lastModified":1544159575,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11942429953":{"id":11942429953,"word":"Your company is planning the infrastructure for a new large-scale application that will need to store over 100 TB or a petabyte of data of data in NoSQL format for high-speed transactions and analytics. \n\nWhich storage option should you use? \n[ ] A) Cloud Bigtable \n[ ] B) Cloud Spanner \n[ ] C) Cloud SQL \n[ ] D) Cloud Datastore","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct answer A \n\nBigtable is ideal for very large NoSQL datasets and is useful for high-speed transactions and analysis. Bigtable: A scalable, fully-managed NoSQL wide-column database that is suitable for both real-time access and analytics workloads. Bigtable is ideal for very large NoSQL datasets and is useful for high-speed transactions and analysis. It integrates well with ML. Dataproc, and analytics \n\nGood for\nLow-latency read\/write access\nHigh-throughput analytics\nNative time series support\n\nWork load\nIoT, finance, adtech\nPersonalization, recommendations\nMonitoring\nGeospatial datasets\nGraphs\n\nAlthough both Datastore and Bigtable are NoSQL databases, Bigtable is able to support over a petabyte of data and is useful for high speed analytics as well, whereas Datastore is not.","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":42,"lastModified":1544159641,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11942454299":{"id":11942454299,"word":"You created an update for your application on App Engine. You want to deploy the update without impacting your users. You want to be able to roll back as quickly as possible if it fails. \n\nWhat should you do? \n[ ] A) Delete the current version of your application. Deploy the update using the same version identifier as the deleted version. \n[ ] B) Notify your users of an upcoming maintenance window. Deploy the update in that maintenance window. \n[ ] C) Deploy the update as the same version that is currently running. \n[ ] D) Deploy the update as a new version. Migrate traffic from the current version to the new version.","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct answer D \n\nFeedback \n\nA and B are not correct because this will make the application temporarily unavailable to users. \n\nC is not correct because to roll back, you'll need to redeploy the previous deployment because the app was overwritten with the same version number. Therefore this takes longer than a rollback using method D. \n\nD is correct because this makes sure there is no downtime and you can roll back the fastest. \n\nReference\nMigrating and Splitting Traffic https:\/\/cloud.google.com\/appengine\/docs\/admin-api\/migrating-splitting-traffic","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":43,"lastModified":1544159696,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11942464087":{"id":11942464087,"word":"You are designing a large distributed application with 30 microservices. Each of your distributed microservices needs to connect to a database back-end. You want to store the credentials securely. \n\nWhere should you store the credentials? \n[ ] A) In a secret management system \n[ ] B) In the source code \n[ ] C) In an environment variable \n[ ] D) In a config file that has restricted access through ACLs","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct Answer A \n\nFeedback \n\nA (Correct answer) - In a secret management system \n\nApplications often require access to small pieces of sensitive data at build or run time. These pieces of data are often referred to as secrets. Secrets are similar in concept to configuration files, but are generally more sensitive, as they may grant access to additional data, such as user data. https:\/\/cloud.google.com\/kms\/docs\/secret-management \n\nB - In the source code: This is exactly again the best practice \"Do not embed secrets related to authentication in source code, such as API keys, OAuth tokens, and service account credentials.\" (see below the best practice #1) \n\nC - In an environment variable - you use environment variable to point to the location where the secrets (credentials) are stored other than store the secrete directly (see below the best practice #1) \n\nD - In a configuration file that has restricted access through ACLs - Secrets are similar to but generally more sensitive than configuration and also, ACLs may not enough for the secrete management. Here is example for Storing secrets \n\nhttps:\/\/cloud.google.com\/kms\/docs\/store-secrets \n\nAdditional Resource\nhttps:\/\/cloud.google.com\/docs\/authentication\/production#providing_credentials_to_your_application \n\nBest practices for managing credentials \n\nCredentials provide access to sensitive data. The following practices help protect access to these resources: \n1) Do not embed secrets related to authentication in source code, such as API keys, OAuth tokens, and service account credentials. You can use an environment variable pointing to credentials outside of the application's source code, such as Cloud Key Management Service. \n2) Do use different credentials in different contexts, such as in testing and production environments. \n3) Do transfer credentials only over HTTPS to prevent a third party from intercepting your credentials. Never transfer in clear text or as part of the URL. \n4) Never embed long-lived credentials into your client-side app. For example, do not embed service account credentials into a mobile app. Client-side apps can be examined, and credentials can easily be found and used by a third party. \n5) Do revoke a token if you no longer need it.","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":44,"lastModified":1544159759,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11942471764":{"id":11942471764,"word":"Based on TerramEarth's current data flow environment (refer to the image in the case study), what are the direct GCP services needed to replicate the same structure for batch uploads?\n[ ] A) Cloud Spanner - Cloud SQL - BigQuery \n[ ] B) Cloud Dataflow - Cloud Bigtable - Cloud Dataproc \n[ ] C) Cloud Dataproc - Cloud Storage - BigQuery \n[ ] D) Cloud Storage - Cloud Dataflow - BigQuery","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct answer D \n\nExplanation \n\nBased on their current batch upload model, the direct equivalent would be to use Cloud Storage for storing files, Dataflow for their ETL processing, and BigQuery for their data warehouse needs. \n\nBelow illustrates the solution concept. \n\nTerramEarth's Existing Technical Environment One Possible GCP solution for batch upload flow (Diagram Links):\nhttps:\/\/s3.amazonaws.com\/whizlabs-pub\/GCP+Professional+Cloud+Architect+Images\/GCP+PCA_PT1\/PT1_Q46.png\nhttps:\/\/s3.amazonaws.com\/whizlabs-pub\/GCP+Professional+Cloud+Architect+Images\/GCP+PCA_PT1\/PT1_Q46.1.png","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":45,"lastModified":1544159870,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11942480658":{"id":11942480658,"word":"An application development team believes their current logging tool will not meet their needs for their new cloud-based product. They want a better tool to capture errors and help them analyze their historical log data. You want to help them find a solution that meets their needs. \n\nWhat should you do?\n[ ] A) Send them a list of online resources about logging best practices. \n[ ] B) Help them define their requirements and assess viable logging tools. \n[ ] C) Help them upgrade their current tool to take advantage of any new features. \n[ ] D) Direct them to download and install the Google StackDriver logging agent.","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct Answer B \n\nFeedback \n\nA and D can be ruled out for them are not general IT good practices. They need your help, not just simply to sell your products by pointing to a specific tool in your favor (D), or just give them a general best practice list (A) without insight opinions and further explains. \n\nB (Correct Answer) - Help them define their requirements and assess viable logging tools. They know the requirements and the existing tools' problems. While it's true StackDriver Logging and Error Reporting possibly meet all their requirements, there might be other tools also meet their need. They need you to provide expertise to make assessment for new tools, specifically, logging tools that can \"capture errors and help them analyze their historical log data\". \n\nC - Help them upgrade their current tool to take advantage of any new features. They have already used and known those tools' shortcomings. They need your help to find better one. Simply help them upgrade for new features is not enough and may not resolve the problems.","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":46,"lastModified":1544159951,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11942500100":{"id":11942500100,"word":"You have a definition for an instance template that contains a web application. You are asked to deploy the application so that it can scale based on the HTTP traffic it receives. \n\nWhat should you do? \n[ ] A) Create a VM from the instance template. Create a custom image from the VM's disk. Export the image to Cloud Storage. Create an HTTP load balancer and add the Cloud Storage bucket as its backend service. \n[ ] B) Create a VM from the instance template. Create an App Engine application in Automatic Scaling mode that forwards all traffic to the VM. \n[ ] C) Create a managed instance group based on the instance template. Configure autoscaling based on HTTP traffic and configure the instance group as the backend service of an HTTP load balancer. \n[ ] D) Create the necessary amount of instances required for peak user traffic based on the instance template. Create an unmanaged instance group and add the instances to that instance group. Configure the instance group as the Backend Service of an HTTP load balancer.","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct answer C \n\nFeedback \n\nA Is not correct because the Load Balancer will just load balance access to the uploaded image itself, and not create or autoscale VMs based on that image. \n\nB Is not correct because while the App Engine can scale as a proxy, all requests will still end up on the same Compute Engine instance, which needs to scale itself. \n\nC is correct because a managed instance group can use an instance template to scale based on HTTP traffic. \n\nD is not correct because unmanaged instance groups do not offer autoscaling. \n\nReference \nManaged instance groups and autoscaling \nhttps:\/\/cloud.google.com\/compute\/docs\/instance-groups\/#managed_instance_groups_and_autoscaling \n\nExporting an Image https:\/\/cloud.google.com\/compute\/docs\/images\/export-image \n\nAdding a Cloud Storage Bucket to Content-based Load Balancing \n\nhttps:\/\/cloud.google.com\/compute\/docs\/load-balancing\/\nhttp\/adding-a-backend-bucket-to-content-based-load-balancing","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":47,"lastModified":1544160013,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11942509308":{"id":11942509308,"word":"As part of your backup plan, you set up regular snapshots of Compute Engine instances that are running. You want to be able to restore these snapshots using the fewest possible steps for replacement instances. \n\nWhat should you do? \n[ ] A) Export the snapshots to Cloud Storage. Create disks from the exported snapshot files. Create images from the new disks. \n[ ] B) Export the snapshots to Cloud Storage. Create images from the exported snapshot files. \n[ ] C) Use the snapshots to create replacement disks. Use the disks to create instances as needed. \n[ ] D) Use the snapshots to create replacement instances as needed.","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct answer D \n\nFeedback:\nD (Correct Answer) - D is correct because the scenario asks how to recreate instances. \n\nA, B, and C are not correct because the Google best practice of creating images from running Compute Engine instances is to first take a snapshot, export it to Cloud Storage, and then import that file as the basis for a custom image for use in DR scenarios \n\nReference \n\nChoosing a storage option https:\/\/cloud.google.com\/storage-options\/","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":48,"lastModified":1544160076,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null},"11942518876":{"id":11942518876,"word":"For future phases, Dress4Win is looking at options to deploy data analytics to the Google Cloud. \n\nWhich option meets their business and technical requirements? \n[ ] A) Run current jobs from the current technical environment on Google Cloud Dataproc. \n[ ] B) Review all current data jobs. Identify the most critical jobs and create Google BigQuery tables to store and query data. \n[ ] C) Review all current data jobs. Identify the most critical jobs and develop Google Cloud Dataflow pipelines to process data. \n[ ] D) Deploy a Hadoop\/Spark cluster to Google Compute Engine virtual machines. Move current jobs from the current technical environment and run them on the Hadoop\/Spark cluster.","_wordTtsUrl":null,"_wordSlowTtsUrl":null,"_wordAudioUrl":null,"definition":"Correct Answer A \n\nFeedback \n\nA (Correct Answer) - There is no requirement to migrate the current jobs to a different technology. Using managed services where possible is a requirement. Using Google Cloud Dataproc allows the current jobs to be executed within Google Cloud Platform on a managed service offering. \n\nB - Migrating the existing data jobs to a different technology such as Google BigQuery, is not a requirement. \n\nC - Migrating existing data jobs to a different technology such as Google Cloud Dataflow, is not a requirement. \n\nD - Using managed services where possible is a requirement. The current jobs can run on a Hadoop\/Spark cluster in Google Compute Engine but it is not a managed services solution. \n\nBoth A and D are technically correct but D against one of tech requirements \"Use managed services whenever possible.\" \n\nDress4win Existing Technical Environment\nApache Hadoop\/Spark servers: \n\u2022 Data analysis\n\u2022 Real-time trending calculations\n\nTechnical Requirements\n\u2022 Evaluate and choose an automation framework for provisioning resources in cloud. \n\u2022 Support failover of the production environment to cloud during an emergency. \n\u2022 Identify production services that can migrate to cloud to save capacity. \n\u2022 Use managed services whenever possible. \n\u2022 Encrypt data on the wire and at rest. \n\u2022 Support multiple VPN connections between the production data center and cloud environment.","_definitionTtsUrl":null,"_definitionSlowTtsUrl":null,"_definitionAudioUrl":null,"_imageUrl":null,"setId":348513265,"rank":49,"lastModified":1544160137,"wordCustomAudioId":null,"definitionCustomAudioId":null,"definitionImageId":null}},"termSort":"original","testProgress":{"all":null,"starred":null},"user":{"id":102871803,"username":"algogz","timestamp":1540630704,"lastModified":1550150187,"type":0,"isLocked":false,"_imageUrl":"\/a\/i\/animals\/4.gKYJ.jpg","timeZone":"Asia\/Shanghai","birthYear":1977,"birthMonth":12,"birthDay":5,"isConfirmed":true,"selfIdentifiedTeacherStatus":2,"profileImageId":104,"email":"wangyaojun@gmail.com","_hasPassword":true,"_hasFacebook":false,"_hasGoogle":false,"_canChangeUsername":true,"_isEligibleForFreeTrial":true,"_isUnderAge":false,"_isUnderAgeForAds":false,"_isUnderAgeOrInCoppaTransition":false,"_needsChildDirectedTreatment":false,"webLocale":"en-us","mobileLocale":"zh-cn","userLocalePreference":null,"srsNotificationTime":28800,"srsEmailNotificationsEnabled":false,"srsPushNotificationsEnabled":true},"userContentPurchases":null,"userSchools":null,"verifiedCreatorsInfo":[],"viewableBy":"\u6240\u6709\u4eba","yourStatsChunks":{"unanswered":{"title":"\u5c1a\u65e0\u7b54\u6848","subtitle":"\u8fd8\u672a\u5b66\u4e60\u8fd9\u4e9b\u5185\u5bb9\uff01","termIds":[11937566308,11937602817,11941027901,11941105369,11941167100,11941252416,11941263581,11941303746,11941369150,11941410900,11941491395,11941535164,11941570378,11941604753,11941678687,11941714676,11941744001,11941758463,11941794499,11941822198,11941992353,11942019530,11942040496,11942088636,11942121095,11942148332,11942185570,11942206152,11942238878,11942256677,11942275003,11942299673,11942318319,11942328821,11942344010,11942353286,11942364513,11942373552,11942383502,11942392203,11942402315,11942412685,11942429953,11942454299,11942464087,11942471764,11942480658,11942500100,11942509308,11942518876],"shortName":"unanswered"}}}; QLoad('Quizlet.setPageData'); </script><footer class="SiteFooter" itemscope="true" itemtype="http://schema.org/WPFooter" role="contentinfo"><div class="UIContainer"><div class="UIRow"><div class="SiteFooter-flexContainer"><div class="SiteFooter-logo"><a class="UILink UILink--inverted" href="/latest"><div aria-label="Quizlet" class="SiteLogo" role="img" title="Quizlet"><svg fill="currentColor" viewBox="0 0 244 53" xmlns="http://www.w3.org/2000/svg"><path d="M26.99 1.09c15.382 0 26.99 11.36 26.99 25.883 0 6.687-2.54 12.583-6.676 17.04l7.182 7.98H42.37l-2.49-2.847c-3.6 2.482-8.102 3.638-12.89 3.638C11.68 52.784 0 41.496 0 26.974 0 12.017 12.116 1.09 26.99 1.09zm0 41.7c2.03 0 3.844-.43 5.586-1.15L22.2 29.993h12.117l5.587 6.4c2.03-2.518 2.974-5.537 2.974-9.42 0-8.698-6.6-15.817-15.89-15.817-9.287 0-15.814 7.046-15.814 15.817 0 8.915 6.527 15.818 15.815 15.818zM61.035 15.76H71.99v20.706c0 4.89 3.048 6.686 6.676 6.686 3.627 0 6.675-1.797 6.675-6.686V15.758h10.956v21.64C96.296 48.04 88.026 53 78.666 53s-17.63-4.96-17.63-15.6V15.757zm42.75 36.235h10.81V15.758h-10.81v36.235zm-.992-45.69c0-3.56 2.92-6.303 6.36-6.303 3.518 0 6.36 2.743 6.36 6.303 0 3.485-2.842 6.23-6.36 6.23-3.44 0-6.36-2.745-6.36-6.23zm35.738 18.873h-16.74v-9.418h35.332l-20.15 26.817h19.133v9.418h-37.94l20.365-26.817zm23.67 26.817h10.81V1.883H162.2v50.11zm17.063-18.19c0-11.503 8.272-18.908 19.372-18.908 11.173 0 18.5 8.196 18.5 18.334 0 0 0 2.03-.217 3.684h-26.843c.218 4.314 3.48 6.883 9.648 6.883 6.966 0 10.883-2.085 12.987-3.523v9.347c-3.41 2.157-7.182 3.308-13.567 3.308-12.263 0-19.88-7.405-19.88-18.765v-.36zm26.99-4.026c0-3.235-3.337-5.967-7.618-5.967-4.498 0-8.27 2.66-8.488 5.967h16.105zm19.172-4.313h-4.86v-9.706h4.86V1.882h10.52v13.876H244v9.706h-8.054v26.53h-10.52v-26.53z" fill-rule="evenodd"></path></svg></div></a></div><div class="SiteFooter-flexItem"><div class="UIColumn UIColumn--d12 UIColumn--m6"><strong class="SiteFooter-sectionLabel">功能</strong><div class="SiteFooter-sectionLink"><a class="UILink UILink--inverted" href="/zh-cn/features/live">Quizlet Live</a></div><div class="SiteFooter-sectionLink"><a class="UILink UILink--inverted" href="/zh-cn/features/learn">Quizlet学习模式</a></div><div class="SiteFooter-sectionLink"><a class="UILink UILink--inverted" href="/zh-cn/features/diagrams">图表</a></div><div class="SiteFooter-sectionLink"><a class="UILink UILink--inverted" href="/features/flashcards">单词卡</a></div><div class="SiteFooter-sectionLink"><a class="UILink UILink--inverted" href="/zh-cn/mobile">移动版</a></div><div class="SiteFooter-sectionLink"><a class="UILink UILink--inverted" href="/upgrade?source=footer">升级</a></div></div></div><div class="SiteFooter-flexItem"><div class="UIColumn UIColumn--d12 UIColumn--m6"><strong class="SiteFooter-sectionLabel">帮助</strong><div class="SiteFooter-sectionLink"><a class="UILink UILink--inverted" href="/zh-cn/help">帮助中心</a></div><div class="SiteFooter-sectionLink"><a class="UILink UILink--inverted" href="/zh-cn/honor-code">行为准则</a></div><div class="SiteFooter-sectionLink"><a class="UILink UILink--inverted" href="/zh-cn/guidelines">社区准则</a></div><div class="SiteFooter-sectionLink"><a class="UILink UILink--inverted" href="/zh-cn/students">学生</a></div><div class="SiteFooter-sectionLink"><a class="UILink UILink--inverted" href="/zh-cn/teachers">教师</a></div></div></div><div class="SiteFooter-flexItem"><div class="UIColumn UIColumn--d12 UIColumn--m6"><div class="UIRow"><div class="SiteFooter-section SiteFooter-socialLinks"><strong class="SiteFooter-sectionLabel">简介</strong><div class="SiteFooter-sectionLink"><a class="UILink UILink--inverted" href="/zh-cn/mission">公司</a></div><div class="SiteFooter-sectionLink"><a class="UILink UILink--inverted" href="/press">新闻</a></div><div class="SiteFooter-sectionLink"><a class="UILink UILink--inverted" href="/jobs">职位</a></div><div class="SiteFooter-sectionLink"><a class="UILink UILink--inverted" href="mailto:advertising@quizlet.com" onclick="if(window.logPageAction){window.logPageAction('Advertise_clicks');}">刊登广告</a></div><div class="SiteFooter-sectionLink"><a class="UILink UILink--inverted" href="/privacy">隐私<svg class="UIIcon UIIcon--shield PrivacyIcon UIIcon--large"><noscript></noscript><use xlink:href="#shield"></use><noscript></noscript></svg><script>QWait('Quizlet.IconContainer',function(){Quizlet.IconContainer.loadIcon("shield")})</script></a></div><div class="SiteFooter-sectionLink"><a class="UILink UILink--inverted" href="/zh-cn/tos">条款</a></div></div></div></div></div><div class="SiteFooter-flexItem"><div class="UIColumn UIColumn--d12 UIColumn--m6"><div class="SiteFooter-flexRightInfoContainer"><div class="SiteFooter-flexRightInfoItem"><div class="UIRow"><div class="SiteFooter-section SiteFooter-socialLinks"><div class="UIColumn UIColumn--d12 UIColumn--m3"><strong class="SiteFooter-sectionLabel">关注我们</strong><div class="SiteFooter-sectionLink"><span class="UIIconButton"><a class="UIButton UIButton--inverted" role="button" href="https://twitter.com/quizlet"><span class="UIButton-wrapper"><svg class="UIIcon UIIcon--twitter"><noscript></noscript><use xlink:href="#twitter"></use><noscript></noscript></svg><script>QWait('Quizlet.IconContainer',function(){Quizlet.IconContainer.loadIcon("twitter")})</script></span></a></span><span class="UIIconButton"><a class="UIButton UIButton--inverted" role="button" href="https://www.facebook.com/quizlet"><span class="UIButton-wrapper"><svg class="UIIcon UIIcon--facebook"><noscript></noscript><use xlink:href="#facebook"></use><noscript></noscript></svg><script>QWait('Quizlet.IconContainer',function(){Quizlet.IconContainer.loadIcon("facebook")})</script></span></a></span><span class="UIIconButton"><a class="UIButton UIButton--inverted" role="button" href="https://www.instagram.com/quizlet/"><span class="UIButton-wrapper"><svg class="UIIcon UIIcon--instagram"><noscript></noscript><use xlink:href="#instagram"></use><noscript></noscript></svg><script>QWait('Quizlet.IconContainer',function(){Quizlet.IconContainer.loadIcon("instagram")})</script></span></a></span></div></div></div></div></div><div class="SiteFooter-flexRightInfoItem SiteFooter-localeItem"><div class="UIRow"><div class="SiteFooter-localeChooser"><strong class="SiteFooter-sectionLabel">语言</strong><form action="/settings/change-locale-preference" method="post"><div class="UIDropdown UIDropdown--inverted UIDropdown--fill"><select class="UIDropdown-select" name="localePreference" onchange="this.form.submit()"><option value="de">Deutsch</option><option value="en-gb">English (UK)</option><option value="en-us">English (USA)</option><option value="es">Español</option><option value="fr-fr">Français (FR)</option><option value="fr-ca">Français (QC/CA)</option><option value="id">Bahasa Indonesia</option><option value="it">Italiano</option><option value="nl">Nederlands</option><option value="pl">polski</option><option value="pt-br">Português (BR)</option><option value="ru">Русский</option><option value="tr">Türkçe</option><option value="vi">Tiếng Việt</option><option value="ko">한국어</option><option selected value="zh-cn">中文 (简体)</option><option value="zh-tw">中文 (繁體)</option><option value="ja">日本語</option></select><svg class="UIIcon UIIcon--chevron-down UIDropdown-icon"><noscript></noscript><use xlink:href="#chevron-down"></use><noscript></noscript></svg><script>QWait('Quizlet.IconContainer',function(){Quizlet.IconContainer.loadIcon("chevron-down")})</script></div><input name="cstoken" type="hidden" value="fxZdRkYG8RAzDyaMMwgQfX"><input name="redir" type="hidden" value="/348513265/google-cloud-professional-cloud-architect-01-flash-cards/"></form></div></div></div></div></div></div></div></div><div class="UIRow"><div class="SiteFooter-copyright">© <span itemprop="copyrightYear">2019</span> Quizlet Inc.</div></div></div></footer></div><script>(function(){var analyticsData = {"studyableTitle":"Google Cloud Professional Cloud Architect 01","studyableId":348513265,"studyableType":"set","hasDiagrams":false,"locale":"zh-cn","abTests":"PrefetchStudyModeLibraries:experiment","loginSource":"password","isLoggedIn":true,"selfIdentifiedUserType":"student","userUpgradeType":"free","isVerifiedCreator":false,"uid":"-255920372665102257","userId":102871803,"siteVersion":13650};analyticsData.path = Quizlet.actionString;analyticsData.event = 'dataLayer-initialized';window.dataLayer = [analyticsData, {'gtm.start': Date.now(),event:'gtm.js'}];})();</script><script async defer src="https://www.googletagmanager.com/gtm.js?id=GTM-5GTSWTM" onerror=""></script><script>_qoptions={qacct:'p-5brKQLtleyIQU'};_comscore=[{c1:'2',c2:'8641686'}];</script><script async defer src="https://secure.quantserve.com/quant.js"></script><script async defer src="https://sb.scorecardresearch.com/beacon.js"></script><noscript><img src="https://sb.scorecardresearch.com/p?c1=2&amp;c2=8641686&amp;cv=2.0&amp;cj=1" alt=""></noscript></div></body></html>